<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-04-19T22:08:56+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">きままにNLP</title><subtitle>A Technical Blog</subtitle><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（3層ニューラルネットワーク ＆ 手書き数字認識編）</title><link href="http://localhost:4000/DL-Intro-2/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（3層ニューラルネットワーク ＆ 手書き数字認識編）" /><published>2019-04-19T00:00:00+09:00</published><updated>2019-04-19T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-2</id><content type="html" xml:base="http://localhost:4000/DL-Intro-2/">&lt;h1 id=&quot;はじめに&quot;&gt;はじめに&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;このシリーズでは，深層学習の入門書として有名な，「ゼロから作るDeep Learning」（以下，ゼロから〜）と同時並行で，フレームワークを学習し，その定着を目指します．&lt;/p&gt;

&lt;p&gt;前回の&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;第一弾: パーセプトロン編&lt;/a&gt;に目を通していない方は，先に目を通しておくことをおすすめします．&lt;/p&gt;

&lt;p&gt;それでは，今回は3層ニューラルネットワークをKerasで実装し，実際に手書き数字認識（MNISTデータセットの分類）をしていきましょう！&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（3層ニューラルネットワーク）参考: ゼロから〜のP58〜65&lt;/em&gt;&lt;br /&gt;
&lt;em&gt;（MNIST）参考: ゼロから〜のP72〜81&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-3層ニューラルネットワークの実装&quot;&gt;1. 3層ニューラルネットワークの実装&lt;/h1&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;11-プロジェクトの作成&quot;&gt;1.1 プロジェクトの作成&lt;/h2&gt;
&lt;p&gt;まず，3層ニューラルネットワーク実装用のプロジェクトを作成してください．&lt;br /&gt;
以下本章では，&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;を作成するものとして進めていきます．&lt;/p&gt;

&lt;h2 id=&quot;12-モデルの作成&quot;&gt;1.2 モデルの作成&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;今回の実装からは全てFunctional APIを用いたモデル実装を行います．&lt;br /&gt;
Sequentialモデルによる実装は行いませんので，あらかじめご了承ください．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;これから実装する3層ニューラルネットワークの概念図を以下に示します．&lt;br /&gt;
実装の際の参考にしてください．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-19/three_layer_nn.png&quot; alt=&quot;3層ニューラルネットワークの概念図&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;121-レイヤー--numpyを読み込む&quot;&gt;1.2.1 レイヤー &amp;amp; NumPyを読み込む&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;まず，前回と同じように，実装に必要なレイヤーとNumPyを読み込みます．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras import Model
from keras.layers import Input, Dense

import numpy as np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;122-各種レイヤーを定義する&quot;&gt;1.2.2 各種レイヤーを定義する&lt;/h3&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;3層のニューラルネットワークなので，それと同数の3つのDenseレイヤーのインスタンスを生成します．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;units&lt;/code&gt;は各層におけるニューロンの数を表しています．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;活性化関数については，ゼロから〜では&lt;code class=&quot;highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;関数が使用されているので，ここでも&lt;code class=&quot;highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;を活用します．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下の例では，簡単のため入れ子式に活性化関数を定義しましたが，活性化関数をレイヤーインスタンスとして定義することもできます．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center&quot;&gt;＜活性化関数を入れ子式に定義する例＞&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_input = Input(shape=(2, ))
_layer1 = Dense(units=3, activation='sigmoid')(_input)
_layer2 = Dense(units=2, activation='sigmoid')(_layer1)
_output = Dense(units=2)(_layer2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;text-align: center&quot;&gt;＜活性化関数をインスタンスとして定義する例＞&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.layers import Activation
_input = Input(shape=(2, ))
_layer1 = Dense(units=3)(_input)
_activ1 = Activation('sigmoid')(_layer1)
_layer2 = Dense(units=2)(_activ1)
_activ2 = Activation('sigmoid')(_layer2)
_output = Dense(units=2)(_activ2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;参考: &lt;a href=&quot;https://keras.io/ja/activations/&quot;&gt;https://keras.io/ja/activations/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;123-モデルを定義する&quot;&gt;1.2.3 モデルを定義する&lt;/h3&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;前回と同様に，入力のテンソルと出力のテンソルを&lt;code class=&quot;highlighter-rouge&quot;&gt;Model&lt;/code&gt;に渡すことで，モデルを定義します．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;model.summary()&lt;/code&gt;でモデルの状態を確認することができます．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;モデルの状態をみる&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 2)                 0
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 9
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 8
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 6
=================================================================
Total params: 23
Trainable params: 23
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;124-重みを設定する&quot;&gt;1.2.4 重みを設定する&lt;/h3&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜では重みの初期化を定義しているので，本実装でも事前に重みを設定します．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kerasでは，重みは入力層から順にNumPyの配列で保持されています．&lt;br /&gt;
したがって，重みを設定する際には，順当に重みの配列をNumPy配列で定義して，そのリストを渡せばよいです．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重みの設定には，&lt;code class=&quot;highlighter-rouge&quot;&gt;model.set_weights()&lt;/code&gt;を使用します．&lt;br /&gt;
引数は重みの入ったリストです．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;w1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
b1 = np.array([0.1, 0.2, 0.3])
w2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
b2 = np.array([0.1, 0.2])
w3 = np.array([[0.1, 0.3], [0.2, 0.4]])
b3 = np.array([0.1, 0.2])
weight_array = [w1, b1, w2, b2, w3, b3]

model.set_weights(weight_array)
print(model.get_weights())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;参照: ゼロから〜 P65&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]], dtype=float32), 
    array([0.1, 0.2, 0.3], dtype=float32), 
    array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]], dtype=float32), 
    array([0.1, 0.2], dtype=float32), 
    array([[0.1, 0.3], [0.2, 0.4]], dtype=float32), 
    array([0.1, 0.2], dtype=float32)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;13-テストする&quot;&gt;1.3 テストする&lt;/h2&gt;
&lt;p&gt;それでは，作成したモデルをテストしましょう．&lt;br /&gt;
作成したモデルのテストには，前回と同様に，&lt;code class=&quot;highlighter-rouge&quot;&gt;model.predict()&lt;/code&gt;を使用します．&lt;/p&gt;

&lt;p&gt;テストデータは，ゼロから〜 P65に示されているものと同一のものを使用します．&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X = np.array([[1.0, 0.5]])
Y = model.predict(X)

print(Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[0.3168271 0.6962791]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;見事，ゼロから〜 P65に示されている出力値と同一の値を得ることができました！&lt;/p&gt;

&lt;h1 id=&quot;2-手書き数字認識mnist&quot;&gt;2. 手書き数字認識（MNIST）&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;ここからは，今実装した3層ニューラルネットワークを活用して，手書き数字を実際に分類していきます．&lt;/p&gt;

&lt;p&gt;&lt;em&gt;参考: ゼロから〜のP72〜81&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;21-mnistデータセットの読み込み&quot;&gt;2.1 MNISTデータセットの読み込み&lt;/h2&gt;
&lt;p&gt;Kerasでは，MNISTデータセットは簡単にダウンロード&amp;amp;呼び出しできるようになっています．&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;を作成して，以下を入力し動作させてみてください．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

print(x_train.shape)
print(y_train.shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;参照: &lt;a href=&quot;https://keras.io/ja/datasets/#mnist&quot;&gt;https://keras.io/ja/datasets/#mnist&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(60000, 28, 28)
(60000,)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) Kerasの&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist.load_data()&lt;/code&gt;は，「正規化されていない &amp;amp; 2次元配列」の状態のリストが返ってきます．ゼロから〜のP73の挙動とは異なるので，注意してください．&lt;/p&gt;

&lt;p&gt;ここで，データセットが&lt;code class=&quot;highlighter-rouge&quot;&gt;train&lt;/code&gt;と&lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt;の二つに分割されていることに気がつくと思います．これは，機械学習においてはモデルの汎化性能を測定するために，通常データセットを訓練データとテストデータの二つ（もしくはそれ以上）に分割するためです．詳しくは，ゼロから〜の第4章を見てください．&lt;/p&gt;

&lt;h2 id=&quot;22-データセットの前処理&quot;&gt;2.2 データセットの前処理&lt;/h2&gt;
&lt;p&gt;モデルの推論処理においてMNISTデータセットを活用するので，「正規化 &amp;amp; 一次元配列化」の処理を行っておきます．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;配列の形状変換は&lt;code class=&quot;highlighter-rouge&quot;&gt;.reshape&lt;/code&gt;メソッドで行えます．&lt;br /&gt;
引数は変換後の配列形状です．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;正規化処理のために，リストをfloat型に変換します．&lt;br /&gt;
型変換は，&lt;code class=&quot;highlighter-rouge&quot;&gt;.astype&lt;/code&gt;メソッドで行えます．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 一次元配列にする
x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)

# 正規化処理
x_train = x_train.astype('float')
x_test = x_test.astype('float')
x_train /= 255.
x_test /= 255.

print(x_train.shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(60000, 784)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;きちんと一次元配列に変換されていることが確認できました．&lt;br /&gt;
正規化されているかどうかは，配列の要素のうち一つを表示させて確認してみてください．&lt;/p&gt;

&lt;h2 id=&quot;22-モデルの改良&quot;&gt;2.2 モデルの改良&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;でMNISTを分類できるように，以下の2点を改良します． &lt;br /&gt;
改良したものは，&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;に追記してください．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜のP76と合わせて，一層目の全結合層のunit数を50，二層目を100とし，出力層は10とします．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MNISTデータセットの分類は「&lt;strong&gt;分類問題&lt;/strong&gt;」であるため，出力層にsoftmax層を追加します．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;モデルの状態をみる&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 784)               0
_________________________________________________________________
dense_1 (Dense)              (None, 50)                39250
_________________________________________________________________
dense_2 (Dense)              (None, 100)               5100
_________________________________________________________________
dense_3 (Dense)              (None, 10)                1010
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0
=================================================================
Total params: 45,360
Trainable params: 45,360
Non-trainable params: 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;きちんと望みのモデルが実装されていることが確認できました．&lt;/p&gt;

&lt;p&gt;ここで，中間層の定義方法について，&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;と書き方が変わっていると気づいた方もいるでしょう．&lt;/p&gt;

&lt;p&gt;Functional APIを用いたモデル定義では，前回紹介したように，入力と出力のテンソルを個別に保持しておけば良いルールになっています．&lt;/p&gt;

&lt;p&gt;したがって，中間のベクトルに関しては特段利用したいケースがない限りは，同一の変数を利用した方が，コードが煩雑にならないのでおすすめです．&lt;/p&gt;

&lt;h2 id=&quot;23-重みファイルの読み込み&quot;&gt;2.3 重みファイルの読み込み&lt;/h2&gt;
&lt;p&gt;重みファイルは，ゼロから〜のものと同一のファイルを使用します．&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/oreilly-japan/deep-learning-from-scratch/tree/master/ch03&quot;&gt;公式レポジトリ&lt;/a&gt;から，&lt;code class=&quot;highlighter-rouge&quot;&gt;sample_weight.pkl&lt;/code&gt;をダウンロードしてください．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;と同一ディレクトリ内に&lt;code class=&quot;highlighter-rouge&quot;&gt;sample_weight.pkl&lt;/code&gt;を配置してください．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;以下が，重みファイルを読み込むためのスクリプトになります．&lt;br /&gt;
なお，今回は「推論処理のみ行う &amp;amp; できる限りゼロから〜に即したものにする」ために，このスクリプトを使用しますが，このような手間のかかる初期化処理は通常行いません．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import pickle
def load_weight():
    with open('sample_weight.pkl', 'rb') as f:
        weights = pickle.load(f)
        weight_array = [weights['W1'], weights['b1'], 
                        weights['W2'], weights['b2'],
                        weights['W3'], weights['b3']]
        
        return weight_array

model.set_weights(load_weight())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;参考: &lt;a href=&quot;https://keras.io/ja/getting-started/faq/#keras-model&quot;&gt;Kerasでモデルの保存/ロードを行う&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;24-テストする&quot;&gt;2.4 テストする&lt;/h2&gt;
&lt;p&gt;それでは，ゼロから〜のP77と同様に実装したモデルをテストしていきましょう．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.argmax&lt;/code&gt;で軸(axis)指定をしていますが，これはリストが2次元配列以上のときに，「どの軸方向に対して演算を行うか」を指定するために活用します．&lt;br /&gt;
軸指定の詳細については，&lt;a href=&quot;https://deepage.net/features/numpy-axis.html&quot;&gt;このページ&lt;/a&gt;を参照するとわかりやすいです．&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_y_test = model.predict(x_test)
_y_test = np.argmax(_y_test, axis=1)

print(f'Accuracy: {np.sum(y_test == _y_test) / len(y_test)}')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Accuracy: 0.9352
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;めでたく，ゼロから〜のP77に示されている分類精度: 0.9352を得ることができました！&lt;/p&gt;

&lt;h1 id=&quot;まとめ&quot;&gt;まとめ&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;今回はゼロから〜の3章に対応する部分である，3層ニューラルネットとMNISTデータセットの分類をKerasで実装しました． 
深層学習フレームワークを活用することで，たった数行でゼロから〜にあるものと同一のモデルを実装できることを実感したと思います．&lt;/p&gt;

&lt;p&gt;次回からはゼロから〜の4章以降に対応する，ニューラルネットワークの学習に入ります！&lt;/p&gt;

&lt;h1 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;ソースコードは，&lt;strong&gt;GitHub&lt;/strong&gt;で5月中に入手できるようにする予定です．&lt;/p&gt;</content><author><name></name></author><summary type="html">はじめに このシリーズでは，深層学習の入門書として有名な，「ゼロから作るDeep Learning」（以下，ゼロから〜）と同時並行で，フレームワークを学習し，その定着を目指します．</summary></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（パーセプトロン編）</title><link href="http://localhost:4000/DL-Intro-1/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（パーセプトロン編）" /><published>2019-04-13T00:00:00+09:00</published><updated>2019-04-13T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-1</id><content type="html" xml:base="http://localhost:4000/DL-Intro-1/">&lt;h1 id=&quot;はじめに&quot;&gt;はじめに&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;「ゼロから作るディープラーニング」は深層学習を学ぶ入門書として非常に人気があり，様々な場所で用いられています．&lt;/p&gt;

&lt;p&gt;しかしながら，「フレームワークを用いないで深層学習の基礎を学ぶ」という本の目的により，深層学習フレームワークに関する内容は触れられていません．&lt;/p&gt;

&lt;p&gt;したがって，読者の中には実際のフレームワークを用いた機械学習の勉強へと繋げる機会や気力を失ってしまった人も少なからずいると思います．&lt;/p&gt;

&lt;p&gt;このプロジェクトでは，「ゼロから作るDeep Learning」（以下，ゼロから〜）を学習しつつ，深層学習フレームワークの一つである，Kerasについて学んでいきます．&lt;br /&gt;
これにより，深層学習の基礎を理解しつつ，フレームワークを活用した実装方法について学ぶことができます！&lt;/p&gt;

&lt;p&gt;それでは，まずはKerasのインストールから始めていきましょう．&lt;/p&gt;

&lt;h1 id=&quot;1-kerasのインストール&quot;&gt;1. Kerasのインストール&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) 本プロジェクトでは，すでにPythonやNumPy等のインストールは終えているものとしてスタートします．&lt;br /&gt;
環境整備がお済みでない方は，先にゼロから〜の一章を参考に済ませてください．&lt;/p&gt;

&lt;p&gt;・コマンドライン上で，以下のコマンドを入力してKerasをインストールします．&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install keras
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;参考: &lt;a href=&quot;https://keras.io/ja/&quot;&gt;https://keras.io/ja/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-プロジェクトの作成&quot;&gt;2. プロジェクトの作成&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;お好きな環境でゼロから〜二章用のプロジェクトを作成してください．&lt;/p&gt;

&lt;p&gt;ただし，ここでは，&lt;code class=&quot;highlighter-rouge&quot;&gt;sequential.py&lt;/code&gt;と&lt;code class=&quot;highlighter-rouge&quot;&gt;functional.py&lt;/code&gt;の二つのファイルを作成することとします．&lt;/p&gt;

&lt;h1 id=&quot;3-モデルの作成--テスト&quot;&gt;3. モデルの作成 &amp;amp; テスト&lt;/h1&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;KerasにはSepuentialモデルとFunctional APIの2種類のモデルの定義方法があります．
    &lt;ul&gt;
      &lt;li&gt;Sepuentialモデル：様々な層を積み木のように積み重ねていくイメージ．線形スタック．&lt;/li&gt;
      &lt;li&gt;Functionalモデル：層をインスタンスとして扱う．複雑なモデルを定義するときに便利．&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;それぞれのモデルの定義方法の違いを以下で見ていきましょう．&lt;/p&gt;

&lt;h2 id=&quot;31-sequential-モデル&quot;&gt;3.1 Sequential モデル&lt;/h2&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;SequentialモデルでANDゲートのパーセプトロンを実装します．&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;sequential.py&lt;/code&gt;に以下のソースを順に書いていきましょう．&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-レイヤー--numpyを読み込む&quot;&gt;1. レイヤー + NumPyを読み込む&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.models import Sequential
from keras.layers import Dense

import numpy as np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-modelにsepuentialモデルを定義する&quot;&gt;2. &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;にSepuentialモデルを定義する&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-modelにdense層全結合層を追加する&quot;&gt;3. &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;にDense層（全結合層）を追加する&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;model.add(Dense(input_dim=2, units=1))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;全結合層という用語はゼロから〜の二章には登場していませんが，ここでは単純パーセプトロンと同じと思ってください．&lt;br /&gt;
参考程度に，&lt;code class=&quot;highlighter-rouge&quot;&gt;input_dim=2, units=1&lt;/code&gt;のときのDense層の様子を概念図にしたものを以下に示します．&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-13/example_dense.png&quot; alt=&quot;Dense層の様子の概念図&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-modelに重みを与える&quot;&gt;4. &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;に重みを与える&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜の二章では予め重みとバイアスが与えられているので，この実装でも与えます．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重みとバイアスの初期設定には，&lt;code class=&quot;highlighter-rouge&quot;&gt;model.set_weights()&lt;/code&gt;を使用します．&lt;br /&gt;
引数は重みの入ったリストです．&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;model.set_weights([np.array([[0.5], [0.5]]), np.array([-0.7])])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;&lt;em&gt;参照: ゼロから〜のP27&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-テストする&quot;&gt;5. テストする&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;モデルのテストは&lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt;メソッドで行えます．&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt;の返り値は，入力データの予測結果のリストになっています．&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X = np.array([[0,0], [0,1], [1,0], [1,1]])
Y = np.array([[0], [0], [0], [1]])

Y_ = model.predict(X)

print(Y_)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;この結果は以下のようになるはずです．&lt;br /&gt;
Output:
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[-0.7       ]
 [-0.19999999]
 [-0.19999999]
 [ 0.3       ]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;これではわかりにくいので，マイナスのものは&lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;で，プラスのものは&lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;に置き換えます．
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Y_[Y_ &amp;lt;= 0] = False
Y_[Y_ &amp;gt; 0] = True
print(Y_)
print(f'Results: {Y == Y_}')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;以下のような結果が得られたと思います．&lt;br /&gt;
見事ANDゲートが実装できていることが確認できますね．&lt;br /&gt;
Output:
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[0.]
 [0.]
 [0.]
 [1.]]
Results: [[ True]
 [ True]
 [ True]
 [ True]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;32-fucntional-api&quot;&gt;3.2 Fucntional API&lt;/h2&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;Functional APIでANDゲートのパーセプトロンを実装します．&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;functional.py&lt;/code&gt;に以下のソースを順に書いていきましょう．&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-レイヤー--numpyを読み込む-1&quot;&gt;1. レイヤー + NumPyを読み込む&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras import Model
from keras.layers import Input, Dense

import numpy as np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-各種レイヤーを定義する&quot;&gt;2. 各種レイヤーを定義する&lt;/h3&gt;
&lt;p&gt;Functional APIでは，入力層を追加で定義する必要があります．&lt;/p&gt;

&lt;p&gt;Dense部分のイメージとしては，Denseレイヤーのインスタンスを生成し，その入力として，テンソル：_inputを与えるという感じです．出力のテンソルは_outputとなります．&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_input = Input(shape=(2, ))
_output = Dense(units=1)(_input)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-モデルを定義する&quot;&gt;3. モデルを定義する&lt;/h3&gt;
&lt;p&gt;以下のように，Functional APIでは，モデルを定義する際に入力と出力のテンソルを別々に保持しておく必要があります！&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;参考: &lt;a href=&quot;https://keras.io/ja/getting-started/functional-api-guide/&quot;&gt;https://keras.io/ja/getting-started/functional-api-guide/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-重みを与える--テストする&quot;&gt;4. 重みを与える &amp;amp; テストする&lt;/h3&gt;
&lt;p&gt;Sequentialモデルと同じなので割愛します．&lt;br /&gt;
結果が同一になることを確認するとよいです．&lt;/p&gt;

&lt;h1 id=&quot;まとめ&quot;&gt;まとめ&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;今回は，パーセプトロンによるANDゲートの実装をKerasにより行いました．&lt;/p&gt;

&lt;p&gt;Kerasを用いることで，より「簡単に&amp;amp;抽象的に」パーセプトロンを実装することが確認できたと思います．&lt;/p&gt;

&lt;p&gt;次回は，3層ニューラルネットワークの実装を行います．&lt;/p&gt;

&lt;h1 id=&quot;発展課題&quot;&gt;発展課題&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;NAND, ORゲートも実装してみると良いでしょう．&lt;br /&gt;
重みとバイアスは，ゼロから〜のP27,28を参照してください．&lt;/p&gt;

&lt;h1 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;ソースコードは，&lt;strong&gt;GitHub&lt;/strong&gt;で5月中に入手できるようにする予定です．&lt;/p&gt;</content><author><name></name></author><summary type="html">はじめに 「ゼロから作るディープラーニング」は深層学習を学ぶ入門書として非常に人気があり，様々な場所で用いられています．</summary></entry><entry xml:lang="ja_JP"><title type="html">論文メモ：Deep contextualized word representations</title><link href="http://localhost:4000/Note-ELMo/" rel="alternate" type="text/html" title="論文メモ：Deep contextualized word representations" /><published>2019-04-06T00:00:00+09:00</published><updated>2019-04-06T00:00:00+09:00</updated><id>http://localhost:4000/Note-ELMo</id><content type="html" xml:base="http://localhost:4000/Note-ELMo/">&lt;h2 id=&quot;文献情報&quot;&gt;文献情報&lt;/h2&gt;
&lt;p&gt;著者: M. Peters et al.&lt;br /&gt;
所属: Allen Institute for Artificial Intelligence / Paul G. Allen School of Computer Science &amp;amp; Engineering, University of Washington&lt;br /&gt;
出典: NAACL 2018 &lt;a href=&quot;https://aclweb.org/anthology/papers/N/N18/N18-1202/&quot;&gt;(https://aclweb.org/anthology/papers/N/N18/N18-1202/)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;どんな論文か&quot;&gt;どんな論文か？&lt;/h2&gt;
&lt;p&gt;ELMo = Embeddings from Language Modelsの略であり，言語モデルを活用した文脈に応じた単語分散表現: ELMoを提唱した論文．&lt;/p&gt;

&lt;h2 id=&quot;先行研究と比べてどこが凄い&quot;&gt;先行研究と比べてどこが凄い？&lt;/h2&gt;
&lt;p&gt;既存のNLPタスクのモデルの埋め込み層にELMoを追加するだけで，様々なタスクで当時のSoTAを達成した．&lt;/p&gt;

&lt;h2 id=&quot;技術や手法のキモはどこ&quot;&gt;技術や手法のキモはどこ？&lt;/h2&gt;
&lt;p&gt;双方向言語モデルを活用し，隠れ層の重みを重み付き線形和で圧縮する点．&lt;br /&gt;
→ 従来手法では，単に双方向言語モデルの出力層だけを取ってきていた．&lt;/p&gt;

&lt;h2 id=&quot;どうやって有効だと検証した&quot;&gt;どうやって有効だと検証した？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;各種NLPタスクに適用して，そのスコアにより評価．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;議論はある&quot;&gt;議論はある？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;ELMoの中間層が捉えている特徴素について&lt;br /&gt;
→ 著者らによると，ELMoの中間層は低層であればあるほど，&lt;strong&gt;文法的(syntactic)&lt;/strong&gt;な情報を含み，高層の方が，&lt;strong&gt;意味的(semantic)&lt;/strong&gt;な情報を含むとのこと．&lt;br /&gt;
→ 基本的にどのタスクもsyntacticな情報を好む傾向にあるらしい．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;論文の詳細メモ&quot;&gt;論文の詳細メモ&lt;/h2&gt;
&lt;h3 id=&quot;1-順方向言語モデル&quot;&gt;1. 順方向言語モデル&lt;/h3&gt;
&lt;p&gt;トークン数: $N$の単語列: $(t_1, t_2, \dots, t_N)$が与えられたとき，順方向の言語モデルは，単語: $t_k$と単語列: $(t_1, \dots, t_{k-1})$の条件付き確率をモデリングすることで，次のように表される.順方向の言語モデルでは，次の単語: $t_{k+1}$を予測することを目的とする．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(t_1, t_2, ..., t_N) = \prod_{k=1}^N p(t_k | t_1, t_2, \dots, t_{k-1})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;最近の言語モデルでは，文脈非依存な単語表現: $\mathbf{x}_k^{LM}$を単語埋め込みやcharacter-based CNNにより算出してから，L層のLSTMに入力することが多い．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;単語列の位置: $k$において，各LSTM層は，文脈依存な単語表現: $\overrightarrow{\mathbf{h}}_{k, j}^{LM}$（ただし，$1 \leq j \leq L$）を出力する．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\overrightarrow{\mathbf{h}}_{k, L}^{LM}&lt;/script&gt;は，次の単語: $t_{k+1}$をsoftmax層で予測するのに用いられる．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-逆方向言語モデル&quot;&gt;2. 逆方向言語モデル&lt;/h3&gt;
&lt;p&gt;逆方向言語モデルは順方向言語モデルと類似しているが，単語列を逆に処理していく点で異なる．なお，逆方向の言語モデルでは，未来の単語列から一つ前の単語: $t_{k-1}$を予測することを目的とする．つまり，逆方向の言語モデルは次のように定義される．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(t_1, t_2, ..., t_N) = \prod_{k=1}^N p(t_k | t_{k+1}, t_{k+2}, \dots, t_N)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;最終的には，&lt;script type=&quot;math/tex&quot;&gt;\overleftarrow{\mathbf{h}}_{k, L}^{LM}&lt;/script&gt; を求めることで，$t_{k-1}$ をsoftmax層で予測する．&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-双方向言語モデル&quot;&gt;3. 双方向言語モデル&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;通常言語モデルは対数尤度を最大化することで最適化を行う．&lt;br /&gt;
→ 文脈中で出現してほしい単語の確率を最大化するため．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ELMoで使われる双方向言語モデルは次の式の対数尤度を最大化することで学習する．&lt;br /&gt;
→ 文脈非依存な単語表現とソフトマックス層のパラメータ: $\Theta_{x}, \Theta_s$は共有．LSTMのパラメータについてのみ独立．&lt;br /&gt;
→ 従来手法ではパラメータはすべて独立&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{k=1}^{N}(\log p(t_k | t_1, t_2, \dots, t_{k-1}; \Theta_x, \overrightarrow{\Theta}_{LSTM}, \Theta_s) \\+ \log p(t_k | t_{k+1}, t_{k+2}, \dots, t_N; \Theta_x, \overleftarrow{\Theta}_{LSTM}, \Theta_s))&lt;/script&gt;

&lt;h3 id=&quot;4-elmoのパラメータ算出&quot;&gt;4. ELMoのパラメータ算出&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;全てのトークン: $t_k$はL層の双方向言語モデルに対し，2L+1個の特徴量を持つ．&lt;br /&gt;
→ 文脈依存しない単語ベクトル: 1個&lt;br /&gt;
→ 文脈依存のする順方向と逆方向のLSTM: 2L個&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{equation*}
\begin{split}
R_k &amp;= \{x_k^{LM}, \overrightarrow{\mathbf{h}}_{k, j}^{LM}, \overleftarrow{\mathbf{h}}_{k, j}^{LM} | j = 1, \dots, L \}\\
    &amp;= \{\mathbf{h}_{k, j}^{LM} | j=0, \dots, L \}
\end{split}
\end{equation*} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;ELMoを他のタスクに応用するには，Rのすべての要素を一つのベクトル表現に変換する．&lt;br /&gt;
→ 簡単な例だと，一番上の層だけを取ってくるものがある．CoVeやTagLMはこれを採用している．&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{ELMo}_k^{task} = E(R_k; \Theta_e) = \mathbf{h}_{k, L}^{LM}&lt;/script&gt;

&lt;div style=&quot;text-align: center&quot;&gt;ただし，$\mathbf{h}_{k, L}^{LM} = \left[\overrightarrow{\mathbf{h}}_{k, j}^{LM}; \overleftarrow{\mathbf{h}}_{k, j}^{LM}\right]$&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ELMoではより便宜をはかり，重み付き線形和の形で変換する．&lt;br /&gt;
→ $s_j^{task}$はsoftmaxで正規化された重み&lt;br /&gt;
→ $\gamma^{task}$はELMoのベクトル全体をスケーリングするため．チューニングの最適化の観点から必要．&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{ELMo}_k^{task} = \gamma^{task} \sum_{j=0}^L s_j^{task}\mathbf{h}_{k, j}^{LM}&lt;/script&gt;

&lt;h3 id=&quot;5-elmoモデルのnlpタスクへの適用&quot;&gt;5. ELMoモデルのNLPタスクへの適用&lt;/h3&gt;
&lt;p&gt;単に$\mathbf{ELMo}_k^{task}$を入力の埋め込みベクトルとconcatすれば良い．&lt;/p&gt;

&lt;h2 id=&quot;まとめスライド&quot;&gt;まとめスライド&lt;/h2&gt;
&lt;div style=&quot;text-align: center&quot;&gt;&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/hvw0gfJhsc8aWL&quot; width=&quot;510&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&quot; allowfullscreen=&quot;&quot;&gt; &lt;/iframe&gt;&lt;/div&gt;
&lt;div style=&quot;margin-bottom:5px&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;実装&quot;&gt;実装&lt;/h2&gt;
&lt;p&gt;試しにKerasでELMo + BiLSTMを使ってIMDBの分類を行ったので，GitHubにあげました．&lt;br /&gt;
→ &lt;a href=&quot;https://github.com/gucci-j/elmo-imdb&quot;&gt;https://github.com/gucci-j/elmo-imdb&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">文献情報 著者: M. Peters et al. 所属: Allen Institute for Artificial Intelligence / Paul G. Allen School of Computer Science &amp;amp; Engineering, University of Washington 出典: NAACL 2018 (https://aclweb.org/anthology/papers/N/N18/N18-1202/)</summary></entry><entry xml:lang="ja_JP"><title type="html">MatplotlibとseabornによるSelf Attentionの可視化</title><link href="http://localhost:4000/SA-Visualization/" rel="alternate" type="text/html" title="MatplotlibとseabornによるSelf Attentionの可視化" /><published>2019-04-02T00:00:00+09:00</published><updated>2019-04-02T00:00:00+09:00</updated><id>http://localhost:4000/SA-Visualization</id><content type="html" xml:base="http://localhost:4000/SA-Visualization/">&lt;p&gt;Pythonの可視化ライブラリであるseabornとグラフ描画ライブラリのMatplotlibを組み合わせることで，意外と簡単にSelf Attentionの重みを可視化することができる．&lt;/p&gt;

&lt;p&gt;とあるデータセットを用いて実際に可視化した結果が以下の図です．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-02/attention.png&quot; alt=&quot;attentionの可視化結果&quot; /&gt;&lt;/p&gt;

&lt;p&gt;それでは，順を追って簡単に見ていきましょう．
なお，深層学習のフレームワークにはPyTorchを使用し，テキストデータの前処理にはtorchtextを使用しています．&lt;/p&gt;

&lt;h2 id=&quot;1-ダウンロード--インストール&quot;&gt;1. ダウンロード &amp;amp; インストール&lt;/h2&gt;
&lt;p&gt;Matplotlib，seabornをインストールしていない場合は，インストールしましょう．&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install matplotlib
pip install seaborn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2-インポート&quot;&gt;2. インポート&lt;/h2&gt;
&lt;p&gt;本稿ではサーバー上で動作させることを想定しているので，前もって&lt;code class=&quot;highlighter-rouge&quot;&gt;mpl.use('Agg')&lt;/code&gt;を指定することで，描画エラーを回避します．&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-self-attentionの実装&quot;&gt;3. Self Attentionの実装&lt;/h2&gt;
&lt;p&gt;Self Attentionの実装については，&lt;a href=&quot;https://github.com/gucci-j/imdb-classification-gru&quot;&gt;GitHub&lt;/a&gt;にあげている，ソースコード: &lt;code class=&quot;highlighter-rouge&quot;&gt;model_with_self_attention.py&lt;/code&gt;を流用しました．クラス部分を以下に貼ります．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Self_Attention(nn.Module):
    def __init__(self, query_dim):
        # assume: query_dim = key/value_dim
        super(Self_Attention, self).__init__()
        self.scale = 1. / math.sqrt(query_dim)

    def forward(self, query, key, value):
        # query == hidden: (batch_size, hidden_dim * 2)
        # key/value == gru_output: (sentence_length, batch_size, hidden_dim * 2)
        query = query.unsqueeze(1) # (batch_size, 1, hidden_dim * 2)
        key = key.transpose(0, 1).transpose(1, 2) # (batch_size, hidden_dim * 2, sentence_length)

        # bmm: batch matrix-matrix multiplication
        attention_weight = torch.bmm(query, key) # (batch_size, 1, sentence_length)
        attention_weight = F.softmax(attention_weight.mul_(self.scale), dim=2) # normalize sentence_length's dimension

        value = value.transpose(0, 1) # (batch_size, sentence_length, hidden_dim * 2)
        attention_output = torch.bmm(attention_weight, value) # (batch_size, 1, hidden_dim * 2)
        attention_output = attention_output.squeeze(1) # (batch_size, hidden_dim * 2)

        return attention_output, attention_weight.squeeze(1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ソースコード中において，&lt;code class=&quot;highlighter-rouge&quot;&gt;attention_weight&lt;/code&gt;は時系列方向に正規化された重みベクトルとなっています．そのため，このベクトルを可視化することで，各時刻における入力の単語の重要度を可視化できることになります．&lt;br /&gt;
要するに，このソースコードにおいては，可視化には&lt;code class=&quot;highlighter-rouge&quot;&gt;attention_weight&lt;/code&gt;のみを用いれば良いことになります．&lt;/p&gt;

&lt;h2 id=&quot;4-いざ描画&quot;&gt;4. いざ描画&lt;/h2&gt;

&lt;p&gt;ヒートマップの描画には，&lt;code class=&quot;highlighter-rouge&quot;&gt;sns.heatmap()&lt;/code&gt;を使います．詳しい使い方は，&lt;a href=&quot;https://seaborn.pydata.org/generated/seaborn.heatmap.html&quot;&gt;ドキュメント&lt;/a&gt;をご覧ください．&lt;/p&gt;

&lt;p&gt;重要な点としては，ヒートマップ中の各セル内に入力の単語を表示させたいときに，&lt;code class=&quot;highlighter-rouge&quot;&gt;annot&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;string&lt;/code&gt;型のリストを渡すことで，描画できてしまうということです！&lt;/p&gt;

&lt;p&gt;ただし，必ず&lt;strong&gt;リストをNumPyに通すこと&lt;/strong&gt; + &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fmt=''&lt;/code&gt;&lt;/strong&gt;を指定するのを忘れないでください！&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;plt.figure(figsize = (15, 7))
sns.heatmap(attention_weight, annot=np.asarray(itos), fmt='', cmap='Blues')
plt.savefig('./fig/attention_' + str(batch_count) + '.png')
plt.close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;
&lt;p&gt;ソースコードは後日: &lt;a href=&quot;https://github.com/gucci-j/imdb-classification-gru&quot;&gt;GitHub&lt;/a&gt;に追加して公開する予定です．&lt;/p&gt;</content><author><name></name></author><summary type="html">Pythonの可視化ライブラリであるseabornとグラフ描画ライブラリのMatplotlibを組み合わせることで，意外と簡単にSelf Attentionの重みを可視化することができる．</summary></entry><entry xml:lang="ja_JP"><title type="html">論文メモ：Frustratingly Short Attention Spans in Neural Language Modeling</title><link href="http://localhost:4000/Note-Frustratingly/" rel="alternate" type="text/html" title="論文メモ：Frustratingly Short Attention Spans in Neural Language Modeling" /><published>2019-04-01T00:00:00+09:00</published><updated>2019-04-01T00:00:00+09:00</updated><id>http://localhost:4000/Note-Frustratingly</id><content type="html" xml:base="http://localhost:4000/Note-Frustratingly/">&lt;h2 id=&quot;文献情報&quot;&gt;文献情報&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;著者: M. Daniluk et al.&lt;br /&gt;
所属: University College London&lt;br /&gt;
出典: ICLR 2017 &lt;a href=&quot;https://arxiv.org/abs/1702.04521&quot;&gt;(https://arxiv.org/abs/1702.04521)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;この論文の主張&quot;&gt;この論文の主張&lt;/h2&gt;
&lt;hr /&gt;
&lt;ol&gt;
  &lt;li&gt;ニューラル言語モデルのためのkey-valueに基づくAttentionを提案&lt;/li&gt;
  &lt;li&gt;さらにそれを改良したkey-value-predictに基づくAttentionの提案&lt;/li&gt;
  &lt;li&gt;従来のMemory-augumented言語モデルよりも，パープレキシティが小さくなった&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;背景関連研究&quot;&gt;背景・関連研究&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;言語モデルは次に出現する単語を予測する能力を持っている．古典的なNグラムに基づく言語モデルは短文内での単語間の依存関係を捉えることができる．&lt;br /&gt;
一方で，ニューラル言語モデルは，より広範囲な単語間の依存関係を捉えることができる．&lt;/p&gt;

&lt;p&gt;近年のニューラル言語モデルはAttentionに基づくものが多く，より直接的に単語間の関係性を捉えられるようになってきている．&lt;/p&gt;

&lt;p&gt;Attentionを言語モデルに取り入れるには，モデル中の出力ベクトルが以下の複数の役割を同時にこなさなければならない．&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;次の単語を予測するためにある分布をエンコードする役割&lt;/li&gt;
  &lt;li&gt;attentionベクトルを計算するためのベクトルとして振る舞う役割&lt;/li&gt;
  &lt;li&gt;attentionにおいて文脈ベクトルを求めるために使われる役割-&amp;gt;次のトークンを予測する際に文脈を考慮するのを助ける役割&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-01/k-v-p_attention.png&quot; alt=&quot;k-v-p attention&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一つの出力ベクトルに複数の役割を課すことは，モデルを複雑化させる要因となり，学習を難しくすると考えられる．&lt;br /&gt;
したがって，本研究では，上記の三つの役割を別々のベクトルに割り当てることで，モデルを簡単化させることを目指す．&lt;br /&gt;
具体的には，各時刻において出力されるベクトルを3つにするということである．&lt;br /&gt;
論文内ではこれを，key-value-predictベクトルと名付けており，Attentionを含めて，key-value-predict Attentionと名付けている．&lt;/p&gt;

&lt;h2 id=&quot;従来手法-attention-for-neural-language-modeling&quot;&gt;従来手法 (Attention for Neural Language Modeling)&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;(1) &lt;strong&gt;時刻: $t$において，$L$個の出力ベクトルを記憶領域として取る&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*}
    Y_t = [{\bf h}_{t-L}, \dots, {\bf h}_{t-1}] \in \mathbb{R}^{k \times L}
\end{equation*}&lt;/script&gt;

&lt;p&gt;ただし，&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;はLSTMの出力ベクトルの次元を指し，$h_t \in \mathbb{R}^k$は時刻: $t$における出力ベクトルを意味する．&lt;/p&gt;

&lt;p&gt;→ L個に限るのは実用的な問題から: Lはハイパーパラメータ&lt;/p&gt;

&lt;p&gt;(2) &lt;strong&gt;Attentionの重み: $\alpha_t$を計算する&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{equation*}
\begin{split}
\alpha_t &amp;= {\rm softmax}(w^TM_t) \\
M_t &amp;= {\rm tanh}(W^YY_t + (W^hh_t)1^T)
\end{split}
\end{equation*} %]]&gt;&lt;/script&gt;

&lt;p&gt;ただし， $W^Y, W^h \in \mathbb{R}^{k \times k}, w \in \mathbb{R}^k$は学習パラメータである．また，$1 \in \mathbb{R}^L$である．&lt;/p&gt;

&lt;p&gt;→ ここでは時刻: $t$の出力ベクトル: $h_t$とそれ以前のL個の出力ベクトル: $Y_t$がどの程度関係しあっているかを求めている．&lt;br /&gt;
つまりL個のトークンの各重要度を算出している．&lt;/p&gt;

&lt;p&gt;(3) &lt;strong&gt;Attentionベクトルを生成する&lt;/strong&gt;&lt;br /&gt;
上記で算出したAttentionの重みを基に，Attentionベクトルを生成する．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r_t = Y_t\alpha^T&lt;/script&gt;

&lt;p&gt;(4) &lt;strong&gt;Attentionベクトルと元の出力ベクトルを結合する&lt;/strong&gt;&lt;br /&gt;
Concatではなく，以下の式に基づいて非線形に結合する．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_t^* = {\rm tanh}(W^rr_t + W^xh_t)\\&lt;/script&gt;

&lt;p&gt;ただし，$W^r, W^x \in \mathbb{R}^{k \times k}$は学習パラメータである．&lt;/p&gt;

&lt;p&gt;(5) &lt;strong&gt;出力ベクトルを求める&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_t = {\rm softmax}(W^*h_t^* + b)&lt;/script&gt;

&lt;p&gt;ただし，$W^* \in \mathbb{R}^{|V| \times k}$であり，$b \in \mathbb{R}^{|V|}$である．&lt;br /&gt;
ともに学習パラメータである．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-01/attention.png&quot; alt=&quot;ふつうのAttentionモデル&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;提案手法&quot;&gt;提案手法&lt;/h2&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;key-value-attention&quot;&gt;Key-value attention&lt;/h3&gt;
&lt;p&gt;key-value Attentionでは，出力ベクトルをkeyとvalueに分割する．&lt;br /&gt;
具体的には，時刻: $t$における出力ベクトルを以下のように定義し直す．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_t = [k_t, v_t] \in \mathbb{R}^{2k}&lt;/script&gt;

&lt;p&gt;また，　$h_t$が関与する式を書き直すと，以下のようになる．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{split}
M_t &amp;= {\rm tanh}(W^Y[k_{t-L}, \dots, k_{t-1}] + (W^hk_t)1^T) \\
r_t &amp;= [v_{t-L}, \dots, v_{t-1}]\alpha^T \\
h_t^* &amp;= {\rm tanh}(W^rr_t + W^xv_t)
\end{split} %]]&gt;&lt;/script&gt;

&lt;p&gt;なお，上記以外の式は前章と同じである．&lt;/p&gt;

&lt;p&gt;→ ここで，$k$は検索キーとしての役割を果たしており，$v$はその中身のデータを表していると考えるとわかりやすいかもしれない．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-01/k-v_attention.png&quot; alt=&quot;key-value attention&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;key-value-predict-attention&quot;&gt;Key-value-predict attention&lt;/h3&gt;
&lt;p&gt;key-value attentionにおいても，valueが複数回使われていることがわかる．&lt;br /&gt;
そこで，valueをさらに分割し，key-value-predict型のAttentionを考案した．&lt;/p&gt;

&lt;p&gt;→ keyはattentionの重みを計算するのにのみ用いられ，valueは文脈表現をエンコードするのに使われ，predictは次のトークンの分布をエンコードするのに用いられる．&lt;br /&gt;
→ 完全分業制が達成されていることがわかる．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_t = [k_t, v_t, p_t] \in \mathbb{R}^{3k}　\\
h_t^* = {\rm tanh}(W^rr_t + W^xp_t)&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-01/k-v-p_attention.png&quot; alt=&quot;k-v-p attention&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;実験結果&quot;&gt;実験結果&lt;/h2&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;評価指標&quot;&gt;評価指標&lt;/h3&gt;
&lt;h4 id=&quot;パープレキシティ&quot;&gt;パープレキシティ&lt;/h4&gt;
&lt;p&gt;参考: &lt;a href=&quot;http://www.jnlp.org/lab/graduates/okada/nlp/term/entropy&quot;&gt;http://www.jnlp.org/lab/graduates/okada/nlp/term/entropy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;パープレキシティ(perplexity)とは，言語モデルにおいてモデルの複雑性を評価するのに使われる指標である． &lt;br /&gt;
パープレキシティは2のクロスエントロピー乗で定義され，一般に小さいほど良いモデルであるとされる．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Perplexity = 2^{-\frac{1}{N}\sum_i^{N}\log P(w_i)}&lt;/script&gt;

&lt;p&gt;→ ここでの$P(w_i)$は言語モデルの単語出現確率を表している．&lt;br /&gt;
→ パープレキシティは単語の分岐数を意味しており，ある単語に対してそれに続く単語の平均候補数も意味している．&lt;/p&gt;

&lt;p&gt;つまり，複雑なモデルであるほど，平均候補数が増加するため，パープレキシティは大きくなるといえる．&lt;/p&gt;

&lt;h3 id=&quot;評価結果&quot;&gt;評価結果&lt;/h3&gt;
&lt;p&gt;提案手法： key-Value-Predictのパープレキシティが有意に小さいことがわかる．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-01/result1.png&quot; alt=&quot;実験結果1&quot; /&gt;
&lt;img src=&quot;../resources/2019-04-01/result2.png&quot; alt=&quot;実験結果2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(a)の図から，提案手法: key-value-predict attentionのおかげで，広範囲な文脈を考慮出来るようになっていることがわかる．&lt;br /&gt;
(b)の図から，より広範な文脈を考慮したとしても，パープレキシティが大幅に改善することは期待できないということが読み取れる．
&lt;img src=&quot;../resources/2019-04-01/weight.png&quot; alt=&quot;重み&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;議論&quot;&gt;議論&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;Attentionを用いた言語モデルによって，従来手法よりもパープレキシティを改善することができた．&lt;br /&gt;
しかし，あまりにも長い文脈を考慮することは，パープレキシティの改善には得策ではないこともわかった．&lt;/p&gt;

&lt;p&gt;Future workとしては局所的な文脈の内容を考慮しないで，その背景にあるより大域的に関係する文脈を考慮できるような手法を考えることが挙げられる．&lt;/p&gt;

&lt;h2 id=&quot;次に読むべき論文は&quot;&gt;次に読むべき論文は？&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;Memory networksとか？&lt;br /&gt;
→ key-valueの概念を初めて導入したらしい．&lt;/p&gt;</content><author><name></name></author><summary type="html">文献情報 著者: M. Daniluk et al. 所属: University College London 出典: ICLR 2017 (https://arxiv.org/abs/1702.04521)</summary></entry><entry xml:lang="ja_JP"><title type="html">はじめに</title><link href="http://localhost:4000/Introduction/" rel="alternate" type="text/html" title="はじめに" /><published>2019-03-31T00:00:00+09:00</published><updated>2019-03-31T00:00:00+09:00</updated><id>http://localhost:4000/Introduction</id><content type="html" xml:base="http://localhost:4000/Introduction/">&lt;p&gt;当サイトでは，機械学習と自然言語処理に関するトピックをブログ形式で扱います．&lt;br /&gt;
連絡等は，メールか&lt;a href=&quot;https://twitter.com/_gucciiiii&quot;&gt;Twitter&lt;/a&gt;のDMにてお願いいたします．&lt;/p&gt;

&lt;p&gt;当サイトのご利用規約やプライバシーポリシーに関しては，&lt;a href=&quot;/privacy/&quot;&gt;こちら&lt;/a&gt;をご覧ください．&lt;/p&gt;</content><author><name></name></author><summary type="html">当サイトでは，機械学習と自然言語処理に関するトピックをブログ形式で扱います． 連絡等は，メールかTwitterのDMにてお願いいたします．</summary></entry></feed>