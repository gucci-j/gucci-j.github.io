<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-05-06T22:56:16+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">きままにNLP</title><subtitle>A Technical Blog about NLP and ML</subtitle><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（学習テクニック編）</title><link href="http://localhost:4000/DL-Intro-4/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（学習テクニック編）" /><published>2019-05-03T00:00:00+09:00</published><updated>2019-05-03T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-4</id><content type="html" xml:base="http://localhost:4000/DL-Intro-4/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;このシリーズでは、深層学習の入門書として有名な、「ゼロから作るDeep Learning」（以下、ゼロから〜）と同時並行で、フレームワークを学習し、その定着を目指します。&lt;/p&gt;

&lt;p&gt;前回までは、Kerasを活用して実際にニューラルネットワークを学習させて、そのモデルを活用して推論までできるようになりました。今回は、ゼロから〜の6章に対応する種々の学習テクニックについて扱います。幅広いトピックを扱うので、理解するのに時間がかかるかと思いますが、どれもモデルの性能と安定性を向上させるために、重要なものばかりです。したがって、一つ一つ理解できるまでじっくりと取り組むことをオススメします。&lt;/p&gt;

&lt;p&gt;それでは、まずはパラメータの最適化アルゴリズムについての話題から入っていきましょう！&lt;/p&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;「ゼロからKeras」シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：畳み込みニューラルネットワーク編&lt;/p&gt;
&lt;/div&gt;

&lt;script async=&quot;&quot; src=&quot;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block; text-align:center;&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1838422896597988&quot; data-ad-slot=&quot;7676908062&quot;&gt;&lt;/ins&gt;
&lt;script&gt;
     (adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-最適化アルゴリズム&quot;&gt;1. 最適化アルゴリズム&lt;/h2&gt;

&lt;p&gt;ゼロから〜で紹介があったように、ニューラルネットワークに対して適用される最適化アルゴリズムはたくさん存在し、モデルに応じて使い分けることが、その性能を引き出すために非常に重要となります。&lt;/p&gt;

&lt;p&gt;ここでは、ゼロから〜のP177に登場した、「SGD、AdaGrad、Adam」に加え、Adadelta、Nadam、の5つの最適化アルゴリズムを、Fashion-MNISTデータセットの分類実験を通して、比較してみようと思います。&lt;/p&gt;

&lt;h3 id=&quot;11-fashion-mnistデータセット&quot;&gt;1.1 Fashion-MNISTデータセット&lt;/h3&gt;
&lt;p&gt;本稿で用いるFashion-MNISTデータセットは、MNISTデータセットと互換性のあるデータセットです。データセットの内容は手書き数字ではなく、靴やズボン、カバン、服などファッションに関係のあるものとなっています。&lt;/p&gt;

&lt;p&gt;Fashion-MNISTは、MNISTの分類タスクが「簡単過ぎること」などを理由に、それを置き換える目的で作成されたデータセットです。&lt;/p&gt;

&lt;p&gt;試しに1枚データセットの画像を表示させてみましょう。下記のソースコードを動作させてみてください。画像の表示は、&lt;code class=&quot;highlighter-rouge&quot;&gt;imshow&lt;/code&gt;メソッドを使えば簡単にできます。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.datasets import fashion_mnist
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

plt.figure()
plt.imshow(x_train[0], cmap='gray')
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/fm_example.png&quot; alt=&quot;Fashion-MNISTの内容の一例&quot; style=&quot;width: 300px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;靴らしき画像が表示されているのが確認できますね。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist&quot;&gt;（Fashion-MNISTのGitHubレポジトリ ）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/datasets/&quot;&gt;（KerasにおけるFashion-MNISTデータセットの説明）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;12-モデルの実装&quot;&gt;1.2 モデルの実装&lt;/h3&gt;
&lt;p&gt;本実験に用いるモデルの構造とハイパーパラメータは、ゼロから〜の公式レポジトリにある&lt;a href=&quot;https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch06/optimizer_compare_mnist.py&quot;&gt;ソースコード&lt;/a&gt;に基づきます。実装自体は前回までのソースコードをほぼ流用して実現できるので、ここでは説明を省略します。ソースコード自体は、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;GitHub&lt;/a&gt;の&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_optimizer.py&lt;/code&gt;にて公開してあります。&lt;/p&gt;

&lt;p&gt;なお、自力で実装をしてみたい方は、公式レポジトリを見つつ、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/blob/master/chapter4%265/two_nn.py&quot;&gt;前回のソースコード&lt;/a&gt;をベースにすることをおすすめします。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: ゼロから〜のP176〜P178&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_optimizer.py）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/optimizers/#keras&quot;&gt;（Kerasで利用可能な最適化アルゴリズムについて）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;13-モデルの比較&quot;&gt;1.3 モデルの比較&lt;/h3&gt;
&lt;p&gt;1.2で実装した5層ニューラルネットワークを実行させると、以下のような結果が得られました。&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/loss.png&quot; alt=&quot;最適化アルゴリズム別の損失関数の値の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;図から、SGDとAdadeltaを用いたモデルは、Adam/Nadam/Adagradを用いたモデルよりも収束が遅いことがわかります。また、この実験においては、Nadamが5つの最適化アルゴリズムの中で、最も収束の速いアルゴリズムであることがわかりました。&lt;/p&gt;

&lt;h2 id=&quot;2-重みの初期化&quot;&gt;2. 重みの初期化&lt;/h2&gt;

&lt;p&gt;Kerasにおける重みの初期化は特に指定しない限り、ブラックボックス的に処理されます。つまり、レイヤー定義時に重みの初期化方法を指定しなければ、各層の所定の初期化方法が自動的に適用されます。&lt;/p&gt;

&lt;p&gt;ここでは、重みの初期化をこちらから事前に指定することで、フレームワーク（Keras）を活用したときの、初期化手法による収束速度の違いを検証していきます。&lt;/p&gt;

&lt;h3 id=&quot;21-公式ドキュメントを見てみる&quot;&gt;2.1 公式ドキュメントを見てみる&lt;/h3&gt;
&lt;p&gt;ここで、全結合層: &lt;code class=&quot;highlighter-rouge&quot;&gt;Dense&lt;/code&gt;レイヤーの公式ドキュメントを確認してみましょう。下記がドキュメントの一部抜粋になります。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform',
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel_initializer&lt;/code&gt;を見ると、初期化の手法として、Glorotの一様分布（Xavierの一様分布）が用いられていることがわかります。&lt;/p&gt;

&lt;p&gt;初期化手法を変更したい場合には、すでに定義されている手法を&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel_initializer&lt;/code&gt;に引数として与えるか、新たに手法自体を定義することもできます。新たに定義する方法については、公式ドキュメントをご覧ください。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/core/#dense&quot;&gt;（KerasにおけるDenseレイヤーのドキュメント）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/initializers/&quot;&gt;（Kerasにおける初期化手法についてのドキュメント）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;22-初期化手法による収束速度の違い&quot;&gt;2.2 初期化手法による収束速度の違い&lt;/h3&gt;
&lt;p&gt;では、前章で実装した5層ニューラルネットワークを活用して、初期化手法による収束速度の違いをKerasでも検証していきましょう。&lt;/p&gt;

&lt;p&gt;初期化手法には、デフォルトのXaiverの初期値とHeの初期値、標準偏差が0.01の正規分布の3つをそれぞれ用います。また、ゼロから〜のP184〜P186の実験設定と合わせるため、中間層の活性化関数を&lt;code class=&quot;highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;から&lt;code class=&quot;highlighter-rouge&quot;&gt;relu&lt;/code&gt;に変更します。ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;GitHub&lt;/a&gt;の&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_initializer.py&lt;/code&gt;より入手できます。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_initializer.py&lt;/code&gt;を動作させた結果、以下の図のような結果が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/loss_init.png&quot; alt=&quot;初期化手法別の損失関数の値の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;図より、やはり活性化関数にReLUを用いる場合には、Heの一様分布による初期化が最も適していることがわかりました。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP184〜P186&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_initializer.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;script async=&quot;&quot; src=&quot;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;!-- 記事内広告2 --&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block&quot; data-ad-client=&quot;ca-pub-1838422896597988&quot; data-ad-slot=&quot;1400355899&quot; data-ad-format=&quot;auto&quot; data-full-width-responsive=&quot;true&quot;&gt;&lt;/ins&gt;
&lt;script&gt;
     (adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-正規化正則化&quot;&gt;3. 正規化・正則化&lt;/h2&gt;

&lt;p&gt;以下、4章と5章では、それぞれ正規化と正則化について扱います。その前に、巷で誤用しがちな、機械学習における正規化と正則化の意味について確認しておきましょう。&lt;/p&gt;

&lt;h3 id=&quot;31-正規化&quot;&gt;3.1 正規化&lt;/h3&gt;
&lt;p&gt;機械学習における正規化は、「&lt;strong&gt;データをある範囲内にスケールすること&lt;/strong&gt;」を意味します。標準化とも呼ばれることがありますが、標準化と正規化では厳密には意味合いが異なります。標準化: standardization は、「平均が0、分散が1」になるようにデータをスケールすることを指します。なお、この用語は統計学で用いられることが多いようです。&lt;/p&gt;

&lt;p&gt;したがって、正規化は標準化を抽象化したような意味合いを持ちます。&lt;/p&gt;

&lt;h3 id=&quot;32-正則化&quot;&gt;3.2 正則化&lt;/h3&gt;
&lt;p&gt;正則化は過学習（過適応）を防ぐためにある種のペナルティを課すことを意味します。Weight Decayがその一例となります。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/regularizers/&quot;&gt;（Kerasにおける正則化の利用方法について）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;4-バッチ正規化&quot;&gt;4. バッチ正規化&lt;/h2&gt;

&lt;p&gt;バッチ正規化は、入力データを平均値が0で分散が1となる分布に変換する手法のことを指します。バッチ正規化を適用することで、モデルの収束を高速化できるほか、重みの初期化手法に対してかなり頑健になります。&lt;/p&gt;

&lt;p&gt;では、Kerasでバッチ正規化の実験をしてみましょう。&lt;/p&gt;

&lt;h3 id=&quot;41-モデルの実装&quot;&gt;4.1 モデルの実装&lt;/h3&gt;
&lt;p&gt;Kerasにおいて、バッチ正規化は&lt;code class=&quot;highlighter-rouge&quot;&gt;BatchNormalization&lt;/code&gt;レイヤーを活用することで実装できます。&lt;/p&gt;

&lt;p&gt;ここでは、2章のモデルの「全結合層と活性化層の間」にバッチ正規化層を追加する形で実装します。また、重みの初期化は「標準偏差が0.01の正規分布」により行います。&lt;/p&gt;

&lt;p&gt;なお、2章で確認したように、この重み初期化では通常学習は全く進行しません。つまり、バッチ正規化を適用することで、どの程度初期化手法に対して頑健になるかを見てみます。&lt;/p&gt;

&lt;p&gt;Kerasにおけるバッチ正規化の適用例は以下のようになります。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_hidden = Dense(hidden_dim, kernel_initializer=_init)(_hidden)
_hidden = BatchNormalization()(_hidden)
_hidden = Activation('relu')(_hidden)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/&quot;&gt;GitHub&lt;/a&gt;より入手できます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/normalization/&quot;&gt;（KerasにおけるBatch Normalizationについて）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_batch_norm.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;42-バッチ正規化の有無による分類精度の比較&quot;&gt;4.2 バッチ正規化の有無による分類精度の比較&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_batch_norm.py&lt;/code&gt;を動作させた結果、以下の図のような結果が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_bn.png&quot; alt=&quot;バッチ正規化の有無による分類精度の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;図より、バッチ正規化をモデルに適用することで、かなり適当な重みの初期化を行っても、きちんと学習してくれることがわかります！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP186〜P189&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;5-過学習を防ぐためのテクニック&quot;&gt;5. 過学習を防ぐためのテクニック&lt;/h2&gt;

&lt;p&gt;ここでは、過学習を防ぐための手法の一例として、ゼロから〜でも扱われていた、Weight decayとドロップアウトに加え、Early Stoppingついても扱います。前章までと同様にKerasでテストモデルを実装し、それぞれの手法の効果を検証します。&lt;/p&gt;

&lt;h3 id=&quot;51-weight-decay&quot;&gt;5.1 Weight decay&lt;/h3&gt;
&lt;h4 id=&quot;511-kerasにおけるweight-decayの適用方法&quot;&gt;5.1.1 KerasにおけるWeight decayの適用方法&lt;/h4&gt;

&lt;p&gt;KerasにおけるWeight decayは、各レイヤーの引数に存在する、&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel_regularizer&lt;/code&gt;に対して利用したい正則化手法を与えることで利用できます。&lt;/p&gt;

&lt;p&gt;ここでは、4章で実装したバッチ正規化ありのモデルにweight decayを適用することで、過学習が軽減するか検証していきます。&lt;/p&gt;

&lt;p&gt;Weight decayの簡単な適用例は以下のようになります。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras import regularizers
_wd = regularizers.l2(0.1)

_hidden = Dense(hidden_dim, kernel_initializer=_init, kernel_regularizer=_wd)(_hidden)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;GitHub&lt;/a&gt;にある、&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_weight_decay.py&lt;/code&gt;となります。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/regularizers/&quot;&gt;（Kerasにおける正則化の利用方法について）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_weight_decay.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;512-weight-decayの適用結果&quot;&gt;5.1.2 Weight decayの適用結果&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_weight_decay.py&lt;/code&gt;を動作させた結果、以下のような図が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 0 0 10px 0;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_wd.png&quot; alt=&quot;Weight decayありのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜Weight decayありのときの分類精度の推移＞
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_wo_wd.png&quot; alt=&quot;Weight decay無しのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜Weight decayなしのときの分類精度の推移＞
&lt;/div&gt;

&lt;p&gt;図より、Weigth decayの有無を問わず、テスト精度はかなり乱高下していることがわかります。一方で、訓練精度については、Weight decayを用いることで、過学習が抑制されていることがわかります。&lt;/p&gt;

&lt;h3 id=&quot;52-ドロップアウト&quot;&gt;5.2 ドロップアウト&lt;/h3&gt;
&lt;h4 id=&quot;521-ドロップアウトの実装&quot;&gt;5.2.1 ドロップアウトの実装&lt;/h4&gt;

&lt;p&gt;Kerasにおいて、ドロップアウトは&lt;code class=&quot;highlighter-rouge&quot;&gt;Dropout&lt;/code&gt;レイヤーを活用することで実装できます。&lt;/p&gt;

&lt;p&gt;ドロップアウトの適用例は以下のようになります。&lt;br /&gt;
下記の例では、ドロップアウト率（入力のユニットを消去する割合）を、引数: &lt;code class=&quot;highlighter-rouge&quot;&gt;rate&lt;/code&gt;に渡しています。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_hidden = Dense(hidden_dim, activation='relu')(_hidden)
_hidden = Dropout(rate=dpout_rate)(_hidden)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;5層ニューラルネットワークでドロップアウトの効果を検証したソースコードは、&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_dropout.py&lt;/code&gt;として、GitHubに置いてあります。では、この実験結果について次項で見ていきます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/core/#dropout&quot;&gt;（KerasにおけるDropoutの説明）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_dropout.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;522-ドロップアウトの適用結果&quot;&gt;5.2.2 ドロップアウトの適用結果&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_dropout.py&lt;/code&gt;を動作させた結果、以下のような図が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 0 0 10px 0;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_dpout.png&quot; alt=&quot;ドロップアウトありのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜ドロップアウトありのときの分類精度の推移＞
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_wo_dpout.png&quot; alt=&quot;ドロップアウト無しのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜ドロップアウトなしのときの分類精度の推移＞
&lt;/div&gt;

&lt;p&gt;図から、ドロップアウトを適用したモデルは、ドロップアウトを適用しないモデルよりも、過学習を抑えられていることがわかります。&lt;/p&gt;

&lt;h3 id=&quot;53-early-stopping&quot;&gt;5.3 Early Stopping&lt;/h3&gt;
&lt;p&gt;Early Stoppingとは、その名の通り学習を早期に終了させてしまうというものです。つまり、過学習が起きる寸前 or 発生したらすぐに学習を終了させることで、ベストなモデルを手に入れようという試みになります。これにより、無駄な計算機リソースの消費防止にも繋がります。&lt;/p&gt;

&lt;h4 id=&quot;531-kerasにおけるearly-stoppingの適用方法&quot;&gt;5.3.1 KerasにおけるEarly Stoppingの適用方法&lt;/h4&gt;

&lt;p&gt;KerasにおいてEarly Stoppingは、&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.callbacks.EarlyStopping&lt;/code&gt;により定義されています。使い方は、&lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;メソッド内で、引数: &lt;code class=&quot;highlighter-rouge&quot;&gt;callbacks&lt;/code&gt;に、&lt;code class=&quot;highlighter-rouge&quot;&gt;EarlyStopping&lt;/code&gt;を渡せばよいです。&lt;code class=&quot;highlighter-rouge&quot;&gt;EarlyStopping&lt;/code&gt;関数の主な引数の説明は以下の表の通りです。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;引数&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;説明&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;monitor&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;何を基準に学習を早期終了させるかを指定します。&lt;br /&gt;デフォルトは&lt;code class=&quot;highlighter-rouge&quot;&gt;val_loss&lt;/code&gt;になっています。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;patience&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;何エポックの間、監視値: &lt;code class=&quot;highlighter-rouge&quot;&gt;monitor&lt;/code&gt;に変化がないことを許容するかを指定します。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;verbose&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;学習中にEarlyStoppingが適用されたことを明示的に表示するかしないかを指定します。&lt;br /&gt;デフォルトは0（表示しない）です。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Early Stoppingの簡単な適用例は以下のようになります。この例では、2エポックの間、テストデータに対する損失関数の値に改善が見られないと、学習が停止するように設定されています。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;early_stopping = EarlyStopping(patience=2, verbose=1)

model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test), callbacks=[early_stopping])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/callbacks/#earlystopping&quot;&gt;（KerasにおけるEarly Stoppingについて）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;532-early-stoppingの適用結果&quot;&gt;5.3.2 Early Stoppingの適用結果&lt;/h4&gt;

&lt;p&gt;5層ニューラルネットワークでEarly Stoppingの効果を検証したソースコードは、GitHubに&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_early_stopping.py&lt;/code&gt;として置いてあります。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_early_stopping.py&lt;/code&gt;を動作させた結果、以下のような図が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 0 0 10px 0;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_es.png&quot; alt=&quot;Early Stoppingありのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜Early Stoppingありのときの分類精度の推移＞
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_wo_es.png&quot; alt=&quot;Early Stopping無しのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜Early Stopping無しのときの分類精度の推移＞
&lt;/div&gt;

&lt;p&gt;図より、Early Stoppingを適用したときには、40エポックで学習が停止し、過学習している様子は読み取れません。一方で、Early Stoppingを適用しなかったときには、60エポックあたりから過学習の傾向が読み取れます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_early_stopping.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;今回は様々な学習のテクニックについて、実際にKerasでモデルを実装し、その効果を検証してきました。次回は、畳み込みニューラルネットワークについて扱います。&lt;/p&gt;

&lt;p&gt;なお、このシリーズは次回で完結予定です。&lt;/p&gt;

&lt;p&gt;本稿で扱わなかったものの、ゼロから〜で紹介されている、「ハイパーパラメータの検証」については、今後「ハイパーパラメータの最適化 &amp;amp; 交差分割検証」をテーマに別の投稿で詳しく紹介する予定です！&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/&quot;&gt;GitHub&lt;/a&gt;より入手できます。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに</summary></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（ニューラルネットワークの学習編）</title><link href="http://localhost:4000/DL-Intro-3/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（ニューラルネットワークの学習編）" /><published>2019-04-26T00:00:00+09:00</published><updated>2019-04-26T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-3</id><content type="html" xml:base="http://localhost:4000/DL-Intro-3/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;このシリーズでは、深層学習の入門書として有名な、「ゼロから作るDeep Learning」（以下、ゼロから〜）と同時並行で、フレームワークを学習し、その定着を目指します。&lt;/p&gt;

&lt;p&gt;前回までは、3層のニューラルネットワークをKerasで実装し、推論処理のみを扱ってきました。今回からは、ゼロから〜の4章と5章に対応する、ニューラルネットワークの学習にとりかかります。また、同時に実験結果の簡単な可視化方法についても触れていきます。&lt;/p&gt;

&lt;p&gt;では、２層のニューラルネットワークを題材にMNISTの分類モデルをKerasで実装し、学習させてみましょう！&lt;/p&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;「ゼロからKeras」シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：畳み込みニューラルネットワーク編&lt;/p&gt;
&lt;/div&gt;

&lt;script async=&quot;&quot; src=&quot;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block; text-align:center;&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1838422896597988&quot; data-ad-slot=&quot;7676908062&quot;&gt;&lt;/ins&gt;
&lt;script&gt;
     (adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-プロジェクトの作成&quot;&gt;1. プロジェクトの作成&lt;/h2&gt;

&lt;p&gt;はじめに、２層ニューラルネットワーク用のプロジェクトを作成してください。&lt;/p&gt;

&lt;p&gt;以下、本投稿では&lt;code class=&quot;highlighter-rouge&quot;&gt;two_nn.py&lt;/code&gt;を作成するものとして進めます。&lt;/p&gt;

&lt;h2 id=&quot;2-実装&quot;&gt;2. 実装&lt;/h2&gt;

&lt;h3 id=&quot;21-モデルの概要&quot;&gt;2.1 モデルの概要&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;今回実装するモデルの概要図を以下に示します。実装の参考にしてください。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MNISTデータセットの分類を行うモデルを学習させるので、出力はクラスの数に合わせて10次元のベクトルとなっています。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-26/two_layer_nn.png&quot; alt=&quot;2層ニューラルネットワークの概念図&quot; style=&quot;width: 450px;&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;22-モデルの実装&quot;&gt;2.2 モデルの実装&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜の第4章に対応する2層ニューラルネットワークをKerasで実装していきます。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;モデルの実装は前回とあまり変わらないので、以下に一気に進めてしまいます。&lt;br /&gt;
復習として、ソースコードを読んで理解できるかを確認すると良いと思います。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;モデルのパラメータ等は全てゼロから〜のP117〜122に基づいています。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;パラメータ&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;img_shape&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output_dim&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;モデルを定義する&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 784)               0
_________________________________________________________________
dense_1 (Dense)              (None, 100)               78500
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1010
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;23-データの読み込み&quot;&gt;2.3 データの読み込み&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;前回と同様にMNISTデータセットを読み込み、前処理（正規化、データの整形）を行います。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;前回との相違点としては、ラベルデータを学習のためにone-hotベクトルに変換させる点です。&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;one-hotベクトル化は、&lt;code class=&quot;highlighter-rouge&quot;&gt;to_categorical&lt;/code&gt;を用いることで行えます。 &lt;br /&gt;
  引数は変換元リストとクラス数です。戻り値は変換後のリストです。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# データを読み込む
from keras.datasets import mnist
from keras.utils import to_categorical

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)
x_train = x_train.astype('float') / 255.
x_test = x_test.astype('float') / 255.

print(f'Before: {y_train.shape}')
y_train = to_categorical(y_train, num_classes=output_dim)
print(f'After: {y_train.shape}')
print(f'y_train[0]: {y_train[0]}')
y_test = to_categorical(y_test, num_classes=output_dim)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Before: (60000,)
y_train[0]: 5
After: (60000, 10)
y_train[0]: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;しっかりと、ラベルがone-hotベクトルに変換されていることが確認できます。&lt;/p&gt;

&lt;h3 id=&quot;24-学習の設定&quot;&gt;2.4 学習の設定&lt;/h3&gt;
&lt;p&gt;ここからが本格的に新しい部分になります。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;設計したモデルで学習を実行できるようにするために、「&lt;strong&gt;損失関数&lt;/strong&gt;」と「&lt;strong&gt;最適化アルゴリズム&lt;/strong&gt;」を設定します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;損失関数と最適化アルゴリズムの設定は、&lt;code class=&quot;highlighter-rouge&quot;&gt;compile&lt;/code&gt;メソッドで行えます。
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;ゼロから〜の4章の実装では、損失関数にクロスエントロピー、最適化アルゴリズムに確率的勾配降下法が用いられています。&lt;br /&gt;
したがって、本実装でも&lt;code class=&quot;highlighter-rouge&quot;&gt;loss&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;'categorical_crossentropy'&lt;/code&gt;を指定し、&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;SGD(lr=learning_rate)&lt;/code&gt;を指定します。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;ゼロから〜で使われている学習率は&lt;code class=&quot;highlighter-rouge&quot;&gt;0.1&lt;/code&gt;であるため、Kerasのデフォルト値0.01と異なります。そのため、&lt;code class=&quot;highlighter-rouge&quot;&gt;SGD&lt;/code&gt;に学習率を渡す必要があります。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;評価関数&lt;/strong&gt;の設定も行います。&lt;br /&gt;
ゼロから〜のP121では、認識精度を評価関数としているので、&lt;code class=&quot;highlighter-rouge&quot;&gt;compile&lt;/code&gt;メソッドの引数: &lt;code class=&quot;highlighter-rouge&quot;&gt;metrics&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;['accuracy']&lt;/code&gt;を指定します。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.optimizers import SGD
model.compile(optimizer=SGD(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/losses/&quot;&gt;（Kerasで利用可能な損失関数について）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/optimizers/&quot;&gt;（Kerasで利用可能な最適化アルゴリズムについて）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/metrics/&quot;&gt;（Kerasにおける評価関数について）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) Kerasをはじめとする深層学習フレームワークでは、ユーザが順伝播の計算グラフを構築すると、フレームワークが自動的に逆伝播用の処理をブラックボックス的に行ってくれます。
したがって、ゼロから〜の5章の部分は、フレームワーク使用時には実装する必要がありません。（自分でレイヤーを設計することがない限り。）&lt;/p&gt;

&lt;h2 id=&quot;3-モデルの学習&quot;&gt;3. モデルの学習&lt;/h2&gt;

&lt;p&gt;それでは、モデルの学習を進めていきましょう。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;モデルの学習は、&lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;メソッドで行います。&lt;br /&gt;
以下に各引数について簡単に対応表を示します。&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;引数&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;説明&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;訓練データを指定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;訓練データに対応するラベルデータ（正解ラベル）を指定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;batch_size&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;ミニバッチのサイズを指定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;epochs&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;エポック数（学習回数）を指定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;verbose&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;学習進捗をどのように表示するか設定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;validation_data&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;テストデータを指定します&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;メソッドの戻り値は、&lt;code class=&quot;highlighter-rouge&quot;&gt;History&lt;/code&gt;オブジェクトになっています。&lt;br /&gt;
この戻り値を活用することで、損失関数や認識精度のプロットができます。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;validation_data&lt;/code&gt;にテストデータを与えることで、エポックごとにモデルのテスト精度を測ることができます。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/models/model/#fit&quot;&gt;（Kerasのfitメソッドにおける引数と戻り値の説明）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;epochs = 17
_results = model.fit(x=x_train, y=y_train, batch_size=100, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Epoch 1/17
60000/60000 [==============================] - 2s 31us/step - loss: 0.8805 - acc: 0.7994
Epoch 2/17
60000/60000 [==============================] - 2s 27us/step - loss: 0.4102 - acc: 0.8907
~~~
~~~
Epoch 17/17
60000/60000 [==============================] - 2s 27us/step - loss: 0.1771 - acc: 0.9497
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;script async=&quot;&quot; src=&quot;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;!-- 記事内広告2 --&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block&quot; data-ad-client=&quot;ca-pub-1838422896597988&quot; data-ad-slot=&quot;1400355899&quot; data-ad-format=&quot;auto&quot; data-full-width-responsive=&quot;true&quot;&gt;&lt;/ins&gt;
&lt;script&gt;
     (adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-学習結果の表示&quot;&gt;4. 学習結果の表示&lt;/h2&gt;

&lt;p&gt;ゼロから〜のP119とP121では、それぞれ損失関数の値と認識精度の推移を図にしているので、ここでも実際に図にしてみましょう！&lt;/p&gt;

&lt;h3 id=&quot;41-損失関数の値の推移&quot;&gt;4.1 損失関数の値の推移&lt;/h3&gt;
&lt;p&gt;Pythonの図表描画ライブラリである、Matplotlibを活用して、損失関数の値の推移を図にします。&lt;/p&gt;

&lt;h4 id=&quot;411-matplotlibのインストール&quot;&gt;4.1.1 Matplotlibのインストール&lt;/h4&gt;

&lt;p&gt;Matplotlibをインストールしていない方は、インストールしましょう。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install matplotlib
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;（&lt;strong&gt;注意&lt;/strong&gt;）macOSでMatplotlibをインポートすると、バックエンドの問題でエラーが発生することがあります。その場合は、下記を参照してバックエンドを書き換えてください。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://qiita.com/Gen6/items/78d83d117ef67e0d53c2&quot;&gt;（Matplotlibでインポートエラーが出るときの対処法）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;412-historyオブジェクトの中身&quot;&gt;4.1.2 Historyオブジェクトの中身&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;メソッドの戻り値は、&lt;code class=&quot;highlighter-rouge&quot;&gt;History&lt;/code&gt;オブジェクトであると前章で紹介しました。&lt;br /&gt;
実験結果を可視化するためにも、&lt;code class=&quot;highlighter-rouge&quot;&gt;History&lt;/code&gt;オブジェクトの中身を確認しておきましょう。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(f'Keys: {_results.history.keys()}')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Keys: dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;このように、損失関数の値と認識精度の結果が訓練・テストデータともに格納されていることがわかります。&lt;/p&gt;

&lt;h4 id=&quot;413-プロットしてみる&quot;&gt;4.1.3 プロットしてみる&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;History&lt;/code&gt;オブジェクトから訓練時とテスト時の損失関数の値のリスト受け取り、それらをプロットします。&lt;/p&gt;

&lt;p&gt;一連のソースコードを下記に示します。&lt;br /&gt;
なお、Matplotlibの詳しい使い方については、&lt;a href=&quot;https://matplotlib.org/tutorials/index.html&quot;&gt;公式チュートリアル&lt;/a&gt;をご覧ください。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import matplotlib.pyplot as plt

loss = _results.history['loss']
val_loss = _results.history['val_loss']

plt.figure()
plt.plot(range(1, epochs+1), loss, marker='.', label='train')
plt.plot(range(1, epochs+1), val_loss, marker='.', label='test')
plt.legend(loc='best', fontsize=10)
plt.grid()
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.savefig('loss.png')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-26/loss.png&quot; alt=&quot;損失関数の値の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;きちんと損失関数がプロットされていることが確認できました！&lt;/p&gt;

&lt;h3 id=&quot;42-認識精度の推移&quot;&gt;4.2 認識精度の推移&lt;/h3&gt;
&lt;p&gt;モデルが&lt;strong&gt;過学習&lt;/strong&gt;していないかを認識精度の推移を図にして確認してみましょう!&lt;/p&gt;

&lt;p&gt;プロットの流れは、損失関数の時とほとんど同一のため、説明は割愛します。&lt;br /&gt;
以下にソースコードを貼るので、各自試してみてください。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;plt.clf()
acc = _results.history['acc']
val_acc = _results.history['val_acc']

plt.plot(range(1, epochs+1), acc, marker='.', label='train')
plt.plot(range(1, epochs+1), val_acc, marker='.', label='test')
plt.legend(loc='best', fontsize=10)
plt.grid()
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.savefig('acc.png')
plt.close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-26/acc.png&quot; alt=&quot;認識精度の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;図から、テストデータの認識精度を訓練データの認識精度が大幅に上回る現象は確認できないので、モデルの過学習は起きていないことがわかります。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://codeday.me/jp/qa/20181207/13787.html&quot;&gt;（Matplotlibでプロットを一旦クリアする）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;今回はニューラルネットワークの学習について扱いました。&lt;br /&gt;
フレームワークを活用することで、誤差逆伝播が自動で実行されるため、順伝播の処理だけ記述すればよいという大きなメリットを体感できたと思います。&lt;/p&gt;

&lt;p&gt;次回は、ゼロから〜の第6章に対応する、「学習に関するテクニック」をKerasを用いて実証していきたいと思います。また、ハイパーパラメータの探索や交差検証等についても扱う予定です。&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras&quot;&gt;GitHub&lt;/a&gt;にて公開しています。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに</summary></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（3層ニューラルネットワーク ＆ 手書き数字認識編）</title><link href="http://localhost:4000/DL-Intro-2/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（3層ニューラルネットワーク ＆ 手書き数字認識編）" /><published>2019-04-19T00:00:00+09:00</published><updated>2019-04-19T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-2</id><content type="html" xml:base="http://localhost:4000/DL-Intro-2/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;このシリーズでは、深層学習の入門書として有名な、「ゼロから作るDeep Learning」（以下、ゼロから〜）と同時並行で、フレームワークを学習し、その定着を目指します。&lt;/p&gt;

&lt;p&gt;前回の&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;第一弾: パーセプトロン編&lt;/a&gt;に目を通していない方は、先に目を通しておくことをおすすめします。&lt;/p&gt;

&lt;p&gt;それでは、今回は3層ニューラルネットワークをKerasで実装し、実際に手書き数字認識（MNISTデータセットの分類）をしていきましょう！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;（3層ニューラルネットワーク）&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP58〜65&lt;br /&gt;
（MNIST）&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP72〜81&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;「ゼロからKeras」シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：畳み込みニューラルネットワーク編&lt;/p&gt;
&lt;/div&gt;

&lt;script async=&quot;&quot; src=&quot;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block; text-align:center;&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1838422896597988&quot; data-ad-slot=&quot;7676908062&quot;&gt;&lt;/ins&gt;
&lt;script&gt;
     (adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-3層ニューラルネットワークの実装&quot;&gt;1. 3層ニューラルネットワークの実装&lt;/h2&gt;

&lt;h3 id=&quot;11-プロジェクトの作成&quot;&gt;1.1 プロジェクトの作成&lt;/h3&gt;
&lt;p&gt;まず、3層ニューラルネットワーク実装用のプロジェクトを作成してください。&lt;br /&gt;
以下本章では、&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;を作成するものとして進めていきます。&lt;/p&gt;

&lt;h3 id=&quot;12-モデルの作成&quot;&gt;1.2 モデルの作成&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;今回の実装からは全てFunctional APIを用いたモデル実装を行います。&lt;br /&gt;
Sequentialモデルによる実装は行いませんので、あらかじめご了承ください。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;これから実装する3層ニューラルネットワークの概念図を以下に示します。&lt;br /&gt;
実装の際の参考にしてください。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-19/three_layer_nn.png&quot; alt=&quot;3層ニューラルネットワークの概念図&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;h4 id=&quot;121-レイヤー--numpyを読み込む&quot;&gt;1.2.1 レイヤー &amp;amp; NumPyを読み込む&lt;/h4&gt;

&lt;p&gt;まず、前回と同じように、実装に必要なレイヤーとNumPyを読み込みます。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras import Model
from keras.layers import Input, Dense

import numpy as np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;122-各種レイヤーを定義する&quot;&gt;1.2.2 各種レイヤーを定義する&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;3層のニューラルネットワークなので、それと同数の3つのDenseレイヤーのインスタンスを生成します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;units&lt;/code&gt;は各層におけるニューロンの数を表しています。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;活性化関数については、ゼロから〜では&lt;code class=&quot;highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;関数が使用されているので、ここでも&lt;code class=&quot;highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;を活用します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下の例では、簡単のため入れ子式に活性化関数を定義しましたが、活性化関数をレイヤーインスタンスとして定義することもできます。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center&quot;&gt;＜活性化関数を入れ子式に定義する例＞&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_input = Input(shape=(2, ))
_layer1 = Dense(units=3, activation='sigmoid')(_input)
_layer2 = Dense(units=2, activation='sigmoid')(_layer1)
_output = Dense(units=2)(_layer2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;text-align: center&quot;&gt;＜活性化関数をインスタンスとして定義する例＞&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.layers import Activation
_input = Input(shape=(2, ))
_layer1 = Dense(units=3)(_input)
_activ1 = Activation('sigmoid')(_layer1)
_layer2 = Dense(units=2)(_activ1)
_activ2 = Activation('sigmoid')(_layer2)
_output = Dense(units=2)(_activ2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/activations/&quot;&gt;https://keras.io/ja/activations/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;123-モデルを定義する&quot;&gt;1.2.3 モデルを定義する&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;前回と同様に、入力のテンソルと出力のテンソルを&lt;code class=&quot;highlighter-rouge&quot;&gt;Model&lt;/code&gt;に渡すことで、モデルを定義します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;model.summary()&lt;/code&gt;でモデルの状態を確認することができます。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;モデルの状態をみる&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 2)                 0
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 9
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 8
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 6
=================================================================
Total params: 23
Trainable params: 23
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;124-重みを設定する&quot;&gt;1.2.4 重みを設定する&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜では重みの初期化を定義しているので、本実装でも事前に重みを設定します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kerasでは、重みは入力層から順にNumPyの配列で保持されています。&lt;br /&gt;
したがって、重みを設定する際には、順当に重みの配列をNumPy配列で定義して、そのリストを渡せばよいです。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重みの設定には、&lt;code class=&quot;highlighter-rouge&quot;&gt;model.set_weights()&lt;/code&gt;を使用します。&lt;br /&gt;
引数は重みの入ったリストです。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;w1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
b1 = np.array([0.1, 0.2, 0.3])
w2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
b2 = np.array([0.1, 0.2])
w3 = np.array([[0.1, 0.3], [0.2, 0.4]])
b3 = np.array([0.1, 0.2])
weight_array = [w1, b1, w2, b2, w3, b3]

model.set_weights(weight_array)
print(model.get_weights())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: ゼロから〜 P65&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]], dtype=float32), 
    array([0.1, 0.2, 0.3], dtype=float32), 
    array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]], dtype=float32), 
    array([0.1, 0.2], dtype=float32), 
    array([[0.1, 0.3], [0.2, 0.4]], dtype=float32), 
    array([0.1, 0.2], dtype=float32)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;13-テストする&quot;&gt;1.3 テストする&lt;/h3&gt;
&lt;p&gt;それでは、作成したモデルをテストしましょう。&lt;br /&gt;
作成したモデルのテストには、前回と同様に、&lt;code class=&quot;highlighter-rouge&quot;&gt;model.predict()&lt;/code&gt;を使用します。&lt;/p&gt;

&lt;p&gt;テストデータは、ゼロから〜 P65に示されているものと同一のものを使用します。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X = np.array([[1.0, 0.5]])
Y = model.predict(X)

print(Y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[0.3168271 0.6962791]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;見事、ゼロから〜 P65に示されている出力値と同一の値を得ることができました！&lt;/p&gt;

&lt;script async=&quot;&quot; src=&quot;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;!-- 記事内広告2 --&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block&quot; data-ad-client=&quot;ca-pub-1838422896597988&quot; data-ad-slot=&quot;1400355899&quot; data-ad-format=&quot;auto&quot; data-full-width-responsive=&quot;true&quot;&gt;&lt;/ins&gt;
&lt;script&gt;
     (adsbygoogle = window.adsbygoogle || []).push({});
&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-手書き数字認識mnist&quot;&gt;2. 手書き数字認識（MNIST）&lt;/h2&gt;

&lt;p&gt;ここからは、今実装した3層ニューラルネットワークを活用して、手書き数字を実際に分類していきます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP72〜81&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;21-mnistデータセットの読み込み&quot;&gt;2.1 MNISTデータセットの読み込み&lt;/h2&gt;
&lt;p&gt;Kerasでは、MNISTデータセットは簡単にダウンロード&amp;amp;呼び出しできるようになっています。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;を作成して、以下を入力し動作させてみてください。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

print(x_train.shape)
print(y_train.shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/datasets/#mnist&quot;&gt;https://keras.io/ja/datasets/#mnist&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(60000, 28, 28)
(60000,)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) Kerasの&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist.load_data()&lt;/code&gt;は、「正規化されていない &amp;amp; 2次元配列」の状態のリストが返ってきます。ゼロから〜のP73の挙動とは異なるので、注意してください。&lt;/p&gt;

&lt;p&gt;ここで、データセットが&lt;code class=&quot;highlighter-rouge&quot;&gt;train&lt;/code&gt;と&lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt;の二つに分割されていることに気がつくと思います。これは、機械学習においてはモデルの汎化性能を測定するために、通常データセットを訓練データとテストデータの二つ（もしくはそれ以上）に分割するためです。詳しくは、ゼロから〜の第4章を見てください。&lt;/p&gt;

&lt;h3 id=&quot;22-データセットの前処理&quot;&gt;2.2 データセットの前処理&lt;/h3&gt;
&lt;p&gt;モデルの推論処理においてMNISTデータセットを活用するので、「正規化 &amp;amp; 一次元配列化」の処理を行っておきます。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;配列の形状変換は&lt;code class=&quot;highlighter-rouge&quot;&gt;.reshape&lt;/code&gt;メソッドで行えます。&lt;br /&gt;
引数は変換後の配列形状です。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;正規化処理のために、リストをfloat型に変換します。&lt;br /&gt;
型変換は、&lt;code class=&quot;highlighter-rouge&quot;&gt;.astype&lt;/code&gt;メソッドで行えます。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 一次元配列にする
x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)

# 正規化処理
x_train = x_train.astype('float')
x_test = x_test.astype('float')
x_train /= 255.
x_test /= 255.

print(x_train.shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(60000, 784)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;きちんと一次元配列に変換されていることが確認できました。&lt;br /&gt;
正規化されているかどうかは、配列の要素のうち一つを表示させて確認してみてください。&lt;/p&gt;

&lt;h3 id=&quot;22-モデルの改良&quot;&gt;2.2 モデルの改良&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;でMNISTを分類できるように、以下の2点を改良します。 &lt;br /&gt;
改良したものは、&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;に追記してください。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜のP76と合わせて、一層目の全結合層のunit数を50、二層目を100とし、出力層は10とします。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MNISTデータセットの分類は「&lt;strong&gt;分類問題&lt;/strong&gt;」であるため、出力層にsoftmax層を追加します。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;モデルの状態をみる&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 784)               0
_________________________________________________________________
dense_1 (Dense)              (None, 50)                39250
_________________________________________________________________
dense_2 (Dense)              (None, 100)               5100
_________________________________________________________________
dense_3 (Dense)              (None, 10)                1010
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0
=================================================================
Total params: 45,360
Trainable params: 45,360
Non-trainable params: 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;きちんと望みのモデルが実装されていることが確認できました。&lt;/p&gt;

&lt;p&gt;ここで、中間層の定義方法について、&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;と書き方が変わっていると気づいた方もいるでしょう。&lt;/p&gt;

&lt;p&gt;Functional APIを用いたモデル定義では、前回紹介したように、入力と出力のテンソルを個別に保持しておけば良いルールになっています。&lt;/p&gt;

&lt;p&gt;したがって、中間のベクトルに関しては特段利用したいケースがない限りは、同一の変数を利用した方が、コードが煩雑にならないのでおすすめです。&lt;/p&gt;

&lt;h3 id=&quot;23-重みファイルの読み込み&quot;&gt;2.3 重みファイルの読み込み&lt;/h3&gt;
&lt;p&gt;重みファイルは、ゼロから〜のものと同一のファイルを使用します。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/oreilly-japan/deep-learning-from-scratch/tree/master/ch03&quot;&gt;公式レポジトリ&lt;/a&gt;から、&lt;code class=&quot;highlighter-rouge&quot;&gt;sample_weight.pkl&lt;/code&gt;をダウンロードしてください。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;と同一ディレクトリ内に&lt;code class=&quot;highlighter-rouge&quot;&gt;sample_weight.pkl&lt;/code&gt;を配置してください。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;以下が、重みファイルを読み込むためのスクリプトになります。&lt;br /&gt;
なお、今回は「推論処理のみ行う &amp;amp; できる限りゼロから〜に即したものにする」ために、このスクリプトを使用しますが、このような手間のかかる初期化処理は通常行いません。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import pickle
def load_weight():
    with open('sample_weight.pkl', 'rb') as f:
        weights = pickle.load(f)
        weight_array = [weights['W1'], weights['b1'], 
                        weights['W2'], weights['b2'],
                        weights['W3'], weights['b3']]
        
        return weight_array

model.set_weights(load_weight())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/getting-started/faq/#keras-model&quot;&gt;Kerasでモデルの保存/ロードを行う&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;24-テストする&quot;&gt;2.4 テストする&lt;/h3&gt;
&lt;p&gt;それでは、ゼロから〜のP77と同様に実装したモデルをテストしていきましょう。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.argmax&lt;/code&gt;で軸(axis)指定をしていますが、これはリストが2次元配列以上のときに、「どの軸方向に対して演算を行うか」を指定するために活用します。&lt;br /&gt;
軸指定の詳細については、&lt;a href=&quot;https://deepage.net/features/numpy-axis.html&quot;&gt;このページ&lt;/a&gt;を参照するとわかりやすいです。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_y_test = model.predict(x_test)
_y_test = np.argmax(_y_test, axis=1)

print(f'Accuracy: {np.sum(y_test == _y_test) / len(y_test)}')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Accuracy: 0.9352
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;めでたく、ゼロから〜のP77に示されている分類精度: 0.9352を得ることができました！&lt;/p&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;今回はゼロから〜の3章に対応する部分である、3層ニューラルネットとMNISTデータセットの分類をKerasで実装しました。 
深層学習フレームワークを活用することで、たった数行でゼロから〜にあるものと同一のモデルを実装できることを実感したと思います。&lt;/p&gt;

&lt;p&gt;次回からはゼロから〜の4章以降に対応する、ニューラルネットワークの学習に入ります！&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras&quot;&gt;GitHub&lt;/a&gt;にて公開しています。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに</summary></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（パーセプトロン編）</title><link href="http://localhost:4000/DL-Intro-1/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（パーセプトロン編）" /><published>2019-04-13T00:00:00+09:00</published><updated>2019-04-13T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-1</id><content type="html" xml:base="http://localhost:4000/DL-Intro-1/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;「ゼロから作るディープラーニング」は深層学習を学ぶ入門書として非常に人気があり、様々な場所で用いられています。&lt;/p&gt;

&lt;p&gt;しかしながら、「フレームワークを用いないで深層学習の基礎を学ぶ」という本の目的により、深層学習フレームワークに関する内容は触れられていません。&lt;/p&gt;

&lt;p&gt;そのため、読者の中には実際のフレームワークを用いた機械学習の勉強へと繋げる機会や気力を失ってしまった人も少なからずいると思います。&lt;/p&gt;

&lt;p&gt;このプロジェクトでは、「ゼロから作るDeep Learning」（以下、ゼロから〜）を学習しつつ、深層学習フレームワークの一つである、Kerasについて学んでいきます。&lt;br /&gt;
これにより、深層学習の基礎を理解しつつ、フレームワークを活用した実装方法について学ぶことができます！&lt;/p&gt;

&lt;p&gt;それでは、まずはKerasのインストールから始めていきましょう。&lt;/p&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;「ゼロからKeras」シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：畳み込みニューラルネットワーク編&lt;/p&gt;
&lt;/div&gt;

&lt;!-- START MoshimoAffiliateEasyLink --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
(function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a;
b[a]=b[a]||function(){arguments.currentScript=c.currentScript
||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)};
c.getElementById(a)||(d=c.createElement(f),d.src=g,
d.id=a,e=c.getElementsByTagName(&quot;body&quot;)[0],e.appendChild(d))})
(window,document,&quot;script&quot;,&quot;//dn.msmstatic.com/site/cardlink/bundle.js&quot;,&quot;msmaflink&quot;);
msmaflink({&quot;n&quot;:&quot;ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装&quot;,&quot;b&quot;:&quot;&quot;,&quot;t&quot;:&quot;&quot;,&quot;d&quot;:&quot;https:\/\/images-fe.ssl-images-amazon.com&quot;,&quot;c_p&quot;:&quot;\/images\/I&quot;,&quot;p&quot;:[&quot;\/512ru2i5gyL.jpg&quot;,&quot;\/51Z7TzDuljL.jpg&quot;,&quot;\/51Dzt-P86rL.jpg&quot;,&quot;\/51VfxOvKEwL.jpg&quot;,&quot;\/51dNlTr6a7L.jpg&quot;,&quot;\/51RfBXWcDAL.jpg&quot;,&quot;\/415IXnDy3IL.jpg&quot;,&quot;\/415VCPaFk1L.jpg&quot;,&quot;\/410OtMHeqkL.jpg&quot;,&quot;\/41F7PYraodL.jpg&quot;,&quot;\/41TFOjFQtaL.jpg&quot;,&quot;\/51SRdr-iBHL.jpg&quot;,&quot;\/51yxT9nEC4L.jpg&quot;,&quot;\/51q0zWV9NnL.jpg&quot;,&quot;\/51MDmgZZ2cL.jpg&quot;,&quot;\/51n9f4IpDZL.jpg&quot;,&quot;\/51erDZNc9tL.jpg&quot;,&quot;\/41qOS5gPctL.jpg&quot;,&quot;\/51wDA5ZuAeL.jpg&quot;,&quot;\/51Fg67TMeCL.jpg&quot;,&quot;\/51KCmWaOqFL.jpg&quot;,&quot;\/51e5o3xlSTL.jpg&quot;,&quot;\/51RF7CQIW1L.jpg&quot;,&quot;\/514m0GkYReL.jpg&quot;,&quot;\/516bqTekHoL.jpg&quot;,&quot;\/41colcboiNL.jpg&quot;,&quot;\/51IRqvCxzAL.jpg&quot;,&quot;\/51mFjvDorhL.jpg&quot;,&quot;\/51BQcHSo5QL.jpg&quot;,&quot;\/51THHJTIaTL.jpg&quot;,&quot;\/51PzJ4B%2BhtL.jpg&quot;,&quot;\/51CRA6FoSLL.jpg&quot;,&quot;\/41M5Qzg1yXL.jpg&quot;,&quot;\/51iMy2fgPkL.jpg&quot;,&quot;\/41xe6JIHELL.jpg&quot;,&quot;\/41HYfr%2Bv%2BKL.jpg&quot;,&quot;\/41gRFTsmr%2BL.jpg&quot;,&quot;\/51fD5k24M8L.jpg&quot;,&quot;\/518%2B8E-OZeL.jpg&quot;,&quot;\/41iyTyjjgdL.jpg&quot;,&quot;\/51L6s8Uo8aL.jpg&quot;,&quot;\/41xHQHIOQ2L.jpg&quot;,&quot;\/51ZWyzq1L3L.jpg&quot;,&quot;\/51oDwhT1gcL.jpg&quot;,&quot;\/51Zu5NuGq2L.jpg&quot;,&quot;\/512VUPnG69L.jpg&quot;,&quot;\/41Ufnm15s9L.jpg&quot;,&quot;\/41nALw08xcL.jpg&quot;,&quot;\/51uZB7hP-xL.jpg&quot;,&quot;\/41Qi%2BzskZHL.jpg&quot;,&quot;\/51p3s1TTn4L.jpg&quot;,&quot;\/413xgCPJnzL.jpg&quot;,&quot;\/51mc1fX%2B7xL.jpg&quot;,&quot;\/51GLiuSVtbL.jpg&quot;,&quot;\/419bmxhHV9L.jpg&quot;,&quot;\/5100WGZVi6L.jpg&quot;],&quot;u&quot;:{&quot;u&quot;:&quot;https:\/\/www.amazon.co.jp\/%E3%82%BC%E3%83%AD%E3%81%8B%E3%82%89%E4%BD%9C%E3%82%8BDeep-Learning-%E2%80%95Python%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AE%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%A3%85-%E6%96%8E%E8%97%A4-%E5%BA%B7%E6%AF%85\/dp\/4873117585&quot;,&quot;t&quot;:&quot;amazon&quot;,&quot;r_v&quot;:&quot;&quot;},&quot;aid&quot;:{&quot;amazon&quot;:&quot;1430714&quot;,&quot;rakuten&quot;:&quot;1430719&quot;,&quot;yahoo&quot;:&quot;1430721&quot;}});
&lt;/script&gt;

&lt;!-- MoshimoAffiliateEasyLink END --&gt;

&lt;h2 id=&quot;1-kerasのインストール&quot;&gt;1. Kerasのインストール&lt;/h2&gt;
&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) 本プロジェクトでは、すでにPythonやNumPy等のインストールは終えているものとしてスタートします。&lt;br /&gt;
環境整備がお済みでない方は、先にゼロから〜の一章を参考に済ませてください。&lt;/p&gt;

&lt;p&gt;・コマンドライン上で、以下のコマンドを入力してKerasをインストールします。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install keras
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/&quot;&gt;https://keras.io/ja/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;2-プロジェクトの作成&quot;&gt;2. プロジェクトの作成&lt;/h2&gt;

&lt;p&gt;お好きな環境でゼロから〜二章用のプロジェクトを作成してください。&lt;/p&gt;

&lt;p&gt;ただし、ここでは、&lt;code class=&quot;highlighter-rouge&quot;&gt;sequential.py&lt;/code&gt;と&lt;code class=&quot;highlighter-rouge&quot;&gt;functional.py&lt;/code&gt;の二つのファイルを作成することとします。&lt;/p&gt;

&lt;h2 id=&quot;3-モデルの作成--テスト&quot;&gt;3. モデルの作成 &amp;amp; テスト&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;KerasにはSepuentialモデルとFunctional APIの2種類のモデルの定義方法があります。
    &lt;ul&gt;
      &lt;li&gt;Sepuentialモデル：様々な層を積み木のように積み重ねていくイメージ。線形スタック。&lt;/li&gt;
      &lt;li&gt;Functionalモデル：層をインスタンスとして扱う。複雑なモデルを定義するときに便利。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;それぞれのモデルの定義方法の違いを以下で見ていきましょう。&lt;/p&gt;

&lt;h3 id=&quot;31-sequential-モデル&quot;&gt;3.1 Sequential モデル&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SequentialモデルでANDゲートのパーセプトロンを実装します。&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;sequential.py&lt;/code&gt;に以下のソースを順に書いていきましょう。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;311-レイヤー--numpyを読み込む&quot;&gt;3.1.1 レイヤー + NumPyを読み込む&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.models import Sequential
from keras.layers import Dense

import numpy as np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;312-modelにsepuentialモデルを定義する&quot;&gt;3.1.2 &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;にSepuentialモデルを定義する&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;313-modelにdense層全結合層を追加する&quot;&gt;3.1.3 &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;にDense層（全結合層）を追加する&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;model.add(Dense(input_dim=2, units=1))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;全結合層という用語はゼロから〜の二章には登場していませんが、ここでは単純パーセプトロンと同じと思ってください。&lt;br /&gt;
参考程度に、&lt;code class=&quot;highlighter-rouge&quot;&gt;input_dim=2, units=1&lt;/code&gt;のときのDense層の様子を概念図にしたものを以下に示します。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-13/example_dense.png&quot; alt=&quot;Dense層の様子の概念図&quot; style=&quot;width: 450px;&quot; /&gt;
&lt;/div&gt;

&lt;h4 id=&quot;314-modelに重みを与える&quot;&gt;3.1.4 &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;に重みを与える&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜の二章では予め重みとバイアスが与えられているので、この実装でも与えます。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重みとバイアスの初期設定には、&lt;code class=&quot;highlighter-rouge&quot;&gt;model.set_weights()&lt;/code&gt;を使用します。&lt;br /&gt;
引数は重みの入ったリストです。&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;model.set_weights([np.array([[0.5], [0.5]]), np.array([-0.7])])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;blockquote&gt;
      &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: ゼロから〜のP27&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;315-テストする&quot;&gt;3.1.5 テストする&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;モデルのテストは&lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt;メソッドで行えます。&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt;の返り値は、入力データの予測結果のリストになっています。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X = np.array([[0,0], [0,1], [1,0], [1,1]])
Y = np.array([[0], [0], [0], [1]])

Y_ = model.predict(X)

print(Y_)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;この結果は以下のようになるはずです。&lt;br /&gt;
Output:
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[-0.7       ]
 [-0.19999999]
 [-0.19999999]
 [ 0.3       ]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;これではわかりにくいので、マイナスのものは&lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;で、プラスのものは&lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;に置き換えます。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Y_[Y_ &amp;lt;= 0] = False
Y_[Y_ &amp;gt; 0] = True
print(Y_)
print(f'Results: {Y == Y_}')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;以下のような結果が得られたと思います。&lt;br /&gt;
見事ANDゲートが実装できていることが確認できますね。&lt;br /&gt;
Output:
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[0.]
 [0.]
 [0.]
 [1.]]
Results: [[ True]
 [ True]
 [ True]
 [ True]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;32-fucntional-api&quot;&gt;3.2 Fucntional API&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Functional APIでANDゲートのパーセプトロンを実装します。&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;functional.py&lt;/code&gt;に以下のソースを順に書いていきましょう。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;321-レイヤー--numpyを読み込む&quot;&gt;3.2.1 レイヤー + NumPyを読み込む&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras import Model
from keras.layers import Input, Dense

import numpy as np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;322-各種レイヤーを定義する&quot;&gt;3.2.2 各種レイヤーを定義する&lt;/h4&gt;
&lt;p&gt;Functional APIでは、入力層を追加で定義する必要があります。&lt;/p&gt;

&lt;p&gt;Dense部分のイメージとしては、Denseレイヤーのインスタンスを生成し、その入力として、テンソル：_inputを与えるという感じです。出力のテンソルは_outputとなります。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_input = Input(shape=(2, ))
_output = Dense(units=1)(_input)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;323-モデルを定義する&quot;&gt;3.2.3 モデルを定義する&lt;/h4&gt;
&lt;p&gt;以下のように、Functional APIでは、モデルを定義する際に入力と出力のテンソルを別々に保持しておく必要があります！&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/getting-started/functional-api-guide/&quot;&gt;https://keras.io/ja/getting-started/functional-api-guide/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;324-重みを与える--テストする&quot;&gt;3.2.4 重みを与える &amp;amp; テストする&lt;/h4&gt;
&lt;p&gt;Sequentialモデルと同じなので割愛します。&lt;br /&gt;
結果が同一になることを確認するとよいです。&lt;/p&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;今回は、パーセプトロンによるANDゲートの実装をKerasにより行いました。&lt;/p&gt;

&lt;p&gt;Kerasを用いることで、より「簡単に&amp;amp;抽象的に」パーセプトロンを実装することが確認できたと思います。&lt;/p&gt;

&lt;p&gt;次回は、3層ニューラルネットワークの実装を行います。&lt;/p&gt;

&lt;h2 id=&quot;発展課題&quot;&gt;発展課題&lt;/h2&gt;

&lt;p&gt;NAND, ORゲートも実装してみると良いでしょう。&lt;br /&gt;
重みとバイアスは、ゼロから〜のP27,28を参照してください。&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras&quot;&gt;GitHub&lt;/a&gt;にて公開しています。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに</summary></entry><entry xml:lang="ja_JP"><title type="html">論文メモ：Deep contextualized word representations</title><link href="http://localhost:4000/Note-ELMo/" rel="alternate" type="text/html" title="論文メモ：Deep contextualized word representations" /><published>2019-04-06T00:00:00+09:00</published><updated>2019-04-06T00:00:00+09:00</updated><id>http://localhost:4000/Note-ELMo</id><content type="html" xml:base="http://localhost:4000/Note-ELMo/">&lt;h2 id=&quot;文献情報&quot;&gt;文献情報&lt;/h2&gt;
&lt;p&gt;著者: M. Peters et al.&lt;br /&gt;
所属: Allen Institute for Artificial Intelligence / Paul G. Allen School of Computer Science &amp;amp; Engineering, University of Washington&lt;br /&gt;
出典: NAACL 2018 &lt;a href=&quot;https://aclweb.org/anthology/papers/N/N18/N18-1202/&quot;&gt;(https://aclweb.org/anthology/papers/N/N18/N18-1202/)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;どんな論文か&quot;&gt;どんな論文か？&lt;/h2&gt;
&lt;p&gt;ELMo = Embeddings from Language Modelsの略であり，言語モデルを活用した文脈に応じた単語分散表現: ELMoを提唱した論文．&lt;/p&gt;

&lt;h2 id=&quot;先行研究と比べてどこが凄い&quot;&gt;先行研究と比べてどこが凄い？&lt;/h2&gt;
&lt;p&gt;既存のNLPタスクのモデルの埋め込み層にELMoを追加するだけで，様々なタスクで当時のSoTAを達成した．&lt;/p&gt;

&lt;h2 id=&quot;技術や手法のキモはどこ&quot;&gt;技術や手法のキモはどこ？&lt;/h2&gt;
&lt;p&gt;双方向言語モデルを活用し，隠れ層の重みを重み付き線形和で圧縮する点．&lt;br /&gt;
→ 従来手法では，単に双方向言語モデルの出力層だけを取ってきていた．&lt;/p&gt;

&lt;h2 id=&quot;どうやって有効だと検証した&quot;&gt;どうやって有効だと検証した？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;各種NLPタスクに適用して，そのスコアにより評価．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;議論はある&quot;&gt;議論はある？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;ELMoの中間層が捉えている特徴素について&lt;br /&gt;
→ 著者らによると，ELMoの中間層は低層であればあるほど，&lt;strong&gt;文法的(syntactic)&lt;/strong&gt;な情報を含み，高層の方が，&lt;strong&gt;意味的(semantic)&lt;/strong&gt;な情報を含むとのこと．&lt;br /&gt;
→ 基本的にどのタスクもsyntacticな情報を好む傾向にあるらしい．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;論文の詳細メモ&quot;&gt;論文の詳細メモ&lt;/h2&gt;
&lt;h3 id=&quot;1-順方向言語モデル&quot;&gt;1. 順方向言語モデル&lt;/h3&gt;
&lt;p&gt;トークン数: $N$の単語列: $(t_1, t_2, \dots, t_N)$が与えられたとき，順方向の言語モデルは，単語: $t_k$と単語列: $(t_1, \dots, t_{k-1})$の条件付き確率をモデリングすることで，次のように表される.順方向の言語モデルでは，次の単語: $t_{k+1}$を予測することを目的とする．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(t_1, t_2, ..., t_N) = \prod_{k=1}^N p(t_k | t_1, t_2, \dots, t_{k-1})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;最近の言語モデルでは，文脈非依存な単語表現: $\mathbf{x}_k^{LM}$を単語埋め込みやcharacter-based CNNにより算出してから，L層のLSTMに入力することが多い．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;単語列の位置: $k$において，各LSTM層は，文脈依存な単語表現: $\overrightarrow{\mathbf{h}}_{k, j}^{LM}$（ただし，$1 \leq j \leq L$）を出力する．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\overrightarrow{\mathbf{h}}_{k, L}^{LM}&lt;/script&gt;は，次の単語: $t_{k+1}$をsoftmax層で予測するのに用いられる．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-逆方向言語モデル&quot;&gt;2. 逆方向言語モデル&lt;/h3&gt;
&lt;p&gt;逆方向言語モデルは順方向言語モデルと類似しているが，単語列を逆に処理していく点で異なる．なお，逆方向の言語モデルでは，未来の単語列から一つ前の単語: $t_{k-1}$を予測することを目的とする．つまり，逆方向の言語モデルは次のように定義される．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(t_1, t_2, ..., t_N) = \prod_{k=1}^N p(t_k | t_{k+1}, t_{k+2}, \dots, t_N)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;最終的には，&lt;script type=&quot;math/tex&quot;&gt;\overleftarrow{\mathbf{h}}_{k, L}^{LM}&lt;/script&gt; を求めることで，$t_{k-1}$ をsoftmax層で予測する．&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-双方向言語モデル&quot;&gt;3. 双方向言語モデル&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;通常言語モデルは対数尤度を最大化することで最適化を行う．&lt;br /&gt;
→ 文脈中で出現してほしい単語の確率を最大化するため．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ELMoで使われる双方向言語モデルは次の式の対数尤度を最大化することで学習する．&lt;br /&gt;
→ 文脈非依存な単語表現とソフトマックス層のパラメータ: $\Theta_{x}, \Theta_s$は共有．LSTMのパラメータについてのみ独立．&lt;br /&gt;
→ 従来手法ではパラメータはすべて独立&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{k=1}^{N}(\log p(t_k | t_1, t_2, \dots, t_{k-1}; \Theta_x, \overrightarrow{\Theta}_{LSTM}, \Theta_s) \\+ \log p(t_k | t_{k+1}, t_{k+2}, \dots, t_N; \Theta_x, \overleftarrow{\Theta}_{LSTM}, \Theta_s))&lt;/script&gt;

&lt;h3 id=&quot;4-elmoのパラメータ算出&quot;&gt;4. ELMoのパラメータ算出&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;全てのトークン: $t_k$はL層の双方向言語モデルに対し，2L+1個の特徴量を持つ．&lt;br /&gt;
→ 文脈依存しない単語ベクトル: 1個&lt;br /&gt;
→ 文脈依存のする順方向と逆方向のLSTM: 2L個&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{equation*}
\begin{split}
R_k &amp;= \{x_k^{LM}, \overrightarrow{\mathbf{h}}_{k, j}^{LM}, \overleftarrow{\mathbf{h}}_{k, j}^{LM} | j = 1, \dots, L \}\\
    &amp;= \{\mathbf{h}_{k, j}^{LM} | j=0, \dots, L \}
\end{split}
\end{equation*} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;ELMoを他のタスクに応用するには，Rのすべての要素を一つのベクトル表現に変換する．&lt;br /&gt;
→ 簡単な例だと，一番上の層だけを取ってくるものがある．CoVeやTagLMはこれを採用している．&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{ELMo}_k^{task} = E(R_k; \Theta_e) = \mathbf{h}_{k, L}^{LM}&lt;/script&gt;

&lt;div style=&quot;text-align: center&quot;&gt;ただし，$\mathbf{h}_{k, L}^{LM} = \left[\overrightarrow{\mathbf{h}}_{k, j}^{LM}; \overleftarrow{\mathbf{h}}_{k, j}^{LM}\right]$&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ELMoではより便宜をはかり，重み付き線形和の形で変換する．&lt;br /&gt;
→ $s_j^{task}$はsoftmaxで正規化された重み&lt;br /&gt;
→ $\gamma^{task}$はELMoのベクトル全体をスケーリングするため．チューニングの最適化の観点から必要．&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{ELMo}_k^{task} = \gamma^{task} \sum_{j=0}^L s_j^{task}\mathbf{h}_{k, j}^{LM}&lt;/script&gt;

&lt;h3 id=&quot;5-elmoモデルのnlpタスクへの適用&quot;&gt;5. ELMoモデルのNLPタスクへの適用&lt;/h3&gt;
&lt;p&gt;単に$\mathbf{ELMo}_k^{task}$を入力の埋め込みベクトルとconcatすれば良い．&lt;/p&gt;

&lt;h2 id=&quot;まとめスライド&quot;&gt;まとめスライド&lt;/h2&gt;
&lt;div style=&quot;text-align: center&quot;&gt;&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/hvw0gfJhsc8aWL&quot; width=&quot;510&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&quot; allowfullscreen=&quot;&quot;&gt; &lt;/iframe&gt;&lt;/div&gt;
&lt;div style=&quot;margin-bottom:5px&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;実装&quot;&gt;実装&lt;/h2&gt;
&lt;p&gt;試しにKerasでELMo + BiLSTMを使ってIMDBの分類を行ったので，GitHubにあげました．&lt;br /&gt;
→ &lt;a href=&quot;https://github.com/gucci-j/elmo-imdb&quot;&gt;https://github.com/gucci-j/elmo-imdb&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="論文メモ" /><summary type="html">文献情報 著者: M. Peters et al. 所属: Allen Institute for Artificial Intelligence / Paul G. Allen School of Computer Science &amp;amp; Engineering, University of Washington 出典: NAACL 2018 (https://aclweb.org/anthology/papers/N/N18/N18-1202/)</summary></entry><entry xml:lang="ja_JP"><title type="html">MatplotlibとseabornによるSelf Attentionの可視化</title><link href="http://localhost:4000/SA-Visualization/" rel="alternate" type="text/html" title="MatplotlibとseabornによるSelf Attentionの可視化" /><published>2019-04-02T00:00:00+09:00</published><updated>2019-04-02T00:00:00+09:00</updated><id>http://localhost:4000/SA-Visualization</id><content type="html" xml:base="http://localhost:4000/SA-Visualization/">&lt;p&gt;Pythonの可視化ライブラリであるseabornとグラフ描画ライブラリのMatplotlibを組み合わせることで，意外と簡単にSelf Attentionの重みを可視化することができる．&lt;/p&gt;

&lt;p&gt;とあるデータセットを用いて実際に可視化した結果が以下の図です．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../resources/2019-04-02/attention.png&quot; alt=&quot;attentionの可視化結果&quot; /&gt;&lt;/p&gt;

&lt;p&gt;それでは，順を追って簡単に見ていきましょう．
なお，深層学習のフレームワークにはPyTorchを使用し，テキストデータの前処理にはtorchtextを使用しています．&lt;/p&gt;

&lt;h2 id=&quot;1-ダウンロード--インストール&quot;&gt;1. ダウンロード &amp;amp; インストール&lt;/h2&gt;
&lt;p&gt;Matplotlib，seabornをインストールしていない場合は，インストールしましょう．&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install matplotlib
pip install seaborn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2-インポート&quot;&gt;2. インポート&lt;/h2&gt;
&lt;p&gt;本稿ではサーバー上で動作させることを想定しているので，前もって&lt;code class=&quot;highlighter-rouge&quot;&gt;mpl.use('Agg')&lt;/code&gt;を指定することで，描画エラーを回避します．&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-self-attentionの実装&quot;&gt;3. Self Attentionの実装&lt;/h2&gt;
&lt;p&gt;Self Attentionの実装については，&lt;a href=&quot;https://github.com/gucci-j/imdb-classification-gru&quot;&gt;GitHub&lt;/a&gt;にあげている，ソースコード: &lt;code class=&quot;highlighter-rouge&quot;&gt;model_with_self_attention.py&lt;/code&gt;を流用しました．クラス部分を以下に貼ります．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Self_Attention(nn.Module):
    def __init__(self, query_dim):
        # assume: query_dim = key/value_dim
        super(Self_Attention, self).__init__()
        self.scale = 1. / math.sqrt(query_dim)

    def forward(self, query, key, value):
        # query == hidden: (batch_size, hidden_dim * 2)
        # key/value == gru_output: (sentence_length, batch_size, hidden_dim * 2)
        query = query.unsqueeze(1) # (batch_size, 1, hidden_dim * 2)
        key = key.transpose(0, 1).transpose(1, 2) # (batch_size, hidden_dim * 2, sentence_length)

        # bmm: batch matrix-matrix multiplication
        attention_weight = torch.bmm(query, key) # (batch_size, 1, sentence_length)
        attention_weight = F.softmax(attention_weight.mul_(self.scale), dim=2) # normalize sentence_length's dimension

        value = value.transpose(0, 1) # (batch_size, sentence_length, hidden_dim * 2)
        attention_output = torch.bmm(attention_weight, value) # (batch_size, 1, hidden_dim * 2)
        attention_output = attention_output.squeeze(1) # (batch_size, hidden_dim * 2)

        return attention_output, attention_weight.squeeze(1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ソースコード中において，&lt;code class=&quot;highlighter-rouge&quot;&gt;attention_weight&lt;/code&gt;は時系列方向に正規化された重みベクトルとなっています．そのため，このベクトルを可視化することで，各時刻における入力の単語の重要度を可視化できることになります．&lt;br /&gt;
要するに，このソースコードにおいては，可視化には&lt;code class=&quot;highlighter-rouge&quot;&gt;attention_weight&lt;/code&gt;のみを用いれば良いことになります．&lt;/p&gt;

&lt;h2 id=&quot;4-いざ描画&quot;&gt;4. いざ描画&lt;/h2&gt;

&lt;p&gt;ヒートマップの描画には，&lt;code class=&quot;highlighter-rouge&quot;&gt;sns.heatmap()&lt;/code&gt;を使います．詳しい使い方は，&lt;a href=&quot;https://seaborn.pydata.org/generated/seaborn.heatmap.html&quot;&gt;ドキュメント&lt;/a&gt;をご覧ください．&lt;/p&gt;

&lt;p&gt;重要な点としては，ヒートマップ中の各セル内に入力の単語を表示させたいときに，&lt;code class=&quot;highlighter-rouge&quot;&gt;annot&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;string&lt;/code&gt;型のリストを渡すことで，描画できてしまうということです！&lt;/p&gt;

&lt;p&gt;ただし，必ず&lt;strong&gt;リストをNumPyに通すこと&lt;/strong&gt; + &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fmt=''&lt;/code&gt;&lt;/strong&gt;を指定するのを忘れないでください！&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;plt.figure(figsize = (15, 7))
sns.heatmap(attention_weight, annot=np.asarray(itos), fmt='', cmap='Blues')
plt.savefig('./fig/attention_' + str(batch_count) + '.png')
plt.close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;
&lt;p&gt;ソースコードは後日: &lt;a href=&quot;https://github.com/gucci-j/imdb-classification-gru&quot;&gt;GitHub&lt;/a&gt;に追加して公開する予定です．&lt;/p&gt;</content><author><name></name></author><category term="Tips" /><summary type="html">Pythonの可視化ライブラリであるseabornとグラフ描画ライブラリのMatplotlibを組み合わせることで，意外と簡単にSelf Attentionの重みを可視化することができる．</summary></entry><entry xml:lang="ja_JP"><title type="html">論文メモ：Frustratingly Short Attention Spans in Neural Language Modeling</title><link href="http://localhost:4000/Note-Frustratingly/" rel="alternate" type="text/html" title="論文メモ：Frustratingly Short Attention Spans in Neural Language Modeling" /><published>2019-04-01T00:00:00+09:00</published><updated>2019-04-01T00:00:00+09:00</updated><id>http://localhost:4000/Note-Frustratingly</id><content type="html" xml:base="http://localhost:4000/Note-Frustratingly/">&lt;h2 id=&quot;文献情報&quot;&gt;文献情報&lt;/h2&gt;

&lt;p&gt;著者: M. Daniluk et al.&lt;br /&gt;
所属: University College London&lt;br /&gt;
出典: ICLR 2017 &lt;a href=&quot;https://arxiv.org/abs/1702.04521&quot;&gt;(https://arxiv.org/abs/1702.04521)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;この論文の主張&quot;&gt;この論文の主張&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;ニューラル言語モデルのためのkey-valueに基づくAttentionを提案&lt;/li&gt;
  &lt;li&gt;さらにそれを改良したkey-value-predictに基づくAttentionの提案&lt;/li&gt;
  &lt;li&gt;従来のMemory-augumented言語モデルよりも，パープレキシティが小さくなった&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;背景関連研究&quot;&gt;背景・関連研究&lt;/h2&gt;

&lt;p&gt;言語モデルは次に出現する単語を予測する能力を持っている．古典的なNグラムに基づく言語モデルは短文内での単語間の依存関係を捉えることができる．&lt;br /&gt;
一方で，ニューラル言語モデルは，より広範囲な単語間の依存関係を捉えることができる．&lt;/p&gt;

&lt;p&gt;近年のニューラル言語モデルはAttentionに基づくものが多く，より直接的に単語間の関係性を捉えられるようになってきている．&lt;/p&gt;

&lt;p&gt;Attentionを言語モデルに取り入れるには，モデル中の出力ベクトルが以下の複数の役割を同時にこなさなければならない．&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;次の単語を予測するためにある分布をエンコードする役割&lt;/li&gt;
  &lt;li&gt;attentionベクトルを計算するためのベクトルとして振る舞う役割&lt;/li&gt;
  &lt;li&gt;attentionにおいて文脈ベクトルを求めるために使われる役割-&amp;gt;次のトークンを予測する際に文脈を考慮するのを助ける役割&lt;/li&gt;
&lt;/ol&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-01/k-v-p_attention.png&quot; alt=&quot;k-v-p attention&quot; style=&quot;width: auto;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;一つの出力ベクトルに複数の役割を課すことは，モデルを複雑化させる要因となり，学習を難しくすると考えられる．&lt;br /&gt;
したがって，本研究では，上記の三つの役割を別々のベクトルに割り当てることで，モデルを簡単化させることを目指す．&lt;br /&gt;
具体的には，各時刻において出力されるベクトルを3つにするということである．&lt;br /&gt;
論文内ではこれを，key-value-predictベクトルと名付けており，Attentionを含めて，key-value-predict Attentionと名付けている．&lt;/p&gt;

&lt;h2 id=&quot;従来手法-attention-for-neural-language-modeling&quot;&gt;従来手法 (Attention for Neural Language Modeling)&lt;/h2&gt;

&lt;p&gt;(1) &lt;strong&gt;時刻: $t$において，$L$個の出力ベクトルを記憶領域として取る&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*}
    Y_t = [{\bf h}_{t-L}, \dots, {\bf h}_{t-1}] \in \mathbb{R}^{k \times L}
\end{equation*}&lt;/script&gt;

&lt;p&gt;ただし，&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;はLSTMの出力ベクトルの次元を指し，$h_t \in \mathbb{R}^k$は時刻: $t$における出力ベクトルを意味する．&lt;/p&gt;

&lt;p&gt;→ L個に限るのは実用的な問題から: Lはハイパーパラメータ&lt;/p&gt;

&lt;p&gt;(2) &lt;strong&gt;Attentionの重み: $\alpha_t$を計算する&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{equation*}
\begin{split}
\alpha_t &amp;= {\rm softmax}(w^TM_t) \\
M_t &amp;= {\rm tanh}(W^YY_t + (W^hh_t)1^T)
\end{split}
\end{equation*} %]]&gt;&lt;/script&gt;

&lt;p&gt;ただし， $W^Y, W^h \in \mathbb{R}^{k \times k}, w \in \mathbb{R}^k$は学習パラメータである．また，$1 \in \mathbb{R}^L$である．&lt;/p&gt;

&lt;p&gt;→ ここでは時刻: $t$の出力ベクトル: $h_t$とそれ以前のL個の出力ベクトル: $Y_t$がどの程度関係しあっているかを求めている．&lt;br /&gt;
つまりL個のトークンの各重要度を算出している．&lt;/p&gt;

&lt;p&gt;(3) &lt;strong&gt;Attentionベクトルを生成する&lt;/strong&gt;&lt;br /&gt;
上記で算出したAttentionの重みを基に，Attentionベクトルを生成する．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r_t = Y_t\alpha^T&lt;/script&gt;

&lt;p&gt;(4) &lt;strong&gt;Attentionベクトルと元の出力ベクトルを結合する&lt;/strong&gt;&lt;br /&gt;
Concatではなく，以下の式に基づいて非線形に結合する．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_t^* = {\rm tanh}(W^rr_t + W^xh_t)\\&lt;/script&gt;

&lt;p&gt;ただし，$W^r, W^x \in \mathbb{R}^{k \times k}$は学習パラメータである．&lt;/p&gt;

&lt;p&gt;(5) &lt;strong&gt;出力ベクトルを求める&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_t = {\rm softmax}(W^*h_t^* + b)&lt;/script&gt;

&lt;p&gt;ただし，$W^* \in \mathbb{R}^{|V| \times k}$であり，$b \in \mathbb{R}^{|V|}$である．&lt;br /&gt;
ともに学習パラメータである．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-01/attention.png&quot; alt=&quot;ふつうのAttentionモデル&quot; style=&quot;width: auto;&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;提案手法&quot;&gt;提案手法&lt;/h2&gt;
&lt;h3 id=&quot;key-value-attention&quot;&gt;Key-value attention&lt;/h3&gt;
&lt;p&gt;key-value Attentionでは，出力ベクトルをkeyとvalueに分割する．&lt;br /&gt;
具体的には，時刻: $t$における出力ベクトルを以下のように定義し直す．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_t = [k_t, v_t] \in \mathbb{R}^{2k}&lt;/script&gt;

&lt;p&gt;また，　$h_t$が関与する式を書き直すと，以下のようになる．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{split}
M_t &amp;= {\rm tanh}(W^Y[k_{t-L}, \dots, k_{t-1}] + (W^hk_t)1^T) \\
r_t &amp;= [v_{t-L}, \dots, v_{t-1}]\alpha^T \\
h_t^* &amp;= {\rm tanh}(W^rr_t + W^xv_t)
\end{split} %]]&gt;&lt;/script&gt;

&lt;p&gt;なお，上記以外の式は前章と同じである．&lt;/p&gt;

&lt;p&gt;→ ここで，$k$は検索キーとしての役割を果たしており，$v$はその中身のデータを表していると考えるとわかりやすいかもしれない．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-01/k-v_attention.png&quot; alt=&quot;key-value attention&quot; style=&quot;width: auto;&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;key-value-predict-attention&quot;&gt;Key-value-predict attention&lt;/h3&gt;
&lt;p&gt;key-value attentionにおいても，valueが複数回使われていることがわかる．&lt;br /&gt;
そこで，valueをさらに分割し，key-value-predict型のAttentionを考案した．&lt;/p&gt;

&lt;p&gt;→ keyはattentionの重みを計算するのにのみ用いられ，valueは文脈表現をエンコードするのに使われ，predictは次のトークンの分布をエンコードするのに用いられる．&lt;br /&gt;
→ 完全分業制が達成されていることがわかる．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_t = [k_t, v_t, p_t] \in \mathbb{R}^{3k}　\\
h_t^* = {\rm tanh}(W^rr_t + W^xp_t)&lt;/script&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-01/k-v-p_attention.png&quot; alt=&quot;k-v-p attention&quot; style=&quot;width: auto;&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;実験結果&quot;&gt;実験結果&lt;/h2&gt;
&lt;h3 id=&quot;評価指標&quot;&gt;評価指標&lt;/h3&gt;
&lt;h4 id=&quot;パープレキシティ&quot;&gt;パープレキシティ&lt;/h4&gt;
&lt;p&gt;参考: &lt;a href=&quot;http://www.jnlp.org/lab/graduates/okada/nlp/term/entropy&quot;&gt;http://www.jnlp.org/lab/graduates/okada/nlp/term/entropy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;パープレキシティ(perplexity)とは，言語モデルにおいてモデルの複雑性を評価するのに使われる指標である． &lt;br /&gt;
パープレキシティは2のクロスエントロピー乗で定義され，一般に小さいほど良いモデルであるとされる．&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Perplexity = 2^{-\frac{1}{N}\sum_i^{N}\log P(w_i)}&lt;/script&gt;

&lt;p&gt;→ ここでの$P(w_i)$は言語モデルの単語出現確率を表している．&lt;br /&gt;
→ パープレキシティは単語の分岐数を意味しており，ある単語に対してそれに続く単語の平均候補数も意味している．&lt;/p&gt;

&lt;p&gt;つまり，複雑なモデルであるほど，平均候補数が増加するため，パープレキシティは大きくなるといえる．&lt;/p&gt;

&lt;h3 id=&quot;評価結果&quot;&gt;評価結果&lt;/h3&gt;
&lt;p&gt;提案手法： key-Value-Predictのパープレキシティが有意に小さいことがわかる．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-01/result1.png&quot; alt=&quot;実験結果1&quot; style=&quot;width: auto;&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-01/result2.png&quot; alt=&quot;実験結果2&quot; style=&quot;width: auto;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;(a)の図から，提案手法: key-value-predict attentionのおかげで，広範囲な文脈を考慮出来るようになっていることがわかる．&lt;br /&gt;
(b)の図から，より広範な文脈を考慮したとしても，パープレキシティが大幅に改善することは期待できないということが読み取れる．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-01/weight.png&quot; alt=&quot;注意機構の重み&quot; style=&quot;width: auto;&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;議論&quot;&gt;議論&lt;/h2&gt;
&lt;p&gt;Attentionを用いた言語モデルによって，従来手法よりもパープレキシティを改善することができた．&lt;br /&gt;
しかし，あまりにも長い文脈を考慮することは，パープレキシティの改善には得策ではないこともわかった．&lt;/p&gt;

&lt;p&gt;Future workとしては局所的な文脈の内容を考慮しないで，その背景にあるより大域的に関係する文脈を考慮できるような手法を考えることが挙げられる．&lt;/p&gt;

&lt;h2 id=&quot;次に読むべき論文は&quot;&gt;次に読むべき論文は？&lt;/h2&gt;
&lt;p&gt;Memory networksとか？&lt;br /&gt;
→ key-valueの概念を初めて導入したらしい．&lt;/p&gt;</content><author><name></name></author><category term="論文メモ" /><summary type="html">文献情報</summary></entry><entry xml:lang="ja_JP"><title type="html">はじめに</title><link href="http://localhost:4000/Introduction/" rel="alternate" type="text/html" title="はじめに" /><published>2019-03-31T00:00:00+09:00</published><updated>2019-03-31T00:00:00+09:00</updated><id>http://localhost:4000/Introduction</id><content type="html" xml:base="http://localhost:4000/Introduction/">&lt;p&gt;当サイトでは，機械学習と自然言語処理に関するトピックをブログ形式で扱います．&lt;br /&gt;
連絡等は，&lt;a href=&quot;/contact/&quot;&gt;お問い合わせフォーム&lt;/a&gt;か&lt;a href=&quot;https://twitter.com/_gucciiiii&quot;&gt;Twitter&lt;/a&gt;のDMにてお願いいたします．&lt;/p&gt;

&lt;p&gt;当サイトのご利用規約やプライバシーポリシーに関しては，&lt;a href=&quot;/privacy/&quot;&gt;こちら&lt;/a&gt;をご覧ください．&lt;/p&gt;</content><author><name></name></author><summary type="html">当サイトでは，機械学習と自然言語処理に関するトピックをブログ形式で扱います． 連絡等は，お問い合わせフォームかTwitterのDMにてお願いいたします．</summary></entry></feed>