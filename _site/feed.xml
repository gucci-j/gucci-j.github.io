<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-07-26T17:49:30+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">きままにNLP</title><subtitle>A Technical Blog about NLP and ML</subtitle><entry xml:lang="ja_JP"><title type="html">論文メモ：Decoupling Strategy and Generation in Negotiation Dialogues</title><link href="http://localhost:4000/Note-Decoupling/" rel="alternate" type="text/html" title="論文メモ：Decoupling Strategy and Generation in Negotiation Dialogues" /><published>2019-07-01T00:00:00+09:00</published><updated>2019-07-14T11:20:00+09:00</updated><id>http://localhost:4000/Note-Decoupling</id><content type="html" xml:base="http://localhost:4000/Note-Decoupling/">&lt;p&gt;本稿では，EMNLP 2018に採択された，自然言語で売り物の価格交渉をするエージェントを提案した論文：「Decoupling Strategy and Generation in Negotiation Dialogues」の論文のメモ書きを共有・紹介します．&lt;/p&gt;

&lt;h2 id=&quot;文献情報&quot;&gt;文献情報&lt;/h2&gt;
&lt;p&gt;著者: H. He et al.&lt;br /&gt;
所属: Computer Science Department, Stanford University&lt;br /&gt;
出典: &lt;a href=&quot;https://www.aclweb.org/anthology/D18-1256&quot;&gt;EMNLP 2018&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;どんなもの&quot;&gt;どんなもの？&lt;/h2&gt;

&lt;p&gt;自然言語で交渉可能なエージェントを作成する際に，交渉戦略とその実行部（発話機構）を切り分けて考えることで，従来手法よりもタスクの合意成功率を向上させ，発話に見られる人間らしさを向上させることに成功した．&lt;/p&gt;

&lt;h2 id=&quot;先行研究と比べてどこがすごい&quot;&gt;先行研究と比べてどこがすごい？&lt;/h2&gt;

&lt;p&gt;単にend-to-endでモデルを学習させるのではなく，「Parser・Manager・Generator」の三つにモデルを分割して捉えた点．（従来手法は，seq2seqに基づいて単に学習させるだけだった．）&lt;/p&gt;

&lt;p&gt;戦略を制御する部分は，従来の単語ベースではなく，coarse-dialogue acts：粗い（要約）対話情報に依存しているため，戦略の制御がしやすいというメリットがある．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/model_diagram.png&quot; alt=&quot;3モジュール型のモデル図&quot; style=&quot;width: 500px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://aclweb.org/anthology/papers/D/D18/D18-1256/&quot;&gt;Decoupling Strategy and Generation in Negotiation Dialogues&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;技術や手法のキモはどこ&quot;&gt;技術や手法のキモはどこ？&lt;/h2&gt;

&lt;p&gt;モジュール型のモデルを提案．戦略と生成を切り離して学習させることで，戦略の制御しやすさを維持しながらも，発話の人間らしさが低下しないようにできている．&lt;/p&gt;

&lt;h2 id=&quot;どうやって有効だと検証した&quot;&gt;どうやって有効だと検証した？&lt;/h2&gt;
&lt;h3 id=&quot;データセット&quot;&gt;データセット&lt;/h3&gt;
&lt;p&gt;クラウドソーシングサービスである，Amazon Mechanical Turk (AMT)を活用．クレイグスリストから交渉シナリオをスクレイピングして，AMTでそのシナリオに基づいた二者間の価格交渉を行わせることで，品物売買データセットを構築．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/table1.png&quot; alt=&quot;交渉ログの例&quot; style=&quot;width: 550px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;実験&quot;&gt;実験&lt;/h3&gt;
&lt;p&gt;Deal or no deal データセットと，著者らが作成した，Craigslist Bargain データセットにより実験を行なっている．人間らしさを5点満点でAMT上で評価．また，task-specificな値（効用，合意率，公平さ，対話の長さ）も計算．&lt;/p&gt;

&lt;h2 id=&quot;議論はある&quot;&gt;議論はある？&lt;/h2&gt;

&lt;p&gt;教師あり学習時は，著者の提案するモジュール型のモデルを使うとよいことが示されている．また，強化学習時も，wordベースではなくdialogue actベースにすると，報酬を最適化しつつ，発話の自然さも維持できることが示されている．&lt;/p&gt;

&lt;h2 id=&quot;1-はじめに&quot;&gt;1. はじめに&lt;/h2&gt;
&lt;p&gt;交渉エージェントは以下の二つの点をうまく実行できる必要がある．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;交渉戦略の立案&lt;/li&gt;
  &lt;li&gt;交渉戦略を実行するための自然言語の生成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;先行研究は「戦略」に着目したものが多かった．また，近年では，end-to-endに交渉戦略と言語生成の両方を同時に，人間同士の交渉を扱ったコーパスからニューラルネットワークベースのモデルにより学習を行う研究がでてきている (&lt;a href=&quot;https://aclweb.org/anthology/papers/D/D17/D17-1259/&quot;&gt;Lewis 2017&lt;/a&gt;, &lt;a href=&quot;https://aclweb.org/anthology/papers/P/P17/P17-1162/&quot;&gt;He 2017&lt;/a&gt;)．&lt;/p&gt;

&lt;p&gt;end-to-endに学習を行うモデルの問題点として，以下が挙げられる．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;交渉戦略の解釈 ＆ 制御の難しさ&lt;/li&gt;
  &lt;li&gt;強化学習で交渉エージェントを学習させると，発話が不自然になる（例：文法に則っていない）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そこで，著者らは戦略と生成を分離する手法の提案を行なっている．これにより，同じ生成器を用いていても，戦略を変更することができる．（例：効用を最大化する・公平な合意案を導く．）&lt;/p&gt;

&lt;h3 id=&quot;11-提案手法の概要&quot;&gt;1.1 提案手法の概要&lt;/h3&gt;
&lt;p&gt;提案手法のフレームワークは三つのモジュールからなる．&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Parser&lt;/strong&gt;&lt;br /&gt;
交渉相手の発言の意図やその変数：（価格）を解析&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Manager&lt;/strong&gt;&lt;br /&gt;
交渉エージェントの次の戦略（行動）を生成&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Generator&lt;/strong&gt;&lt;br /&gt;
戦略と発話履歴を基に返答文を生成&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/model_diagram.png&quot; alt=&quot;3モジュール型のモデル図&quot; style=&quot;width: 500px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://aclweb.org/anthology/papers/D/D18/D18-1256/&quot;&gt;Decoupling Strategy and Generation in Negotiation Dialogues&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;12-データセットについて&quot;&gt;1.2 データセットについて&lt;/h3&gt;
&lt;p&gt;先行研究で用いられているデータセットは，クローズドなドメイン：物の山分け交渉のみを扱っている．こうした設定は，実社会（real world）とは程遠い．そのため，craigslistと呼ばれる，クラシファイドコミュニティサイトから，物の売り買いに関するポスティングを抽出して，交渉シナリオを作成した．この交渉シナリオを基に，Amazon Mechanical Turk（AMT）を活用して，二者間での物の価格交渉を実施した．この交渉ログが本論文で用いられている，Craigslist Bargain データセットである．&lt;/p&gt;

&lt;h3 id=&quot;13-評価指標について&quot;&gt;1.3 評価指標について&lt;/h3&gt;
&lt;p&gt;獲得効用 ＆ 人間らしさで評価．&lt;br /&gt;
→ AMTを活用して，A/Bテストを行なって評価．&lt;/p&gt;

&lt;h2 id=&quot;2-データセット&quot;&gt;2. データセット&lt;/h2&gt;
&lt;p&gt;Settlers of catan データセットや，Deal or no deal データセットは，ゲーム形式の交渉対話データセットになっている．このため，対話が直接的（オファー内容をそのまま伝えてしまう）であった．本来の実社会の交渉では，「説得」や「情報収集」が入るので，先行研究のデータセットはあまり現実的でない．&lt;/p&gt;

&lt;p&gt;クレイグスリストデータセットでは，売り手と買い手になりきって，商品の売買を行う．より自然な状況設定なので，より現実的になるという主張．&lt;/p&gt;

&lt;p&gt;交渉シナリオの生成は，クレイグスリストの6カテゴリを選択した．（housing，furniture，cars，bikes，phones，electronics）．買い手の目標価格は，リスティング価格の0.5，0.7，0.9倍で設定されている．&lt;/p&gt;

&lt;p&gt;交渉ログの例とデータセットの統計は以下の表の通り．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/table1.png&quot; alt=&quot;交渉ログの例&quot; style=&quot;width: 550px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/table2.png&quot; alt=&quot;データセットの統計&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://aclweb.org/anthology/papers/D/D18/D18-1256/&quot;&gt;Decoupling Strategy and Generation in Negotiation Dialogues&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;先行研究とのデータセットの比較結果は次の通り．多ジャンルのデータセットなので，語彙数が多くなっている．さらに，発話あたりの単語数も多い．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/table3.png&quot; alt=&quot;データセットの比較&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://aclweb.org/anthology/papers/D/D18/D18-1256/&quot;&gt;Decoupling Strategy and Generation in Negotiation Dialogues&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;3-approach&quot;&gt;3. Approach&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;seq2seqベースのモデルは，戦略と生成の両方を同時に学習することは困難．（発話がかなり不自然になる．）&lt;br /&gt;
→ 戦略と生成を切り分けて考える&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;31-overview&quot;&gt;3.1 Overview&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;dialogue agentの役割&lt;/strong&gt;：&lt;br /&gt;
入力：発話履歴 $x_1, x_2, \dots, x_{t-1}$ と交渉シナリオ $c$&lt;br /&gt;
出力：返答 $x_t$ の確率分布&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;coarse dialogue act&lt;/strong&gt;：&lt;br /&gt;
$x_t$に対して，coarse dialogue act $z_t$ が設けられている．&lt;br /&gt;
例：$x_t$→ “I am willing to pay ＄15.” $z_t$→ “propose(price=15)”&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;モジュール型モデルの各定義&quot;&gt;モジュール型モデルの各定義&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;parser&lt;/strong&gt;&lt;br /&gt;
入力: $x_{t-1}$, 対話履歴 $x_{&amp;lt;t}$, $z_{&amp;lt;t}$, 交渉シナリオ $c$&lt;br /&gt;
出力: $z_{t-1}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;manager&lt;/strong&gt;&lt;br /&gt;
入力: $z_{&amp;lt;t}$，$c$&lt;br /&gt;
出力: $z_t$
    &lt;blockquote&gt;
      &lt;p&gt;$x_{&amp;lt;t}$ はcoarse dialogue actの決定には影響しない&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;generator&lt;/strong&gt;&lt;br /&gt;
入力: $z_t$, $x_{&amp;lt;t}$&lt;br /&gt;
出力: $x_t$&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;32-parser&quot;&gt;3.2 Parser&lt;/h3&gt;
&lt;p&gt;ルールベースのマッチングで，価格や物品に関する情報を抽出する．具体的には，正規表現とif文でマッチングをしているらしい．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/table5.png&quot; alt=&quot;ルールベースの抽出法の一覧&quot; style=&quot;width: 350px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://aclweb.org/anthology/papers/D/D18/D18-1256/&quot;&gt;Decoupling Strategy and Generation in Negotiation Dialogues&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;33-manager&quot;&gt;3.3 Manager&lt;/h3&gt;
&lt;p&gt;dialogue managerは，各タイムステップ $t$ において，過去のcoarse dialogue acts 履歴 $z_{&amp;lt;t}$ と，交渉シナリオ $c$ から，次に取る行動 $z_t$ を策定する．&lt;/p&gt;

&lt;p&gt;Managerの学習手法は，教師あり学習，強化学習，ハイブリッド方式の三つが用いられている．&lt;/p&gt;

&lt;h4 id=&quot;331-教師あり学習&quot;&gt;3.3.1 教師あり学習&lt;/h4&gt;
&lt;p&gt;人間の振る舞いをモデリングするのに最適な学習手法．&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;入力&lt;/strong&gt;: 各学習データは，各対話のcoarse dialogue acts $z_1, \dots. z_T$ からなる．&lt;br /&gt;
&lt;strong&gt;出力&lt;/strong&gt;: $p_\theta (z_t | z_{&amp;lt;t}, c)$&lt;/p&gt;

&lt;p&gt;学習は学習データの尤度を最大化することで行う．
モデルは，通常のseq2seqモデルに注意機構を付加したものである．各dialogue actは，通常のトークンとして入力される．例：offer 150．この場合，語彙数はかなり少なくなる．&lt;/p&gt;

&lt;h4 id=&quot;332-強化学習&quot;&gt;3.3.2 強化学習&lt;/h4&gt;
&lt;p&gt;報酬 $R(z_{1:T})$ をcoarse dialogue actsのひとまとまりに対して適用．3つの報酬関数により実験を行う．&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Utility&lt;/strong&gt;&lt;br /&gt;
クレイグスリストデータセットでは，ゼロサムゲームとして与える．それ以外のFBのような二者間山分け交渉の場合は，総和となる．&lt;/p&gt;

    &lt;p&gt;クレイグスリストでは，目標価格で購入 or 販売できたときにのみ，効用として，1を獲得でき，それ以外の場合には，0を獲得する&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fairness&lt;/strong&gt; &lt;br /&gt;
二者間の効用になるべく差がなくなるようにする．平等重視．計算方法としては，二者間の効用の差で表される．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Length&lt;/strong&gt;&lt;br /&gt;
長く会話させるための指標．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;合意が形成されなかった場合，報酬は一律に$-1$  である．
最適化には，policy gradient（方策勾配法）を用いる．パラメータは以下の式(1)に基づいて更新される．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\theta \leftarrow \theta - \eta \sum_{i} \nabla_\theta \log p_\theta (a_i | a_{&amp;lt; i}, c)(r - b) \tag{1}
$$
&lt;/div&gt;

&lt;p&gt;ただし，$\eta$ は学習率，$b$ は出力の平均から推定されるベースライン．$a_i$ は生成されたトークン（policyが取る行動）を意味しており，$z_{1:T}$に対応している．&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;方策勾配法について&lt;br /&gt;
方策勾配法は価値関数 $Q^{\pi_\theta}(s, a)$ を実際に得られた報酬の合計で近似するもの．&lt;br /&gt;
ベースラインを設けるのは，期待値の分散を減らすため（variance reduction)． これによって，モデルの学習を成功させやすくなるらしい．&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;333-hybrid-policy&quot;&gt;3.3.3 Hybrid Policy&lt;/h4&gt;
&lt;p&gt;coarse dialogue actsが与えられたとき，ドメインに関する知識があれば，ルールベースのmanagerを作成できる．&lt;/p&gt;

&lt;p&gt;例：$z_{t-1} = {\rm greet}$ のとき，$z_{t}$ も $\rm greet$ とする．&lt;/p&gt;

&lt;p&gt;実用的には，学習済みのmanagerを用いて，意図（行動）を決定させて，それに関する変数は，ルールベースで決定するものである．&lt;/p&gt;

&lt;h3 id=&quot;34-generator&quot;&gt;3.4 Generator&lt;/h3&gt;
&lt;p&gt;generatorは，coarse dialogue actと対話履歴の両方に基づいて，検索ベースにより発話内容を決定する．&lt;/p&gt;

&lt;p&gt;検索対象の候補はタプルとして保存されている：$(d(x_{t-1}), z_{t-1}, d(x_t), z_t)$&lt;br /&gt;
$d$はテンプレート抽出器：”How about ＄150?”という文があったら，”How about [price]?”と置き換えられる．[price] 部分は生成時に穴埋めされる．&lt;/p&gt;

&lt;p&gt;テスト時には，$z_t$ が与えられたら，まず，$z_t$ と $z_{t-1}$ と同じ意図を持つ候補を検索する．候補はテンプレートと現在の対話のコンテキストの類似度で評価される．具体的には，テンプレート $d(x_{t-1})$ はTF-IDFで重み付けされた，BoWベクトルであり，類似度は二つのコンテキストベクトル間の内積で得られる．&lt;/p&gt;

&lt;h2 id=&quot;4-experiments&quot;&gt;4. Experiments&lt;/h2&gt;
&lt;h3 id=&quot;41-models&quot;&gt;4.1 Models&lt;/h3&gt;
&lt;p&gt;まず，教師あり学習によってモデルを学習させる．このとき，2種類のモデルを比較する．&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SL(word)&lt;/strong&gt;:  seq2seq + attention&lt;br /&gt;
ベクトルはCBoWで埋め込み．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SL(act)&lt;/strong&gt;: モジュール型のモデル&lt;br /&gt;
ルールベースのパーサー，学習済みのmanager，検索ベースのgeneratorからなる．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;クレイグスリストデータセットには様々な価格帯があるので，値段を正規化して扱う．（target priceが1，bottomline priceが0．）売り手のbottomlineは，listing priceの0.7倍．買い手のbottomlineはlisting price．&lt;/p&gt;

&lt;p&gt;教師あり学習で学習させたモデルを用いて，強化学習でfine-tuneする．モデルの詳細は以下の表6の通り．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/table6.png&quot; alt=&quot;実験モデルの一覧&quot; style=&quot;width: 350px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://aclweb.org/anthology/papers/D/D18/D18-1256/&quot;&gt;Decoupling Strategy and Generation in Negotiation Dialogues&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;42-実験設定&quot;&gt;4.2 実験設定&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SL(word)&lt;/strong&gt;&lt;br /&gt;
3個前までの発言をattentionの対象にする．交渉シナリオは，CBoWで埋め込み．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SL(word) / SL(act)の両方&lt;/strong&gt;&lt;br /&gt;
GloVe埋め込み：300次元&lt;br /&gt;
2層のLSTM：300次元&lt;br /&gt;
パラメータは-0.1から0.1の一様分布で初期化&lt;br /&gt;
AdaGrad：（学習率：0.01，バッチサイズ：128）&lt;br /&gt;
20エポック学習&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;RL&lt;/strong&gt;&lt;br /&gt;
学習率：0.001&lt;br /&gt;
5000エピソード学習&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;43-人間による評価&quot;&gt;4.3 人間による評価&lt;/h3&gt;
&lt;p&gt;二つの指標により評価．&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;task specificなスコア&lt;/strong&gt;&lt;br /&gt;
効用・合意案の公平性・発話の長さ・合意率&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;human-likeness&lt;/strong&gt;&lt;br /&gt;
1〜5の5段階評価．高ければ高いほど良い．スコアはAMTのworkerによりつけられた．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;表7の意味するところ&quot;&gt;表7の意味するところ&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;教師あり学習をつけると人間らしさが向上．ただし，actベースの方がスコアが良い．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;強化学習をつけると，wordベースのときは人間らしさが低下する．一方で，actベースのときは報酬を最適化しながらも，人間らしさを維持している．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/table7.png&quot; alt=&quot;ルールベースの抽出法の一覧&quot; style=&quot;width: 500px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-07-01/table8.png&quot; alt=&quot;対話履歴の比較&quot; style=&quot;width: 500px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://aclweb.org/anthology/papers/D/D18/D18-1256/&quot;&gt;Decoupling Strategy and Generation in Negotiation Dialogues&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;スライド&quot;&gt;スライド&lt;/h2&gt;
&lt;p&gt;(&lt;strong&gt;追加&lt;/strong&gt;: 2019/07/14)&lt;/p&gt;
&lt;div style=&quot;text-align: center&quot;&gt;&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/3L3ugPvxSRAt6o&quot; width=&quot;510&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;</content><author><name></name></author><category term="論文メモ" /><summary type="html">本稿では，EMNLP 2018に採択された，自然言語で売り物の価格交渉をするエージェントを提案した論文：「Decoupling Strategy and Generation in Negotiation Dialogues」の論文のメモ書きを共有・紹介します．</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/resources/2019-07-01/model_diagram.png" /></entry><entry xml:lang="ja_JP"><title type="html">サポートベクターマシンのお話</title><link href="http://localhost:4000/memo-svm/" rel="alternate" type="text/html" title="サポートベクターマシンのお話" /><published>2019-06-23T00:00:00+09:00</published><updated>2019-06-23T00:00:00+09:00</updated><id>http://localhost:4000/memo-svm</id><content type="html" xml:base="http://localhost:4000/memo-svm/">&lt;p&gt;サポートベクターマシン（SVM）は，深層学習によらない機械学習の手法の一つとして広く知られており，あるデータに関する事前知識が全く無いような場合に有効な手法と言われています．&lt;/p&gt;

&lt;p&gt;ここでは，個人的な備忘録として，SVMの考え方を少しずつ厳選して扱います．&lt;/p&gt;

&lt;h2 id=&quot;お膳立て&quot;&gt;お膳立て&lt;/h2&gt;

&lt;p&gt;今，図のような分布の「●と😀の二値分類」をしたいときに，パーセプトロン系のネットワークでモデルを構築した場合，その識別面（境界線）は次の図の点線になるかもしれない．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-06-23/empirical_example.png&quot; alt=&quot;いろんな境界線の比較&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;p&gt;パーセプトロンのようなネットワークでは，経験損失（empirical loss）の最小化によって学習が行われる．なので，境界線がスレスレであっても，訓練データに対して損失を最小化するように学習して引かれた正しい線である場合がある．しかしながら，境界線がスレスレだと，テストデータで分類した時に，「●と😀」が間違えて分類されてしまう可能性があり，あまり嬉しくない．&lt;/p&gt;

&lt;p&gt;SVMは，この問題に対処することで汎化性能をあげようとしているモデルである．SVMの学習は，汎化損失（generalization loss）の最小化により行われる．着想としては，テストデータは訓練データと同じ確率分布に従っているものと仮定して，境界面（separator；識別面）と観測データの距離がなるべく大きくなるような境界面を選ぶことで，汎化損失の最小化を目指すものである．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-06-23/svm_example.png&quot; alt=&quot;SVMの境界面の例と用語定義&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;用語の定義&quot;&gt;用語の定義&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;サポートベクトル（support vector）&lt;/strong&gt;&lt;br /&gt;
境界面（separator；識別面）にもっとも近い点のことをサポートベクトルと呼ぶ．サポートと呼ばれる所以は，サポートベクトルが境界面を「支えている」ことから来ているらしい．&lt;/p&gt;

    &lt;p&gt;通常，サポートベクトルの数は本来のサンプルサイズよりも小さくなるので，SVMはパラメトリックなモデルよりも更新の計算量が少なく済む．（サポートベクトル以外のデータが変化しても，境界は変化しないため．）また，重要なベクトルだけを見ればよいので，汎化性能も向上すると考えられる．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;マージン（margin）&lt;/strong&gt;&lt;br /&gt;
図中で点線によって囲われた範囲をマージンと呼ぶ．マージンは境界面と境界面からもっとも近い点（観測データ）との距離の2倍となる．&lt;/p&gt;

    &lt;p&gt;SVMにおいて，「境界面と観測データの距離がなるべく大きくなるように学習する」ということは，「マージンをなるべく大きくするように学習する」ということを意味している．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;用語の数式的定義&quot;&gt;用語の数式的定義&lt;/h3&gt;

&lt;p&gt;以降，簡単にではあるが数式で説明を行うため，あまり書かれていない基本的な部分の計算手法について説明する．&lt;/p&gt;

&lt;h4 id=&quot;識別面の数式的表記&quot;&gt;識別面の数式的表記&lt;/h4&gt;

&lt;p&gt;識別面は，入力データが $\boldsymbol{x}$ と表されるとき，以下のように表される．&lt;/p&gt;
&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\boldsymbol{w^Tx} + b = 0
$$
&lt;/div&gt;
&lt;p&gt;ここで，$\boldsymbol{w}$ は重みベクトルであり，$b$ はバイアスベクトルである．また，各サポートベクトルが作る直線（上図の点線に相当する）は，$\boldsymbol{w^Tx} + b = 1$ か $\boldsymbol{w^Tx} + b = -1$ で定義される．&lt;/p&gt;

&lt;h4 id=&quot;マージンの数式的表記&quot;&gt;マージンの数式的表記&lt;/h4&gt;

&lt;p&gt;さて，$\boldsymbol{w^Tx} + b = 1$ となるような，$\boldsymbol{x}$ のうちの一つを，$\boldsymbol{x}_1$ とする．また，$\boldsymbol{w^Tx} + b = -1$ となるような，$\boldsymbol{x}$ のうちの一つを，$\boldsymbol{x}_2$ とする．&lt;/p&gt;

&lt;p&gt;このとき，境界面と，サポートベクトル $\boldsymbol{x}_1$ の距離 $r_1$は，垂線の公式の拡張版を用いて，次のように表される．&lt;/p&gt;
&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
r_1 = \frac{\boldsymbol{w^Tx}_1 + b }{||\boldsymbol{w}||}
$$
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;ここではイメージを掴むのが目的なので，垂線の公式については触れません．&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;したがって，マージン: $m$は次のように表される．&lt;/p&gt;
&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\begin{equation}
\begin{split}
m &amp;amp;= \frac{\boldsymbol{w^Tx}_1 + b }{||\boldsymbol{w}||} - \frac{\boldsymbol{w^Tx}_2 + b }{||\boldsymbol{w}||}\\
&amp;amp;= \frac{\boldsymbol{w^T}(\boldsymbol{x}_1 - \boldsymbol{x}_2)}{||\boldsymbol{w}||}\\
&amp;amp;= \frac{2}{||\boldsymbol{w}||}
\end{split}
\end{equation}
$$
&lt;/div&gt;
&lt;p&gt;ただし，$\boldsymbol{w^Tx}_1 + b = 1$ と $\boldsymbol{w^Tx}_2 + b = -1$ から，$\boldsymbol{w^T}(\boldsymbol{x}_1 - \boldsymbol{x}_2) = 2$ となることを用いた．&lt;/p&gt;

&lt;h2 id=&quot;svmの学習方法&quot;&gt;SVMの学習方法&lt;/h2&gt;

&lt;p&gt;SVMの学習方法は2種類あり，直感的な解き方としては，マージンを最大化する問題を解くことであり，そこから派生した解法も存在する．そのため，以下で紹介する2手法は双対問題と言われる．双対問題とは，ある最適化問題の制約条件を用いて，より最適化しやすい問題に置き換えて解くような問題のことをいい，どちらかの解が両方の解になる性質を持つ．&lt;/p&gt;

&lt;h3 id=&quot;マージン最大化主問題&quot;&gt;マージン最大化（主問題）&lt;/h3&gt;
&lt;h4 id=&quot;マージン最大化の定式化&quot;&gt;マージン最大化の定式化&lt;/h4&gt;
&lt;p&gt;さて，マージンは，$\frac{2}{||\bm{w}||}$ で定義されることを先ほど示した．マージンを最大化することは，重みベクトルのノルムを最小化することに他ならない．したがって，式でマージン最大化を表すと，$\argmax_{\bm{w}} \frac{2}{||\bm{w}||}$ となる．これでは，最適化をする際に計算の都合上扱いにくいので，大半の説明では以下が等価であるとみなしている．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\argmin_{\bm{w}} \frac{1}{2} ||w||^2
$$
&lt;/div&gt;

&lt;h4 id=&quot;マージン最大化の制約条件&quot;&gt;マージン最大化の制約条件&lt;/h4&gt;
&lt;p&gt;最適化のための制約条件について考える．入力データ $\{ \bm{x}_1, \bm{x}_2, \bm{x}_3, \dots, \bm{x}_n \}$ があったときに，それに対応する（正解）ラベルデータが，$\{ y_1, y_2, y_3, \dots, y_n \}$ であるとする．ただし，$y_i$ は，$1$か$-1$をとる．このとき，以下の制約条件が成り立つ．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
y_i (\bm{w}^T\bm{x}_i + b) \ge 1 \qquad{\rm for} \; i=1,\dots, n
$$
&lt;/div&gt;

&lt;p&gt;したがって，マージン最大化は上記の制約条件をもとに，条件を満たす重みベクトルを探す問題に帰着される．&lt;/p&gt;

&lt;h3 id=&quot;ラグランジュの未定乗数法による方法補問題&quot;&gt;ラグランジュの未定乗数法による方法（補問題）&lt;/h3&gt;
&lt;p&gt;一方で，別の解き方も存在して，ラグランジュの未定乗数法を使う解き方がある．ラグランジュアンを活用することで，上記のマージン最大化問題は次のように書き換えられる．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\mathcal{L}(\bm{w}, b, \alpha) = \frac{1}{2}||\bm{w}||^2 + \sum_{i=1}^{n} \alpha_i (1 - y_i(\bm{w}^T\bm{x_i} + b))
$$
&lt;/div&gt;

&lt;p&gt;このとき，最適化条件を考慮すると，以下が得られる．&lt;/p&gt;
&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\begin{equation}
\begin{split}
\frac{\partial}{\partial \bm{w}} \mathcal{L} &amp;amp;= \bm{w} - \sum_{i=1}^{n} \alpha_i y_i \bm{x}_i = 0\\
\frac{\partial}{\partial b} \mathcal{L} &amp;amp;= - \sum_{i=1}^{n} \alpha_i y_i = 0
\end{split}
\end{equation}
$$
&lt;/div&gt;

&lt;p&gt;上記の最適化条件を，元のラグランジュアン $\mathcal{L}$ に代入して計算すると，以下が得られる．&lt;/p&gt;
&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\mathcal{L}(\bm{w}, b, \alpha) = \sum_{i=1}^{n} \alpha_i - \frac{1}{2}\sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\bm{x}_i^T \bm{x}_j) \tag{1}
$$
&lt;/div&gt;

&lt;p&gt;また，双対問題時のKKT条件を考慮することにより，追加の制約条件: $\alpha_i \ge 0$ を得られる．以上から，マージン最大化の問題は，ラグランジュ関数を活用することで，$\alpha$ を最大化する問題に落としこむことができる．式で表すと下記のようになる．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\argmax_\alpha \sum_{i=1}^{n} \alpha_i - \frac{1}{2}\sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\bm{x}_i^T \bm{x}_j)
$$
&lt;/div&gt;

&lt;p&gt;これは，二次計画問題であるため，ソルバーを使えば最適解を得ることができる．最適なベクトル $\alpha$ を見つけることができれば，最適化条件である，$\bm{w} = \sum_{i=1}^{n} \alpha_i y_i \bm{x}_i$ を用いて，重みベクトル $\bm{w}$ も芋づる式に求めることができる．また，バイアス $b$ についても，上述のマージン最大化の制約条件から算出することができる．これによって，識別関数を求めることができるので，ラグランジュの未定乗数法による方法で，SVMの学習ができることがわかった．&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考：&lt;a href=&quot;https://qiita.com/AnchorBlues/items/8fe2483a3a72676eb96d&quot;&gt;ベクトルの微分&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考：&lt;a href=&quot;https://ja.wikipedia.org/wiki/%E3%82%AB%E3%83%AB%E3%83%BC%E3%82%B7%E3%83%A5%E3%83%BB%E3%82%AF%E3%83%BC%E3%83%B3%E3%83%BB%E3%82%BF%E3%83%83%E3%82%AB%E3%83%BC%E6%9D%A1%E4%BB%B6&quot;&gt;KKT条件&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2手法の比較&quot;&gt;2手法の比較&lt;/h3&gt;

&lt;p&gt;ラグランジュの未定乗数法を用いる手法の方が種々の利点がある．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\mathcal{L}$ は凸関数であるため，唯一の大域最適解を見つけやすい．&lt;/li&gt;
  &lt;li&gt;サポートベクトル以外の$\alpha_i$ は0となるため，計算が少なく済む．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;線形分離不可能なときは&quot;&gt;線形分離不可能なときは？&lt;/h2&gt;

&lt;p&gt;入力データが線形分離できない場合，非線形変換を施して高次元空間に写像してしまえば，分類可能となるときがある．例として，ある特徴空間 $F(\bm{x})$ が，次のように定義されるとする．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
F([x_1, x_2]) = (x_1^2, x_2^2, \sqrt{2} x_1 x_2)
$$
&lt;/div&gt;

&lt;p&gt;このとき，$F(\bm{x})$ でのラグランジュアン: 式(1)は次のように書き換えられる．&lt;/p&gt;
&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\mathcal{L}(\bm{w}, b, \alpha) = \sum_{i=1}^{n} \alpha_i - \frac{1}{2}\sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j F(\bm{x}_i) F(\bm{x}_j) \tag{2}
$$
&lt;/div&gt;

&lt;p&gt;式(2)の値を求めるには，高次元空間 $F(\bm{x})$ での内積 $F(\bm{x}_i) \cdot F(\bm{x}_j)$の値を計算する必要がある．今回の例の場合，高次元空間における内積を計算してみると，以下のようになる．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\begin{equation}
\begin{split}
F(\bm{x}_i) \cdot F(\bm{x}_j) &amp;amp;= 
\begin{bmatrix}
x_{i_1}^2\\
x_{i_2}^2\\
\sqrt{2} x_{i_1}x_{i_2} 
\end{bmatrix}
\cdot 
\begin{bmatrix}
x_{j_1}^2\\
x_{j_2}^2\\
\sqrt{2} x_{j_1}x_{j_2} 
\end{bmatrix}\\
&amp;amp;= x_{i_1}^2 x_{j_1}^2 + x_{i_2}^2 x_{j_2}^2 + 2x_{i_1}x_{i_2}x_{j_1}x_{j_2} 
\end{split}
\end{equation}
$$
&lt;/div&gt;

&lt;p&gt;高次元空間に変換してから内積を計算する手間がお分かりになったと思う．&lt;/p&gt;

&lt;p&gt;そんなところに朗報で，実は上記の内積は変換前における，$(\bm{x_i}\cdot\bm{x_j})^2$ の演算結果に一致する．この$(\bm{x_i}\cdot\bm{x_j})^2$ を，&lt;strong&gt;カーネル関数&lt;/strong&gt;（kernel function）と呼ぶ．カーネル関数さえわかれば，元の空間でのベクトル演算だけで済むので，逐一各入力ベクトルの値を高次元空間に写像する処理は必要なく，少ない手間で線形分離できないデータに対応することができる．このことを&lt;strong&gt;カーネルトリック&lt;/strong&gt;ともいう．&lt;/p&gt;

&lt;h3 id=&quot;種々のカーネル関数&quot;&gt;種々のカーネル関数&lt;/h3&gt;

&lt;p&gt;カーネル関数はいくつか種類があり，多項式カーネルとガウスカーネルが有名である．&lt;/p&gt;

&lt;h4 id=&quot;多項式カーネル&quot;&gt;多項式カーネル&lt;/h4&gt;
&lt;p&gt;多項式カーネルは次のように定義される．&lt;/p&gt;
&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
K(\bm{x}_i, \bm{x}_j) = (\bm{x}_i^T \bm{x}_j + 1)^d
$$
&lt;/div&gt;

&lt;h4 id=&quot;ガウスカーネル&quot;&gt;ガウスカーネル&lt;/h4&gt;
&lt;p&gt;ガウスカーネル（RBFカーネルと表記されていることが多い）は次のように定義される．&lt;/p&gt;
&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
K(\bm{x}_i, \bm{x}_j) = \exp(-\beta||\bm{x}_i - \bm{x}_j||^2)
$$
&lt;/div&gt;
&lt;p&gt;ただし，$\beta$は正の定数．なお，実際にSVMでデータ分類をする際には，ガウスカーネルを使う場合が多いようである．&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考：&lt;a href=&quot;https://dev.classmethod.jp/machine-learning/svm-kernel/&quot;&gt;SVMのカーネルについて&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;ソフトマージンとハードマージン&quot;&gt;ソフトマージンとハードマージン&lt;/h2&gt;

&lt;p&gt;理想的な環境であればデータにノイズが入ることはない．しかし，現実にはそうはいかない．今まで説明してきたSVMの考え方を元に，ノイズの入ったデータを分類させると，ノイズにサポートベクトルが左右されてしまうため，分類がうまくいかなくなってしまう．そこで，ソフトマージンという考え方が一般に知られている．反対に，これまで説明してきたSVMのマージンの決め方は，ハードマージンと呼ばれる．&lt;/p&gt;

&lt;h2 id=&quot;svmを実用する&quot;&gt;SVMを実用する&lt;/h2&gt;

&lt;p&gt;今回は量が多くなってしまったので理論だけに留めておきますが，Pythonのライブラリである，scikit-learnにはSVMが実装されています．これを使えばひとまずは実データで分類ができるでしょう．&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照：&lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html&quot;&gt;scikit-learnにおけるSVMのドキュメント&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="機械学習全般" /><summary type="html">サポートベクターマシン（SVM）は，深層学習によらない機械学習の手法の一つとして広く知られており，あるデータに関する事前知識が全く無いような場合に有効な手法と言われています．</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/resources/2019-06-23/svm_example.png" /></entry><entry xml:lang="ja_JP"><title type="html">torchtextでk-分割交差検証をする話</title><link href="http://localhost:4000/cv-with-torchtext/" rel="alternate" type="text/html" title="torchtextでk-分割交差検証をする話" /><published>2019-06-09T00:00:00+09:00</published><updated>2019-06-09T00:00:00+09:00</updated><id>http://localhost:4000/cv-with-torchtext</id><content type="html" xml:base="http://localhost:4000/cv-with-torchtext/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/pytorch/text&quot;&gt;torchtext&lt;/a&gt;は，PyTorchで自然言語処理（NLP）系のデータを比較的簡単に読み込むことができるライブラリとして有名です．しかし，とっつきやすい性質を持つ分，細かいところで苦戦する場合があります．その一例として，交差検証をやりにくいという点が挙げられます．&lt;/p&gt;

&lt;p&gt;正確には，torchtextで処理したデータを用いて交差検証をした例がネット上に少ないことに加え，torchtextのドキュメントにそれに関する記述がないことも災いしていると思われます．&lt;/p&gt;

&lt;p&gt;通常なら，torchtextで交差検証をするのは諦めて，&lt;a href=&quot;https://github.com/skorch-dev/skorch&quot;&gt;skorch&lt;/a&gt;などの他のライブラリを使うと思いますが，ここではあえて「torchtext」と「sklearn」の &lt;code class=&quot;highlighter-rouge&quot;&gt;KFold&lt;/code&gt; を使うことで交差検証を適用する方法を紹介したいと思います．&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://towardsdatascience.com/use-torchtext-to-load-nlp-datasets-part-ii-f146c8b9a496&quot;&gt;Use torchtext to Load NLP Datasets — Part II&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;1-タスク設定&quot;&gt;1. タスク設定&lt;/h2&gt;
&lt;p&gt;映画レビュー文データセットである，IMDBデータセットを用いたネガティブ・ポジティブの2値分類タスクを解くモデルを，k分割交差検証にかけてみます．&lt;/p&gt;

&lt;p&gt;ベースにするモデルは，GRUとSelf-Attentionで構成されたモデルです．この実装は，&lt;a href=&quot;https://github.com/gucci-j/imdb-classification-gru&quot;&gt;GitHub&lt;/a&gt;にて公開してあります．&lt;/p&gt;

&lt;h2 id=&quot;2-実装&quot;&gt;2. 実装&lt;/h2&gt;
&lt;p&gt;それでは，torchtextで読み込んだデータを交差検証にかけられるようにしていきましょう．&lt;/p&gt;

&lt;h3 id=&quot;21-データローダ側&quot;&gt;2.1 データローダ側&lt;/h3&gt;
&lt;h4 id=&quot;211-初期設定--コンストラクタ&quot;&gt;2.1.1 初期設定 ＆ コンストラクタ&lt;/h4&gt;

&lt;p&gt;コンストラクタ内では，通常のtorchtextの用法と同じく，&lt;code class=&quot;highlighter-rouge&quot;&gt;datasets.IMDB.splits()&lt;/code&gt; でIMDBデータセットを呼び出すようにします．&lt;/p&gt;

&lt;p&gt;返り値は，self.train_data, self.test_data として保持しておきます．&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchtext&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KFold&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SEED&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1234&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manual_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SEED&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manual_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SEED&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backends&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cudnn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deterministic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'spacy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;LABEL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LabelField&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMDB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LABEL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SEED&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SEED&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;212-学習データ読み込み&quot;&gt;2.1.2 学習データ読み込み&lt;/h4&gt;

&lt;p&gt;学習データを読み込む際は，&lt;code class=&quot;highlighter-rouge&quot;&gt;get_fold_data()&lt;/code&gt; を使うようにします．&lt;/p&gt;

&lt;p&gt;scikit-learnの &lt;code class=&quot;highlighter-rouge&quot;&gt;model_selection.KFold&lt;/code&gt; クラスを使うことで，データセットを交差分割用に分割します．scikit-learnを普段から使っている人なら，おなじみかもしれません．&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;KFold&lt;/code&gt; のメソッドである，&lt;code class=&quot;highlighter-rouge&quot;&gt;split&lt;/code&gt; は，引数にNumPy配列を渡す必要があるので，torchtextから生成されたデータセットでは型エラーとなってしまいます．そこで，データをNumPy配列に変換して渡してあげると型エラーにならずに動作してくれます．&lt;/p&gt;

&lt;p&gt;しかしながら，無理やりNumPy配列に変換したことによる弊害も生じます．というのも，そのまま，&lt;code class=&quot;highlighter-rouge&quot;&gt;torchtext.data.Iterator&lt;/code&gt; にデータを渡すと，再び型エラーになってしまいます．学習をラクして回すためにイテレータは欲しいところです．&lt;/p&gt;

&lt;p&gt;そこで，&lt;code class=&quot;highlighter-rouge&quot;&gt;torchtext.data.Dataset&lt;/code&gt; にNumPy配列に変換されてしまった学習データを渡して，イテレータを生成できる状態に戻してあげます．&lt;/p&gt;

&lt;p&gt;以上が，学習データの読み込み部分になります．&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_fold_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_folds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'spacy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;LABEL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LabelField&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'label'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LABEL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;kf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KFold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_folds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SEED&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_data_arr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_index&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data_arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;LABEL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data_arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data_arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;213-テストデータ読み込み&quot;&gt;2.1.3 テストデータ読み込み&lt;/h4&gt;

&lt;p&gt;テストデータの読み込みは，NumPy配列に変換する必要もないので，メソッドが呼び出されたら，そのままデータを渡してあげるだけで大丈夫です．&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;22-呼び出し側&quot;&gt;2.2 呼び出し側&lt;/h3&gt;

&lt;p&gt;呼び出し側は基本的には，交差検証無しの&lt;a href=&quot;https://github.com/gucci-j/imdb-classification-gru&quot;&gt;ベースモデル&lt;/a&gt;と同じです．&lt;/p&gt;

&lt;p&gt;追加されている点としては，&lt;code class=&quot;highlighter-rouge&quot;&gt;data.Iterator&lt;/code&gt; でイテレータを生成する作業が追加されていることです．また，各foldでの結果を保存するために，リスト: &lt;code class=&quot;highlighter-rouge&quot;&gt;_history&lt;/code&gt; を用意してあります．&lt;/p&gt;

&lt;p&gt;細かい点は，&lt;a href=&quot;https://github.com/gucci-j/pytorch-imdb-cv&quot;&gt;GitHub&lt;/a&gt;にて実装を公開しているので，そちらを参照いただければと思います．&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LABEL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_data&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_generator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_fold_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;glove.6B.300d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;LABEL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'embedding_dim'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hidden_dim'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'output_dim'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'num_layers'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dropout'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BCEWithLogitsLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gpu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gpu_number'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gpu_number'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cuda'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cpu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;train_iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'batch_size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sort_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'batch_size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sort_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eval_run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Val. Loss: {val_loss:.3f} | Val. Acc: {val_acc*100:.2f}&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;% &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;|'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;_history&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;_history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'LOSS: {loss}, ACC: {acc}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;やや駆け足の解説となりましたが，一回NumPy配列に変換してあげることで交差検証が可能になるので，どうしてもtorchtextでデータセットを読み込みたい人には使えるテクニックだと思います．&lt;/p&gt;

&lt;p&gt;実際のところtorchtextのレポジトリを見ると，交差検証に関するissueが出ているので，この機能を設けて欲しい人はそれなりにいるみたいですね．（ですが，今の所はこの投稿のような形で無理やり対処するしかないでしょう…）&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは，&lt;a href=&quot;https://github.com/gucci-j/pytorch-imdb-cv&quot;&gt;GitHub&lt;/a&gt;にて公開しています．&lt;/p&gt;</content><author><name></name></author><category term="Tips" /><category term="PyTorch" /><summary type="html">はじめに torchtextは，PyTorchで自然言語処理（NLP）系のデータを比較的簡単に読み込むことができるライブラリとして有名です．しかし，とっつきやすい性質を持つ分，細かいところで苦戦する場合があります．その一例として，交差検証をやりにくいという点が挙げられます．</summary></entry><entry xml:lang="ja_JP"><title type="html">論文メモ：Attention Is All You Need</title><link href="http://localhost:4000/Note-Transformer/" rel="alternate" type="text/html" title="論文メモ：Attention Is All You Need" /><published>2019-05-23T00:00:00+09:00</published><updated>2019-05-30T15:00:00+09:00</updated><id>http://localhost:4000/Note-Transformer</id><content type="html" xml:base="http://localhost:4000/Note-Transformer/">&lt;p&gt;Googleが昨年発表した，BERT：Bidirectional Encoder Representation for Transformersは，様々なNLPタスクにおいて当時の最高スコアを記録し，世界中で瞬く間に注目を浴びることとなりました．結果として，BERTはNAACL 2019のBest Long Paper Awardにも輝いています．&lt;/p&gt;

&lt;p&gt;ここでは，そんなBERTの基本構成要素となっている，Transformerについての論文メモを共有します．&lt;/p&gt;

&lt;p&gt;なお，BERTを理解するためにTransformerを雰囲気でつかみたい方は，&lt;a href=&quot;#まとめスライド&quot;&gt;末尾のスライド&lt;/a&gt;を参照すると参考になるかもしれません．&lt;/p&gt;

&lt;h2 id=&quot;文献情報&quot;&gt;文献情報&lt;/h2&gt;
&lt;p&gt;著者: A. Vaswani et al.&lt;br /&gt;
所属: Google Brain&lt;br /&gt;
出典: &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;NeurIPS 2017&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;どんなもの&quot;&gt;どんなもの？&lt;/h2&gt;
&lt;p&gt;Attentionをフルに活用した系列変換モデルを提案した．&lt;/p&gt;

&lt;h2 id=&quot;先行研究と比べてどこがすごい&quot;&gt;先行研究と比べてどこがすごい？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;再帰や畳み込みを用いない新しい系列変換（sequence transduction）モデルを提案した．&lt;br /&gt;
→ 並列処理が可能となり，計算コストを削減したことで，学習時間を大幅に減らすことができた．&lt;br /&gt;
→ 英独・英仏の翻訳テストで当時の最高スコア: BLEUを記録した．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;技術や手法のキモはどこ&quot;&gt;技術や手法のキモはどこ？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ほぼAttention（注意機構）だけを用いて系列変換モデルを構築している点&lt;br /&gt;
→ Scaled Dot-Product Attention&lt;br /&gt;
→ Multi-Head Attention&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;時系列を考慮するために，位置エンコーディング（positional encoding）を導入している点&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;どうやって有効だと検証した&quot;&gt;どうやって有効だと検証した？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;主にBLEUスコアとパープレキシティ&lt;/li&gt;
  &lt;li&gt;構文解析のスコア&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;inner_ads&quot;&gt;
    &lt;div class=&quot;left_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022749.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt; 
    &lt;div class=&quot;right_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502952&amp;amp;p_id=1386&amp;amp;pc_id=2364&amp;amp;pl_id=20737&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0598/000000020737.png&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502952&amp;amp;p_id=1386&amp;amp;pc_id=2364&amp;amp;pl_id=20737&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;論文の主張&quot;&gt;論文の主張&lt;/h2&gt;
&lt;p&gt;近年の系列変換モデルは，再帰ニューラルネットや畳込みニューラルネットに大きく依存している．また，SoTAを達成するようなモデルであっても，注意機構を取り入れた再帰 or CNNのモデルに依存しており，モデルが複雑になっている．&lt;/p&gt;

&lt;p&gt;この論文では，&lt;strong&gt;Transformer&lt;/strong&gt;と呼ばれる，注意機構にだけ基づくシンプルなモデルを提案している．Transformerは再帰ニューラルネットや畳み込みニューラルネットを必要としないモデルである．&lt;/p&gt;

&lt;p&gt;実験結果では，翻訳タスクについてstate-of-the-artを達成し，かつその並列演算能力の高さや，学習時間の低減というメリットが挙げられた．また，翻訳タスク以外のNLPタスクへの有用性も示唆された．&lt;/p&gt;

&lt;h2 id=&quot;従来手法&quot;&gt;従来手法&lt;/h2&gt;
&lt;p&gt;時系列モデリングにおける再帰ニューラルネット &amp;amp; 畳み込みを用いたモデルは，これまで多く活用されてきた．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;再帰を伴うモデルは実行時間にかなりの影響を及ぼす．&lt;br /&gt;
→ 再帰によって並列計算が妨げられるため．&lt;br /&gt;
→ factorization trickやconditional computationといった手法が考案されてきた．
    &lt;ul&gt;
      &lt;li&gt;こうした手法は直接的に時系列モデリングの問題を解決するものではない．&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;畳み込みを伴うモデルは再帰よりも実行時間に影響は及ぼさない．
    &lt;ul&gt;
      &lt;li&gt;しかし，入出力の依存関係を計算する際に，その範囲が大きくなればなるほど，計算量が対数または，線形に増加してしまうというデメリットがある．&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;注意機構は時系列モデリングにおいて広く用いられてきた．&lt;br /&gt;
→ 注意機構を用いることで，依存関係のモデリングが可能となる．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;提案手法の先行研究との違い&quot;&gt;提案手法の先行研究との違い&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;新たに提唱するTransformerは，Attentionだけを活用し，再帰は一切伴わない．&lt;br /&gt;
→ Attentionが入力と出力間の大域的な依存関係を抽出できる．&lt;br /&gt;
→ 並列計算が可能となり，計算の高速化が図られる．&lt;br /&gt;
→ 翻訳の質の観点においても，SoTAを達成することができた．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;attentionについて&quot;&gt;Attentionについて&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Attentionの算出方法には次の二つが挙げられる．
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Additive Attention: 加法注意機構
  隠れ層が一つのフィードフォワードネットワークを用いてAttentionを計算する．&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Dot-product Attention: 内積注意機構
  論文中で使われているAttentionである．行列を用いてAttentionが計算できるため，高速性・省メモリ性に優れている．&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;self-attention: 自己注意機構&lt;br /&gt;
単一のシーケンスに対してattentionを適用する手法のこと．Encoder-Decoderモデルで用いられるattentionとは異なる．&lt;br /&gt;
→ 入力文の特徴量を抽出するために使われる．&lt;br /&gt;
→ Transformerで使われるAttetionはSelf-attention．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;提案手法&quot;&gt;提案手法&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;モデルは基本的な系列変換モデルの枠組みに基づく．&lt;br /&gt;
→ つまり，各時刻において，モデルは自己回帰を行う．
    &lt;ul&gt;
      &lt;li&gt;ここでの自己回帰は，次のトークンを生成するために，前に生成されたトークンを追加の入力として用いるということである．&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;モデルは，スタック型自己注意と全結合層（point-wise）からなる．&lt;br /&gt;
→ 以下の図がモデルの概要図になっている．&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-23/model.png&quot; alt=&quot;Transformerモデル図&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;https://arxiv.org/abs/1706.03762&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;1-エンコーダスタック&quot;&gt;1. エンコーダスタック&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;エンコーダネットワークはスタック型となっており，6個のブロックから構成される．&lt;br /&gt;
→ この6はハイパーパラメータ．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;ブロック内での処理の流れ（順方向）
    &lt;ol&gt;
      &lt;li&gt;multi-head self-attentionを適用する．&lt;/li&gt;
      &lt;li&gt;残差接続のベクトル（つまり入力ベクトル）と1の出力ベクトルを足し合わせて，層正規化を行う．&lt;/li&gt;
      &lt;li&gt;位置ごとの全結合を適用する．&lt;/li&gt;
      &lt;li&gt;残差接続のベクトル（つまり2の出力ベクトル）と3の出力ベクトルを足し合わせて，層正規化を行う．&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;各層の次元は512で統一されている．&lt;/li&gt;
  &lt;li&gt;残差接続は単に勾配消失を防いで学習をうまく進めるためと思われる．&lt;/li&gt;
  &lt;li&gt;層正規化は学習時間の軽減&amp;amp;学習の安定化に寄与する．&lt;/li&gt;
  &lt;li&gt;BERTはこのエンコーダ部分を活用している．&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://arxiv.org/abs/1607.06450&quot;&gt;（層正規化の論文）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2-デコーダスタック&quot;&gt;2. デコーダスタック&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;デコーダネットワークも6個の独立したスタックブロックから構成される．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;エンコーダネットワークにある2層に加えて，エンコーダの出力を活用したmulti-head attentionを追加している．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Self-attentionに関しては，未来の入力を考慮することがないように，マスク付きに改良している．&lt;br /&gt;
→ 予測対象の単語の情報が事前に漏れるのを防ぐ目的&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-attention&quot;&gt;3. Attention&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Attentionはクエリとキー&amp;amp;バリューの組を出力ベクトルにマッピングするものと捉えることができる． &lt;br /&gt;
→ 出力ベクトルはバリューの重みつき線形和で表される．&lt;br /&gt;
→ 重みは，クエリとキーの変換関数から算出される.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;31-スケール化内積注意&quot;&gt;3.1 スケール化内積注意&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;論文内で使用されるattentionは基本的に，スケール化内積注意（Scaled Dot-Product Attention）を用いている．&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;入力は次元: $d_k$のクエリとキー，次元: $d_v$のバリューからなる．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Attentionの計算手順は以下のようになる
    &lt;ol&gt;
      &lt;li&gt;あるクエリに対して，そのクエリと&lt;strong&gt;全て&lt;/strong&gt;のキーの内積を求める．&lt;/li&gt;
      &lt;li&gt;$\sqrt{d_k}$で除算する．（スケール化）&lt;/li&gt;
      &lt;li&gt;ソフトマックスにかけることで，各バリューの重みを求める．&lt;/li&gt;
      &lt;li&gt;バリューと重みを掛け合わせる．&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;実際には，複数のクエリを同時に処理するため，行列を用いて以下のように求められる．&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
{\rm Attention}(Q, K, V) = {\rm softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;$d_k$ が小さいときは内積注意も加法注意も実行時間に変わりはないが，$d_k$ が大きくなるにつれて，加法注意の方が高速になってしまう．&lt;br /&gt;
  → 内積が大きくなるので，勾配が極端に小さくなり，学習が進まなくなる．&lt;br /&gt;
  → これに対処するために，スケール化を行う．&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;32-multi-head-attention&quot;&gt;3.2 Multi-head attention&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;multi-head attentionは，attentionを複数に分割することを意味する．&lt;br /&gt;
→ モデルが異なる部分空間から異なる情報を抽出するのに長けている．&lt;br /&gt;
→ いろいろなnグラムを取る目的と一緒．&lt;br /&gt;
→ イメージとしてはCNNでチャンネル数を増やしてモデルの表現力を高めることと同じ？&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
{\rm MultiHead}(Q, K, V) = {\rm Concat}({\rm head_1}, \dots, {\rm head_h})W^O \\
{\rm head_i} = {\rm Attention}(QW_i^Q, KW_i^K, VW_i^V)
$$
&lt;/div&gt;

&lt;p&gt;ただし，$W_i^Q, W_i^K \in \mathbb{R}^{d_{model} \times d_k}$, $W_i^V \in \mathbb{R}^{d_{model} \times d_v}$, $W^O \in \mathbb{R}^{hd_v \times d_{model}}$ である．&lt;/p&gt;

&lt;p&gt;論文中では，$h = 8$, $d_k = d_v = d_{\rm model} / h = 64$ なので，各ヘッドの次元が小さくなるため，計算量的にはsingle-head attentionとあまり変わらなくなる．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-23/attention_comparison.png&quot; alt=&quot;Attentionの比較&quot; style=&quot;width: 500px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;https://arxiv.org/abs/1706.03762&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;33-transformerにおけるattention&quot;&gt;3.3 TransformerにおけるAttention&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;デコーダの「エンコーダ・デコーダ」Attention&lt;br /&gt;
→ クエリは前のデコーダの出力&lt;br /&gt;
→ キーとバリューはエンコーダの出力&lt;br /&gt;
つまり，普通の系列変換モデルでのattentionと同様である．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;エンコーダのAttention&lt;br /&gt;
→ 単純な自己注意&lt;br /&gt;
→ クエリ，キー，バリューともに前のエンコーダの出力&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;デコーダのAttention&lt;br /&gt;
→ 自分のポジションまで参照できる自己注意&lt;br /&gt;
→ 自己回帰がきちんとできるようにするため&lt;br /&gt;
→ 図2中で，スケール化内積注意のsoftmax前に，未来の入力に対応する部分を，$-\infty$で置き換えることにより，実装した．&lt;br /&gt;
→ ${\rm softmax}(x_i)=\frac{\exp(x_i)}{\sum_j \exp (x_j)}$で，$x_i \to -\infty$なら，その項は0になるので，考慮されなくなるということ．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-位置エンコーディング&quot;&gt;4. 位置エンコーディング&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Transformerは畳み込みや再帰を伴わないので，それだけでは時系列を考慮することができない．&lt;br /&gt;
→ 時系列を考慮するために，入力の埋め込み表現に「位置情報」を埋め込む．&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
PE_{(pos, 2i + 1)} = \cos\left(\frac{pos}{10000^{\frac{2i}{d_{model}}}}\right)
$$
&lt;/div&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
PE_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{\frac{2i}{d_{model}}}}\right)
$$
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-23/pe.png&quot; alt=&quot;Positional Encodingを可視化した図&quot; style=&quot;width: 500px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図作成: &lt;a href=&quot;https://github.com/gucci-j/pe-visualization&quot;&gt;https://github.com/gucci-j/pe-visualization&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;評価指標&quot;&gt;評価指標&lt;/h2&gt;
&lt;h3 id=&quot;bleu&quot;&gt;BLEU&lt;/h3&gt;
&lt;p&gt;Bilingual Evaluation Understudyの略．&lt;br /&gt;
ACL2002で発表された機械翻訳の自動評価指標である．&lt;/p&gt;

&lt;p&gt;BLEUスコアは高ければ高いほどよい指標となっている．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
{\rm BLEU} = {\rm BP} \exp{\left(\sum_{n=1}^N \frac{1}{N} \log P_n \right)}
$$
&lt;/div&gt;

&lt;h3 id=&quot;bpとは&quot;&gt;BPとは？&lt;/h3&gt;
&lt;p&gt;BPとは，brevity penaltyの略．brevityは英語で「簡潔さ・短さ」を意味する．&lt;br /&gt;
つまり，翻訳された結果が短文であると，その文だけペナルティを喰らうということである．&lt;/p&gt;

&lt;p&gt;修正Nグラムだけでは，翻訳文が短い文のときに$P_n$が高くなってしまうため，このBP項で低減させる．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
{\rm BP} = \begin{cases}
    1 &amp;amp; {\rm if}\  c &amp;gt; r\\
    \exp{(1-r/c)} &amp;amp; {\rm if}\  c \leq r\\
    \end{cases}
$$
&lt;/div&gt;

&lt;p&gt;ただし，$c$は翻訳された文の長さを意味し，$r$は正解コーパス中の対応する文の長さである．&lt;/p&gt;

&lt;h3 id=&quot;修正nグラム精度とは&quot;&gt;修正Nグラム精度とは?&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;$\left(\sum_{n=1}^N \frac{1}{N} \log P_n \right)$において，
    &lt;ul&gt;
      &lt;li&gt;$N$はNグラムの最大長（英語だと4が多いらしい）&lt;/li&gt;
      &lt;li&gt;$P_n$はNグラム精度を表している．&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Nグラム精度は，翻訳文とコーパスの参照文がどれだけ一致するかを数値化したものである．&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;詳しくは長ったらしくなるので，&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=1073135&quot;&gt;論文本体&lt;/a&gt;を参照．&lt;/p&gt;

&lt;h2 id=&quot;実験解析結果&quot;&gt;実験・解析結果&lt;/h2&gt;
&lt;h3 id=&quot;計算コスト比較&quot;&gt;計算コスト比較&lt;/h3&gt;

&lt;p&gt;通常，シーケンスの長さ $n$ は，モデルの次元 $d$ よりも小さいことが多いので， $n &amp;lt; d$ で，Self-Attentionの計算量コストが最も小さくなる．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-23/table1.png&quot; alt=&quot;計算コスト比較表&quot; style=&quot;width: 700px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;https://arxiv.org/abs/1706.03762&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;complexity-per-layer&quot;&gt;Complexity per layer&lt;/h4&gt;
&lt;p&gt;1層あたりの計算量を意味する．&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Self-Attentionの場合&lt;br /&gt;
Self-Attentionの重み算出式は，${\rm softmax}(QK^{T}) V$ である．&lt;/p&gt;

    &lt;p&gt;分解して考えていくと，まず，$QK^{T}$ は，$(n \times d)$ と $(d \times n)$ の行列の積であるから，$O(n^2d)$ である．続いて，${\rm softmax}$ の計算量は，ひとつの要素を計算するのに，$O(n)$ かかるので，$n$ 個の要素を考えると $O(n) \times n$ で，$O(n^2)$ である．最後に，${\rm softmax}(QK^{T})$ と，$V$ の行列の積は，$QK^{T}$ と同じく $O(n^2d)$ となる．&lt;/p&gt;

    &lt;p&gt;したがって，これらを合計すると，$O(n^2d) + O(n^2) + O(n^2d)$ であり，$O(n^2d)$ とまとめることができる．ゆえに，Self-Attentionの層あたりの計算量は，$O(n^2d)$ となる．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Recurrentの場合&lt;br /&gt;
Recurrentの時刻 $t$ における隠れ層の重み算出式は，$\mathbf{h_t} = \tanh \left(\mathbf{h_{t-1}} W + \mathbf{x_t} U + \mathbf{b} \right)$ と表せる．なお，活性化関数は $\tanh$ に限らず，シグモイド関数のときもある．いずれにせよ，どちらの手法も定数時間で処理できるので，ここでは $\tanh$ を活性化関数として使う．&lt;/p&gt;

    &lt;p&gt;Self-Attentionと同様に，分解して考えていくと，まず，$\mathbf{h_{t-1}} W$ は，$(1 \times d)$ と $(d \times d)$ の行列積であるから，$O(d^2)$ である．続いて，$\mathbf{x_t} U$ は，$(1 \times d)$ と $(d \times d)$ の行列積であるので，$O(d^2)$ である．また，行列和については，サイズが $(1 \times d)$ 同士の和であるので，$O(d)$ である．最後に，$\tanh (x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(-x)}$ の計算量は，$d$ 個の要素に対して適用するので，$O(d)$である．&lt;/p&gt;

    &lt;p&gt;したがって，時刻 $t$における計算量は，$O(d^2) + O(d^2) + O(d) + O(d)$ で，$O(d^2)$ とまとめられる．入力シーケンスの長さは，$n$ であるから，層あたりの計算量は $O(d^2) \times n$ で， $O(nd^2)$ となる．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Convolutionについてはどうやって算出したのか不明．何か情報があればご教示ください．&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;sequential-operations&quot;&gt;Sequential Operations&lt;/h4&gt;
&lt;p&gt;逐次処理を最小限にする並列処理可能な計算量のこと．Recurrent層はシーケンスの長さだけコストがかかるのは直感的である．&lt;/p&gt;

&lt;h4 id=&quot;maximum-path-length&quot;&gt;Maximum Path Length&lt;/h4&gt;
&lt;p&gt;ネットワーク内の長距離依存関係間の経路長のこと．
Self-Attentionは定数のコストで，入出力間の任意の組み合わせの経路を繋げることができる．一方で，再帰が$O(n)$であり，畳み込みが$O(\log n)$であることは，簡単にBackgroundで触れられていた気がする．&lt;/p&gt;

&lt;h3 id=&quot;翻訳性能比較&quot;&gt;翻訳性能比較&lt;/h3&gt;
&lt;p&gt;表から，Transformerは高い翻訳精度を出しつつ，かつ計算コストを削減できていることがわかる．&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-23/table2.png&quot; alt=&quot;翻訳精度比較表&quot; style=&quot;width: 700px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-image&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt; 図引用: &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;https://arxiv.org/abs/1706.03762&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;まとめスライド&quot;&gt;まとめスライド&lt;/h2&gt;
&lt;div style=&quot;text-align: center&quot;&gt;&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/3zlzCmoC9icWLd&quot; width=&quot;510&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&quot; allowfullscreen=&quot;&quot;&gt; &lt;/iframe&gt;&lt;/div&gt;
&lt;div style=&quot;margin-bottom:5px&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;実装&quot;&gt;実装&lt;/h2&gt;
&lt;p&gt;時系列を考慮するために提案された手法：Positional Encoding（位置エンコーディング）を可視化するスクリプトを書きました．&lt;br /&gt;
&lt;a href=&quot;https://github.com/gucci-j/pe-visualization&quot;&gt;GitHub&lt;/a&gt; に置いてあります．ご自由にご利用ください．&lt;/p&gt;</content><author><name></name></author><category term="論文メモ" /><summary type="html">Googleが昨年発表した，BERT：Bidirectional Encoder Representation for Transformersは，様々なNLPタスクにおいて当時の最高スコアを記録し，世界中で瞬く間に注目を浴びることとなりました．結果として，BERTはNAACL 2019のBest Long Paper Awardにも輝いています．</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/resources/2019-05-23/pe.png" /></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（畳み込みニューラルネットワーク編）</title><link href="http://localhost:4000/DL-Intro-5/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（畳み込みニューラルネットワーク編）" /><published>2019-05-10T00:00:00+09:00</published><updated>2019-05-10T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-5</id><content type="html" xml:base="http://localhost:4000/DL-Intro-5/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;このシリーズでは、深層学習の入門書として有名な、「ゼロから作るDeep Learning」（以下、ゼロから〜）と同時並行でフレームワークを学習し、その定着を目指します。&lt;/p&gt;

&lt;p&gt;前回は、学習に関する様々テクニックについて紹介しました。今回はこれまでの話題とは大きく変わって、畳み込みニューラルネットワーク（CNN）による画像分類に取り組みます。また、CNNのフィルターの重み可視化や、学習済みモデルの転移学習・最近のCNNモデルで使われるテクニックの一端についても紹介します。なお、本稿はゼロから〜の第7章に対応する内容となっています。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜の第7章: P205〜P238&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-5/&quot;&gt;畳み込みニューラルネットワーク編&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;1-cifar10-データセット&quot;&gt;1. CIFAR10 データセット&lt;/h2&gt;
&lt;p&gt;今回取り組むタスクは、CIFAR10と呼ばれる画像データセットをCNNで分類することです。&lt;/p&gt;

&lt;p&gt;CIFAR10は、10個のクラスを持つカラー画像のデータセットとなっていて、MNISTデータセットと同様にKerasで簡単に呼び出せるようになっています。CIFAR10の画像の一部を試しに表示させてみましょう。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.misc&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;toimage&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;toimage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'off'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-10/cifar10_example.png&quot; alt=&quot;CIFAR10の画像一例&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;p&gt;出力結果から、大型自動車の画像や、動物のような画像が表示されていることが確認できます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/datasets/#cifar10&quot;&gt;（KerasのCIFAR10ドキュメント）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;2-モデルの実装&quot;&gt;2. モデルの実装&lt;/h2&gt;
&lt;p&gt;それでは、CIFAR10を分類するためのCNNモデルの実装をしていきましょう。&lt;/p&gt;

&lt;p&gt;今回実装するモデルは、ゼロから〜のP229で扱われているSimpleConvNetに似た構成とします。また、ソースコード名は、&lt;code class=&quot;highlighter-rouge&quot;&gt;cnn.py&lt;/code&gt;として進めていきます。&lt;/p&gt;

&lt;p&gt;例によってモデルの概要図を以下に示します。実装の際の参考にしてください。なお、この図は自作ではなく、GitHubの@yu4uさんらによる「&lt;a href=&quot;https://github.com/yu4u/convnet-drawer&quot;&gt;convnet-drawer&lt;/a&gt;」により描画しています。CNNであれば簡単に作図できるので、ぜひ使ってみてください。&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-10/model_diagram.png&quot; alt=&quot;1層CNNモデルの概要図&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch07/simple_convnet.py&quot;&gt;（SimpleConvNetの公式ソースコード）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://github.com/yu4u/convnet-drawer&quot;&gt;（GitHub: convnet-drawer）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;21-レイヤーの定義&quot;&gt;2.1 レイヤーの定義&lt;/h3&gt;
&lt;p&gt;今回使うモジュールやレイヤーをインポートします。&lt;/p&gt;

&lt;p&gt;新たに登場するレイヤーとしては、&lt;code class=&quot;highlighter-rouge&quot;&gt;Conv2D&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;MaxPooling2D&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;Flatten&lt;/code&gt;が挙げられます。これらのレイヤーについては、以下でそれぞれ解説していきます。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;22-畳み込み処理&quot;&gt;2.2 畳み込み処理&lt;/h3&gt;
&lt;p&gt;畳み込み処理部のソースコードとその説明を以下に示します。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;入力部&lt;br /&gt;
  CIFAR10データセットは、32*32のカラー画像: RGBのデータセットです。&lt;br /&gt;
  したがって、入力サイズは&lt;code class=&quot;highlighter-rouge&quot;&gt;(32, 32, 3)&lt;/code&gt;となります。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;畳み込み部&lt;br /&gt;
  画像の畳み込み処理には、&lt;code class=&quot;highlighter-rouge&quot;&gt;Conv2D&lt;/code&gt;レイヤーを活用します。&lt;br /&gt;
  &lt;code class=&quot;highlighter-rouge&quot;&gt;Conv2D&lt;/code&gt;の主な引数の説明は以下のようになります。&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;引数&lt;/strong&gt;&lt;/th&gt;
          &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;説明&lt;/strong&gt;&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;filters&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;フィルターの個数を指定する。&lt;br /&gt;ここで指定するフィルターはそれぞれ異なる重みやバイアスを持つものである。&lt;br /&gt;ゼロから〜では、&lt;code class=&quot;highlighter-rouge&quot;&gt;filter_num&lt;/code&gt;として定義されている。&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel_size&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;フィルターのサイズを指定する。&lt;br /&gt;ゼロから〜では、&lt;code class=&quot;highlighter-rouge&quot;&gt;filter_size&lt;/code&gt;として定義されている。&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;strides&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;ストライド幅を指定する。&lt;br /&gt;ゼロから〜では、&lt;code class=&quot;highlighter-rouge&quot;&gt;stride&lt;/code&gt;として定義されている。&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;padding&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;ゼロパディングの有無を指定する。&lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;'same'&lt;/code&gt;のときには、ゼロパディングが適用され、入力サイズと出力サイズは同じになる。&lt;code class=&quot;highlighter-rouge&quot;&gt;'valid'&lt;/code&gt;のときには、出力サイズは入力サイズよりも小さくなる。&lt;br /&gt;ゼロから〜では、&lt;code class=&quot;highlighter-rouge&quot;&gt;pad&lt;/code&gt;として定義されている。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;今回実装する畳み込み層は、ほぼゼロから〜の設定値に基づくので、各値の詳細な説明は省きます。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;プーリング部&lt;br /&gt;
  Kerasにおいて画像の最大値プーリングの処理は、&lt;code class=&quot;highlighter-rouge&quot;&gt;MaxPooling2D&lt;/code&gt;で実装できます。&lt;code class=&quot;highlighter-rouge&quot;&gt;MaxPooling2D&lt;/code&gt;の主な引数は、&lt;code class=&quot;highlighter-rouge&quot;&gt;pool_size&lt;/code&gt;のみです。例えば、2*2のプーリングを行いたい場合には、&lt;code class=&quot;highlighter-rouge&quot;&gt;pool_size&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;2&lt;/code&gt;か&lt;code class=&quot;highlighter-rouge&quot;&gt;(2,2)&lt;/code&gt;を指定します。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 入力部
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 畳み込み部
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# プーリング部
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/convolutional/#conv2d&quot;&gt;（Keras: Conv2Dのドキュメント）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/pooling/&quot;&gt;（Keras: MaxPooling2Dのドキュメント）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;23-出力処理&quot;&gt;2.3 出力処理&lt;/h3&gt;
&lt;p&gt;プーリングが終わったら、残るは全結合層に通して、Softmaxで分類するだけです。簡単な気がしますが一つだけ落とし穴があります。&lt;/p&gt;

&lt;p&gt;ここで、&lt;code class=&quot;highlighter-rouge&quot;&gt;MaxPooling2D&lt;/code&gt;の出力のテンソルサイズを見てみましょう。最大値プーリングまでのモデルを切り出して確認します。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 30)        2280
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 30)        0
=================================================================
Total params: 2,280
Trainable params: 2,280
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;MaxPooling2D&lt;/code&gt;の出力は、&lt;code class=&quot;highlighter-rouge&quot;&gt;(None, 14, 14, 30)&lt;/code&gt;となっていることがわかります。この状態で、&lt;code class=&quot;highlighter-rouge&quot;&gt;Dense&lt;/code&gt;レイヤーにこのテンソルを渡すとどうなるか、確認してみましょう。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 30)        2280
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 30)        0
_________________________________________________________________
dense_1 (Dense)              (None, 14, 14, 100)       3100
=================================================================
Total params: 5,380
Trainable params: 5,380
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;なんと、&lt;code class=&quot;highlighter-rouge&quot;&gt;(None, 14, 14, 100)&lt;/code&gt;という出力が出てきてしまいました。本来ならば、ここでは出力として&lt;code class=&quot;highlighter-rouge&quot;&gt;(None, 100)&lt;/code&gt;が欲しい場面です。&lt;/p&gt;

&lt;p&gt;この原因は、Kerasの&lt;code class=&quot;highlighter-rouge&quot;&gt;Dense&lt;/code&gt;レイヤーの出力の定義が、&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;nD tensor with shape: (batch_size, …, units)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;となっているためで、元の入力のテンソルの次元を変えない仕様になっているのです。&lt;/p&gt;

&lt;p&gt;したがって、Kerasで3次元以上のデータを2次元に落とし込みたいときには、事前に&lt;code class=&quot;highlighter-rouge&quot;&gt;Reshape&lt;/code&gt;か&lt;code class=&quot;highlighter-rouge&quot;&gt;Flatten&lt;/code&gt;などを用いてテンソルの形状を変更（平滑化）する必要があります。今回の場合、以下のようにすれば望みの出力が得られます。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 30)        2280
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 30)        0
_________________________________________________________________
flatten_1 (Flatten)          (None, 5880)              0
_________________________________________________________________
dense_1 (Dense)              (None, 100)               588100
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1010
=================================================================
Total params: 591,390
Trainable params: 591,390
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;なお、&lt;code class=&quot;highlighter-rouge&quot;&gt;Flatten&lt;/code&gt;はその名の通り、入力のテンソルを平らにする（平滑化する）レイヤーです。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/core/#flatten&quot;&gt;（Keras: Flattenのドキュメント）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/core/#dense&quot;&gt;（Keras: Denseのドキュメント）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;24-データセットの読み込みと学習設定&quot;&gt;2.4 データセットの読み込みと学習設定&lt;/h3&gt;

&lt;p&gt;この部分は前回までとほぼ同一なので、説明は省きます。以下にソースコードを示すので、上のソースコードと合わせて動かしてみてください。&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) 畳み込みニューラルネットの学習は、普通のパソコンで回すとそれなりの時間を要します。（手持ちのノートPCでは、エポックあたり30秒程度かかりました。）また、初めて動かすときには、CIFAR10データセットのダウンロード処理に数分を要します。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# データセットの読み込み
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 学習設定
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'adam'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;inner_ads&quot;&gt;
    &lt;div class=&quot;left_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022749.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt; 
    &lt;div class=&quot;right_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22750&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022750.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22750&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;3-実験&quot;&gt;3. 実験&lt;/h2&gt;
&lt;h3 id=&quot;31-１層畳み込みニューラルネットの学習結果&quot;&gt;3.1 １層畳み込みニューラルネットの学習結果&lt;/h3&gt;
&lt;p&gt;上記で実装した&lt;code class=&quot;highlighter-rouge&quot;&gt;cnn.py&lt;/code&gt;を動作させた結果、以下のような分類精度の推移となりました。&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-10/acc.png&quot; alt=&quot;１層CNNの分類精度の推移&quot; style=&quot;width: 500px;&quot; /&gt;&lt;br /&gt;
&lt;/div&gt;

&lt;p&gt;5エポック目あたりから過学習の傾向が見られます。また、テストデータでの最高精度は65%程度であることが読み取れます。&lt;/p&gt;

&lt;p&gt;10クラスの分類で65%の精度なので、デタラメに分類しているわけではなさそうです。そこで、次節ではゼロから〜のP234と同様に、CNNのフィルターの重みを可視化することで、規則性のあるフィルターを学習できているかどうかを確認してみることにします。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter7&quot;&gt;（GitHub: cnn.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;32-重みの可視化&quot;&gt;3.2 重みの可視化&lt;/h3&gt;
&lt;h4 id=&quot;321-重み画像の生成&quot;&gt;3.2.1 重み画像の生成&lt;/h4&gt;
&lt;p&gt;CNNの重みを可視化するには、&lt;code class=&quot;highlighter-rouge&quot;&gt;model.get_weights()&lt;/code&gt;でパラメータのリストを取得して、そのリストに少し手を加える必要があります。&lt;/p&gt;

&lt;p&gt;本シリーズの第2弾で確認したように、パラメータのリストはモデルの入力側から順に登録されています。したがって、今回のモデルでは、畳み込み層のフィルターの重みは先頭に格納されていることになります。&lt;/p&gt;

&lt;p&gt;その点を踏まえて、次のCNNのフィルターの重みを可視化するスクリプト抜粋をみてください。このスクリプトは、&lt;code class=&quot;highlighter-rouge&quot;&gt;weight_image&lt;/code&gt;というリストに各フィルタの重みのNumPy配列を追加していくものになっています。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.preprocessing.image&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array_to_img&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 畳み込み層の重みを取ってくる
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 各フィルターに分割する
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;weight_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array_to_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;weight_image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;簡単に各部を説明していきます。まず、&lt;code class=&quot;highlighter-rouge&quot;&gt;np.split()&lt;/code&gt;により、&lt;code class=&quot;highlighter-rouge&quot;&gt;(5, 5, 3, 30)&lt;/code&gt;となっている重みのリストを、&lt;code class=&quot;highlighter-rouge&quot;&gt;(5, 5, 3, 1)&lt;/code&gt;の形を持つ30個のリストに分割します。&lt;/p&gt;

&lt;p&gt;その後、&lt;code class=&quot;highlighter-rouge&quot;&gt;np.squeeze()&lt;/code&gt;により、無駄な次元: 3次元目をなくします。これにより、&lt;code class=&quot;highlighter-rouge&quot;&gt;(5, 5, 3)&lt;/code&gt;の形状を持つリストが得られます。&lt;/p&gt;

&lt;p&gt;最後に&lt;code class=&quot;highlighter-rouge&quot;&gt;array_to_image()&lt;/code&gt;を用いてリストをPIL形式の画像に変換し、タイル状に画像を並べるために再びNumPy形式に変換し直して、リストに追加しておきます。&lt;/p&gt;

&lt;h4 id=&quot;322-タイル状に画像を表示&quot;&gt;3.2.2 タイル状に画像を表示&lt;/h4&gt;
&lt;p&gt;残るは&lt;code class=&quot;highlighter-rouge&quot;&gt;weight_image&lt;/code&gt;を画像化すれば良いだけですが、どうせならタイル状に並べて表示したいところです。しかし、タイル状に複数画像を出力するのは若干手間がかかります…&lt;/p&gt;

&lt;p&gt;以下に、タイル状に画像を表示するサンプルスクリプトを示します。各部の詳しい説明は省きますが、大まかには空の生成画像サイズのリストを用意して、そこに元のピースとなる画像を入れていく流れになります。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combine_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 重み画像の合体
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'weight.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;combine_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上のスクリプトで重み画像を可視化した結果が以下の図です。&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-10/param.png&quot; alt=&quot;CNNのフィルター重み可視化結果&quot; style=&quot;width: 300px;&quot; /&gt;&lt;br /&gt;
    ＜重みの可視化結果＞
&lt;/div&gt;

&lt;p&gt;重みの可視化結果の図から、学習前は完全にランダムな重みとなっているフィルタが、学習後にはある特定の方向に反応するフィルタとして変化していることがわかります。したがって、本来の目的である、規則性のあるフィルターを学習できていることが確認できました！&lt;/p&gt;

&lt;p&gt;なお、一連のソースコードについては、&lt;code class=&quot;highlighter-rouge&quot;&gt;visualize_weights.py&lt;/code&gt;としてGitHubに置いてあります。参考にしてください。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter7&quot;&gt;（GitHub: visualize_weights.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;4-学習済みモデルの活用&quot;&gt;4. 学習済みモデルの活用&lt;/h2&gt;
&lt;p&gt;今回実装してきた1層のCNNでは、CIFAR10で65%程度の分類精度しか出せませんでした。満足に写真の分類をできるようになるには程遠いですね。&lt;/p&gt;

&lt;p&gt;分類精度をより向上させるにはモデルの構造を改良することも考えられますが、手っ取り早いのは、学習済みモデルを活用して転移学習を行うことです。ここでは一例として、Kerasが学習済みモデルとして提供している&lt;code class=&quot;highlighter-rouge&quot;&gt;MobileNet&lt;/code&gt;を用いて、転移学習によるCIFAR10データセットの分類実験をして、どれほど高い分類性能が記録されるかを検証していこうと思います。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照： &lt;a href=&quot;https://keras.io/ja/applications/#mobilenet&quot;&gt;（KerasにおけるMobileNetのドキュメント）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;41-mobilenetの特徴&quot;&gt;4.1 MobileNetの特徴&lt;/h3&gt;
&lt;p&gt;MobileNetはその名の通り、学習が速い＆軽いという特徴を持ち、それなりの分類精度を誇るモデルです。学習はImageNetという画像データベースを用いて行っています。&lt;/p&gt;

&lt;p&gt;今回MobileNetを扱った理由は、各自のパソコン上でも現実的に動作可能な学習済みモデルであるためです。モデルの詳細を知りたい方は、下記のリンクより論文を確認してみてください。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;http://www.image-net.org/&quot;&gt;（ImageNetの公式サイト）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://arxiv.org/abs/1704.04861&quot;&gt;（MobileNetの論文）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;42-mobilenetの読み込み&quot;&gt;4.2 MobileNetの読み込み&lt;/h3&gt;
&lt;p&gt;では、Kerasで実際にMobileNetを活用したモデルを構築してみましょう。&lt;/p&gt;

&lt;p&gt;MobileNetモデルの読み込みは非常に簡単で、下記に示すように1行で読み込めます。&lt;/p&gt;

&lt;p&gt;MobileNetの引数については、&lt;code class=&quot;highlighter-rouge&quot;&gt;include_top&lt;/code&gt;は出力層も含めたモデルにするかどうかを指定し、&lt;code class=&quot;highlighter-rouge&quot;&gt;pooling&lt;/code&gt;については出力層を含めないモデルのときに、プーリングの有無やその種類を指定します。今回は10クラス分類のため、出力層を含めないモデルとし、プーリングには次章で説明する「Global Average Pooling」を指定しました。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.applications.mobilenet&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MobileNet&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MobileNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;include_top&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pooling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'avg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0
_________________________________________________________________
mobilenet_1.00_224 (Model)   (None, 1024)              3228864
_________________________________________________________________
dense_1 (Dense)              (None, 10)                10250
=================================================================
Total params: 3,239,114
Trainable params: 3,217,226
Non-trainable params: 21,888
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;43-データセットの読み込み&quot;&gt;4.3 データセットの読み込み&lt;/h3&gt;
&lt;p&gt;MobileNetは入力サイズとして、&lt;code class=&quot;highlighter-rouge&quot;&gt;(224, 224, 3)&lt;/code&gt;を想定していますが、Kerasのドキュメントを見ると、幅と高さが32以上であれば良いと書いてあります。そのため、今回に限っては特にリサイズすることなく、CIFAR10の画像データをそのままモデルに入力することができます。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;44-転移学習の実行&quot;&gt;4.4 転移学習の実行&lt;/h3&gt;
&lt;p&gt;転移学習を実行する前に、&lt;code class=&quot;highlighter-rouge&quot;&gt;evaluate&lt;/code&gt;メソッドを使って学習前のモデルの精度を確認しておこうと思います。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 学習設定
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'adam'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 事前学習済みモデルのテスト
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10000/10000 [==============================] - 2s 211us/step
[2.3138149349212647, 0.1194]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;出力からわかるように、精度は11.9%でした。出力層の学習が全くできていない状態なので、このような結果となったと考えられます。&lt;/p&gt;

&lt;p&gt;では、転移学習なので数エポック回すだけで事足りるため、今回は3エポックだけ回して精度の推移を見ていくことにします。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 転移学習してみる
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Train on 50000 samples, validate on 10000 samples
Epoch 1/3
50000/50000 [==============================] - 17s 344us/step - loss: 1.0968 - acc: 0.6426 - val_loss: 0.9881 - val_acc: 0.7144
Epoch 2/3
50000/50000 [==============================] - 15s 307us/step - loss: 0.6443 - acc: 0.7826 - val_loss: 0.7400 - val_acc: 0.7499
Epoch 3/3
50000/50000 [==============================] - 16s 314us/step - loss: 0.5114 - acc: 0.8265 - val_loss: 0.7199 - val_acc: 0.7728
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2エポック目の時点で、&lt;code class=&quot;highlighter-rouge&quot;&gt;val_acc&lt;/code&gt;が74.99%とほぼ10%精度が向上していることがわかります。やはり、転移学習を用いることで、省コストでそれなりの精度を出せる分類器を手に入れられるメリットは大きいと感じます。&lt;/p&gt;

&lt;p&gt;ソースコードは、&lt;code class=&quot;highlighter-rouge&quot;&gt;transfer_learning.py&lt;/code&gt;として、GitHubに置いてあります。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter7&quot;&gt;（GitHub: transfer_learning.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;5-最近のcnn&quot;&gt;5. 最近のCNN&lt;/h2&gt;
&lt;p&gt;最後に簡単ですが、ゼロから〜には書かれていないCNN関連のテクニックについて触れていきたいと思います。&lt;/p&gt;

&lt;h3 id=&quot;51-global-average-pooling&quot;&gt;5.1 Global Average Pooling&lt;/h3&gt;
&lt;p&gt;Global Average Pooling（以下、GAP）は出力側の全結合層を置き換えるものとして活用されています。このメリットとしては、過学習を防ぎつつ、モデルのパラメータ数を減らすことができる点が挙げられます。&lt;/p&gt;

&lt;p&gt;GAPでは、各チャンネルごとにその特徴マップの値を平均した値を出力値とします。つまり、畳み込み＆プーリング処理後のテンソルの形状が、&lt;code class=&quot;highlighter-rouge&quot;&gt;(None, 14, 14, 30)&lt;/code&gt;であったとき、GAPを適用すると、&lt;code class=&quot;highlighter-rouge&quot;&gt;(None, 30)&lt;/code&gt;となります。&lt;a href=&quot;https://arxiv.org/abs/1312.4400&quot;&gt;論文&lt;/a&gt;によると、各出力の特徴マップは、分類カテゴリの”confidence map”として容易に解釈できるとされています。&lt;/p&gt;

&lt;p&gt;KerasでGAPを適用するのは非常に簡単であり、&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.layers&lt;/code&gt;にある、&lt;code class=&quot;highlighter-rouge&quot;&gt;GlobalAveragePooling2D&lt;/code&gt;レイヤーをインポートして使うだけです。&lt;/p&gt;

&lt;p&gt;以下に、&lt;code class=&quot;highlighter-rouge&quot;&gt;cnn.py&lt;/code&gt;にGAPを適用したモデルのスクリプトを示します。このモデルでは、最大値プーリングと全結合層の間にGAPを配置しています。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GlobalAveragePooling2D&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# モデル定義
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GlobalAveragePooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 30)        2280
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 30)        0
_________________________________________________________________
global_average_pooling2d_1 ( (None, 30)                0
_________________________________________________________________
dense_1 (Dense)              (None, 100)               3100
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1010
=================================================================
Total params: 6,390
Trainable params: 6,390
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;出力結果より、&lt;code class=&quot;highlighter-rouge&quot;&gt;cnn.py&lt;/code&gt;では、総パラメータ数が591,390であったのに対し、GAPを適用したモデルでは、6,390とかなり減少していることが実際に確認できます。&lt;/p&gt;

&lt;p&gt;ちなみにこのモデルを学習させた結果が以下の図のようになります。&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-10/acc_gap.png&quot; alt=&quot;GAP適用モデルの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;150エポック回して、分類精度は56%程度となりました。チューニング等一切していないので、元のモデルよりも、10%程度下がってしまっていますね…なお、この例のようにGAPを適用したモデルは一般に学習が遅くなるというデメリットが報告されているので、ご注意ください。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/layers/pooling/#globalaveragepooling2d&quot;&gt;（KerasのGlobal Average Poolingのドキュメント）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://arxiv.org/abs/1312.4400&quot;&gt;（GAPの原著論文）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter7&quot;&gt;（GitHub: cnn_with_gap.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;52-cnnのサーベイ記事&quot;&gt;5.2 CNNのサーベイ記事&lt;/h3&gt;
&lt;p&gt;CNNに関する研究のより詳しい流れについては、若干古くなっていますが、かなり充実したまとめがあるので、以下のリンクを参考にすると良いと思います。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://qiita.com/yu4u/items/7e93c454c9410c4b5427&quot;&gt;（畳み込みニューラルネットワークの最新研究動向 (〜2017)）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;今回は、畳み込みニューラルネットワーク（CNN）について触れていきました。Global Average Poolingは単に一般物体認識だけでなく、深層生成モデルの分野でも使われる重要なテクニックです。また、前回までに登場したドロップアウトやバッチ正規化もよくCNNで使われる手法であることは、間違いないです。今後、GAPと合わせて意識しておくと良いかもしれません。&lt;/p&gt;

&lt;p&gt;これにて、ゼロから〜とともに学ぶKerasシリーズは完結となりますが、本シリーズで少しでも深層学習フレームワークに慣れる一助となっていたら幸いです。&lt;/p&gt;

&lt;p&gt;今後は少し期間を置いて、自然言語処理の入門のための記事などを投稿できたらと思っています。&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;
&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/&quot;&gt;GitHub&lt;/a&gt;より入手できます。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに このシリーズでは、深層学習の入門書として有名な、「ゼロから作るDeep Learning」（以下、ゼロから〜）と同時並行でフレームワークを学習し、その定着を目指します。</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/resources/2019-05-10/model_diagram.png" /></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（学習テクニック編）</title><link href="http://localhost:4000/DL-Intro-4/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（学習テクニック編）" /><published>2019-05-03T00:00:00+09:00</published><updated>2019-05-03T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-4</id><content type="html" xml:base="http://localhost:4000/DL-Intro-4/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;このシリーズでは、深層学習の入門書として有名な、「ゼロから作るDeep Learning」（以下、ゼロから〜）と同時並行で、フレームワークを学習し、その定着を目指します。&lt;/p&gt;

&lt;p&gt;前回までは、Kerasを活用して実際にニューラルネットワークを学習させて、そのモデルを活用して推論までできるようになりました。今回は、ゼロから〜の6章に対応する種々の学習テクニックについて扱います。幅広いトピックを扱うので、理解するのに時間がかかるかと思いますが、どれもモデルの性能と安定性を向上させるために、重要なものばかりです。したがって、一つ一つ理解できるまでじっくりと取り組むことをオススメします。&lt;/p&gt;

&lt;p&gt;それでは、まずはパラメータの最適化アルゴリズムについての話題から入っていきましょう！&lt;/p&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-5/&quot;&gt;畳み込みニューラルネットワーク編&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;1-最適化アルゴリズム&quot;&gt;1. 最適化アルゴリズム&lt;/h2&gt;

&lt;p&gt;ゼロから〜で紹介があったように、ニューラルネットワークに対して適用される最適化アルゴリズムはたくさん存在し、モデルに応じて使い分けることが、その性能を引き出すために非常に重要となります。&lt;/p&gt;

&lt;p&gt;ここでは、ゼロから〜のP177に登場した、「SGD、AdaGrad、Adam」に加え、Adadelta、Nadam、の5つの最適化アルゴリズムを、Fashion-MNISTデータセットの分類実験を通して、比較してみようと思います。&lt;/p&gt;

&lt;h3 id=&quot;11-fashion-mnistデータセット&quot;&gt;1.1 Fashion-MNISTデータセット&lt;/h3&gt;
&lt;p&gt;本稿で用いるFashion-MNISTデータセットは、MNISTデータセットと互換性のあるデータセットです。データセットの内容は手書き数字ではなく、靴やズボン、カバン、服などファッションに関係のあるものとなっています。&lt;/p&gt;

&lt;p&gt;Fashion-MNISTは、MNISTの分類タスクが「簡単過ぎること」などを理由に、それを置き換える目的で作成されたデータセットです。&lt;/p&gt;

&lt;p&gt;試しに1枚データセットの画像を表示させてみましょう。下記のソースコードを動作させてみてください。画像の表示は、&lt;code class=&quot;highlighter-rouge&quot;&gt;imshow&lt;/code&gt;メソッドを使えば簡単にできます。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fashion_mnist&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fashion_mnist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gray'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/fm_example.png&quot; alt=&quot;Fashion-MNISTの内容の一例&quot; style=&quot;width: 300px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;靴らしき画像が表示されているのが確認できますね。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist&quot;&gt;（Fashion-MNISTのGitHubレポジトリ ）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/datasets/&quot;&gt;（KerasにおけるFashion-MNISTデータセットの説明）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;12-モデルの実装&quot;&gt;1.2 モデルの実装&lt;/h3&gt;
&lt;p&gt;本実験に用いるモデルの構造とハイパーパラメータは、ゼロから〜の公式レポジトリにある&lt;a href=&quot;https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch06/optimizer_compare_mnist.py&quot;&gt;ソースコード&lt;/a&gt;に基づきます。実装自体は前回までのソースコードをほぼ流用して実現できるので、ここでは説明を省略します。ソースコード自体は、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;GitHub&lt;/a&gt;の&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_optimizer.py&lt;/code&gt;にて公開してあります。&lt;/p&gt;

&lt;p&gt;なお、自力で実装をしてみたい方は、公式レポジトリを見つつ、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/blob/master/chapter4%265/two_nn.py&quot;&gt;前回のソースコード&lt;/a&gt;をベースにすることをおすすめします。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: ゼロから〜のP176〜P178&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_optimizer.py）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/optimizers/#keras&quot;&gt;（Kerasで利用可能な最適化アルゴリズムについて）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;13-モデルの比較&quot;&gt;1.3 モデルの比較&lt;/h3&gt;
&lt;p&gt;1.2で実装した5層ニューラルネットワークを実行させると、以下のような結果が得られました。&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/loss.png&quot; alt=&quot;最適化アルゴリズム別の損失関数の値の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;図から、SGDとAdadeltaを用いたモデルは、Adam/Nadam/Adagradを用いたモデルよりも収束が遅いことがわかります。また、この実験においては、Nadamが5つの最適化アルゴリズムの中で、最も収束の速いアルゴリズムであることがわかりました。&lt;/p&gt;

&lt;h2 id=&quot;2-重みの初期化&quot;&gt;2. 重みの初期化&lt;/h2&gt;

&lt;p&gt;Kerasにおける重みの初期化は特に指定しない限り、ブラックボックス的に処理されます。つまり、レイヤー定義時に重みの初期化方法を指定しなければ、各層の所定の初期化方法が自動的に適用されます。&lt;/p&gt;

&lt;p&gt;ここでは、重みの初期化をこちらから事前に指定することで、フレームワーク（Keras）を活用したときの、初期化手法による収束速度の違いを検証していきます。&lt;/p&gt;

&lt;h3 id=&quot;21-公式ドキュメントを見てみる&quot;&gt;2.1 公式ドキュメントを見てみる&lt;/h3&gt;
&lt;p&gt;ここで、全結合層: &lt;code class=&quot;highlighter-rouge&quot;&gt;Dense&lt;/code&gt;レイヤーの公式ドキュメントを確認してみましょう。下記がドキュメントの一部抜粋になります。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform',
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel_initializer&lt;/code&gt;を見ると、初期化の手法として、Glorotの一様分布（Xavierの一様分布）が用いられていることがわかります。&lt;/p&gt;

&lt;p&gt;初期化手法を変更したい場合には、すでに定義されている手法を&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel_initializer&lt;/code&gt;に引数として与えるか、新たに手法自体を定義することもできます。新たに定義する方法については、公式ドキュメントをご覧ください。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/core/#dense&quot;&gt;（KerasにおけるDenseレイヤーのドキュメント）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/initializers/&quot;&gt;（Kerasにおける初期化手法についてのドキュメント）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;22-初期化手法による収束速度の違い&quot;&gt;2.2 初期化手法による収束速度の違い&lt;/h3&gt;
&lt;p&gt;では、前章で実装した5層ニューラルネットワークを活用して、初期化手法による収束速度の違いをKerasでも検証していきましょう。&lt;/p&gt;

&lt;p&gt;初期化手法には、デフォルトのXaiverの初期値とHeの初期値、標準偏差が0.01の正規分布の3つをそれぞれ用います。また、ゼロから〜のP184〜P186の実験設定と合わせるため、中間層の活性化関数を&lt;code class=&quot;highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;から&lt;code class=&quot;highlighter-rouge&quot;&gt;relu&lt;/code&gt;に変更します。ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;GitHub&lt;/a&gt;の&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_initializer.py&lt;/code&gt;より入手できます。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_initializer.py&lt;/code&gt;を動作させた結果、以下の図のような結果が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/loss_init.png&quot; alt=&quot;初期化手法別の損失関数の値の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;図より、やはり活性化関数にReLUを用いる場合には、Heの一様分布による初期化が最も適していることがわかりました。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP184〜P186&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_initializer.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;3-正規化正則化&quot;&gt;3. 正規化・正則化&lt;/h2&gt;

&lt;p&gt;以下、4章と5章では、それぞれ正規化と正則化について扱います。その前に、巷で誤用しがちな、機械学習における正規化と正則化の意味について確認しておきましょう。&lt;/p&gt;

&lt;h3 id=&quot;31-正規化&quot;&gt;3.1 正規化&lt;/h3&gt;
&lt;p&gt;機械学習における正規化は、「&lt;strong&gt;データをある範囲内にスケールすること&lt;/strong&gt;」を意味します。標準化とも呼ばれることがありますが、標準化と正規化では厳密には意味合いが異なります。標準化: standardization は、「平均が0、分散が1」になるようにデータをスケールすることを指します。なお、この用語は統計学で用いられることが多いようです。&lt;/p&gt;

&lt;p&gt;したがって、正規化は標準化を抽象化したような意味合いを持ちます。&lt;/p&gt;

&lt;h3 id=&quot;32-正則化&quot;&gt;3.2 正則化&lt;/h3&gt;
&lt;p&gt;正則化は過学習（過適応）を防ぐためにある種のペナルティを課すことを意味します。Weight Decayがその一例となります。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/regularizers/&quot;&gt;（Kerasにおける正則化の利用方法について）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;inner_ads&quot;&gt;
    &lt;div class=&quot;left_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022749.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt; 
    &lt;div class=&quot;right_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22750&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022750.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22750&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;4-バッチ正規化&quot;&gt;4. バッチ正規化&lt;/h2&gt;

&lt;p&gt;バッチ正規化は、入力データを平均値が0で分散が1となる分布に変換する手法のことを指します。バッチ正規化を適用することで、モデルの収束を高速化できるほか、重みの初期化手法に対してかなり頑健になります。&lt;/p&gt;

&lt;p&gt;では、Kerasでバッチ正規化の実験をしてみましょう。&lt;/p&gt;

&lt;h3 id=&quot;41-モデルの実装&quot;&gt;4.1 モデルの実装&lt;/h3&gt;
&lt;p&gt;Kerasにおいて、バッチ正規化は&lt;code class=&quot;highlighter-rouge&quot;&gt;BatchNormalization&lt;/code&gt;レイヤーを活用することで実装できます。&lt;/p&gt;

&lt;p&gt;ここでは、2章のモデルの「全結合層と活性化層の間」にバッチ正規化層を追加する形で実装します。また、重みの初期化は「標準偏差が0.01の正規分布」により行います。&lt;/p&gt;

&lt;p&gt;なお、2章で確認したように、この重み初期化では通常学習は全く進行しません。つまり、バッチ正規化を適用することで、どの程度初期化手法に対して頑健になるかを見てみます。&lt;/p&gt;

&lt;p&gt;Kerasにおけるバッチ正規化の適用例は以下のようになります。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/&quot;&gt;GitHub&lt;/a&gt;より入手できます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/normalization/&quot;&gt;（KerasにおけるBatch Normalizationについて）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_batch_norm.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;42-バッチ正規化の有無による分類精度の比較&quot;&gt;4.2 バッチ正規化の有無による分類精度の比較&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_batch_norm.py&lt;/code&gt;を動作させた結果、以下の図のような結果が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_bn.png&quot; alt=&quot;バッチ正規化の有無による分類精度の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;図より、バッチ正規化をモデルに適用することで、かなり適当な重みの初期化を行っても、きちんと学習してくれることがわかります！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP186〜P189&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;5-過学習を防ぐためのテクニック&quot;&gt;5. 過学習を防ぐためのテクニック&lt;/h2&gt;

&lt;p&gt;ここでは、過学習を防ぐための手法の一例として、ゼロから〜でも扱われていた、Weight decayとドロップアウトに加え、Early Stoppingついても扱います。前章までと同様にKerasでテストモデルを実装し、それぞれの手法の効果を検証します。&lt;/p&gt;

&lt;h3 id=&quot;51-weight-decay&quot;&gt;5.1 Weight decay&lt;/h3&gt;
&lt;h4 id=&quot;511-kerasにおけるweight-decayの適用方法&quot;&gt;5.1.1 KerasにおけるWeight decayの適用方法&lt;/h4&gt;

&lt;p&gt;KerasにおけるWeight decayは、各レイヤーの引数に存在する、&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel_regularizer&lt;/code&gt;に対して利用したい正則化手法を与えることで利用できます。&lt;/p&gt;

&lt;p&gt;ここでは、4章で実装したバッチ正規化ありのモデルにweight decayを適用することで、過学習が軽減するか検証していきます。&lt;/p&gt;

&lt;p&gt;Weight decayの簡単な適用例は以下のようになります。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regularizers&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_wd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regularizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_regularizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_wd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;GitHub&lt;/a&gt;にある、&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_weight_decay.py&lt;/code&gt;となります。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/regularizers/&quot;&gt;（Kerasにおける正則化の利用方法について）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_weight_decay.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;512-weight-decayの適用結果&quot;&gt;5.1.2 Weight decayの適用結果&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_weight_decay.py&lt;/code&gt;を動作させた結果、以下のような図が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 0 0 10px 0;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_wd.png&quot; alt=&quot;Weight decayありのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜Weight decayありのときの分類精度の推移＞
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_wo_wd.png&quot; alt=&quot;Weight decay無しのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜Weight decayなしのときの分類精度の推移＞
&lt;/div&gt;

&lt;p&gt;図より、Weigth decayの有無を問わず、テスト精度はかなり乱高下していることがわかります。一方で、訓練精度については、Weight decayを用いることで、過学習が抑制されていることがわかります。&lt;/p&gt;

&lt;h3 id=&quot;52-ドロップアウト&quot;&gt;5.2 ドロップアウト&lt;/h3&gt;
&lt;h4 id=&quot;521-ドロップアウトの実装&quot;&gt;5.2.1 ドロップアウトの実装&lt;/h4&gt;

&lt;p&gt;Kerasにおいて、ドロップアウトは&lt;code class=&quot;highlighter-rouge&quot;&gt;Dropout&lt;/code&gt;レイヤーを活用することで実装できます。&lt;/p&gt;

&lt;p&gt;ドロップアウトの適用例は以下のようになります。&lt;br /&gt;
下記の例では、ドロップアウト率（入力のユニットを消去する割合）を、引数: &lt;code class=&quot;highlighter-rouge&quot;&gt;rate&lt;/code&gt;に渡しています。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dpout_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;5層ニューラルネットワークでドロップアウトの効果を検証したソースコードは、&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_dropout.py&lt;/code&gt;として、GitHubに置いてあります。では、この実験結果について次項で見ていきます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/layers/core/#dropout&quot;&gt;（KerasにおけるDropoutの説明）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_dropout.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;522-ドロップアウトの適用結果&quot;&gt;5.2.2 ドロップアウトの適用結果&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_dropout.py&lt;/code&gt;を動作させた結果、以下のような図が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 0 0 10px 0;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_dpout.png&quot; alt=&quot;ドロップアウトありのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜ドロップアウトありのときの分類精度の推移＞
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_wo_dpout.png&quot; alt=&quot;ドロップアウト無しのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜ドロップアウトなしのときの分類精度の推移＞
&lt;/div&gt;

&lt;p&gt;図から、ドロップアウトを適用したモデルは、ドロップアウトを適用しないモデルよりも、過学習を抑えられていることがわかります。&lt;/p&gt;

&lt;h3 id=&quot;53-early-stopping&quot;&gt;5.3 Early Stopping&lt;/h3&gt;
&lt;p&gt;Early Stoppingとは、その名の通り学習を早期に終了させてしまうというものです。つまり、過学習が起きる寸前 or 発生したらすぐに学習を終了させることで、ベストなモデルを手に入れようという試みになります。これにより、無駄な計算機リソースの消費防止にも繋がります。&lt;/p&gt;

&lt;h4 id=&quot;531-kerasにおけるearly-stoppingの適用方法&quot;&gt;5.3.1 KerasにおけるEarly Stoppingの適用方法&lt;/h4&gt;

&lt;p&gt;KerasにおいてEarly Stoppingは、&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.callbacks.EarlyStopping&lt;/code&gt;により定義されています。使い方は、&lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;メソッド内で、引数: &lt;code class=&quot;highlighter-rouge&quot;&gt;callbacks&lt;/code&gt;に、&lt;code class=&quot;highlighter-rouge&quot;&gt;EarlyStopping&lt;/code&gt;を渡せばよいです。&lt;code class=&quot;highlighter-rouge&quot;&gt;EarlyStopping&lt;/code&gt;関数の主な引数の説明は以下の表の通りです。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;引数&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;strong&gt;説明&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;monitor&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;何を基準に学習を早期終了させるかを指定します。&lt;br /&gt;デフォルトは&lt;code class=&quot;highlighter-rouge&quot;&gt;val_loss&lt;/code&gt;になっています。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;patience&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;何エポックの間、監視値: &lt;code class=&quot;highlighter-rouge&quot;&gt;monitor&lt;/code&gt;に変化がないことを許容するかを指定します。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;verbose&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;学習中にEarlyStoppingが適用されたことを明示的に表示するかしないかを指定します。&lt;br /&gt;デフォルトは0（表示しない）です。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Early Stoppingの簡単な適用例は以下のようになります。この例では、2エポックの間、テストデータに対する損失関数の値に改善が見られないと、学習が停止するように設定されています。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;early_stopping&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EarlyStopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;callbacks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;early_stopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/callbacks/#earlystopping&quot;&gt;（KerasにおけるEarly Stoppingについて）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;532-early-stoppingの適用結果&quot;&gt;5.3.2 Early Stoppingの適用結果&lt;/h4&gt;

&lt;p&gt;5層ニューラルネットワークでEarly Stoppingの効果を検証したソースコードは、GitHubに&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_early_stopping.py&lt;/code&gt;として置いてあります。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;compare_early_stopping.py&lt;/code&gt;を動作させた結果、以下のような図が得られました。&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 0 0 10px 0;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_es.png&quot; alt=&quot;Early Stoppingありのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜Early Stoppingありのときの分類精度の推移＞
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-05-03/acc_wo_es.png&quot; alt=&quot;Early Stopping無しのときの分類精度の推移&quot; style=&quot;width: 400px;&quot; /&gt;&lt;br /&gt;
    ＜Early Stopping無しのときの分類精度の推移＞
&lt;/div&gt;

&lt;p&gt;図より、Early Stoppingを適用したときには、40エポックで学習が停止し、過学習している様子は読み取れません。一方で、Early Stoppingを適用しなかったときには、60エポックあたりから過学習の傾向が読み取れます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/tree/master/chapter6&quot;&gt;（GitHub: compare_early_stopping.py）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;今回は様々な学習のテクニックについて、実際にKerasでモデルを実装し、その効果を検証してきました。次回は、畳み込みニューラルネットワークについて扱います。&lt;/p&gt;

&lt;p&gt;なお、このシリーズは次回で完結予定です。&lt;/p&gt;

&lt;p&gt;本稿で扱わなかったものの、ゼロから〜で紹介されている、「ハイパーパラメータの検証」については、今後「ハイパーパラメータの最適化 &amp;amp; 交差分割検証」をテーマに別の投稿で詳しく紹介する予定です！&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras/&quot;&gt;GitHub&lt;/a&gt;より入手できます。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに</summary></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（ニューラルネットワークの学習編）</title><link href="http://localhost:4000/DL-Intro-3/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（ニューラルネットワークの学習編）" /><published>2019-04-26T00:00:00+09:00</published><updated>2019-04-26T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-3</id><content type="html" xml:base="http://localhost:4000/DL-Intro-3/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;このシリーズでは、深層学習の入門書として有名な、「ゼロから作るDeep Learning」（以下、ゼロから〜）と同時並行で、フレームワークを学習し、その定着を目指します。&lt;/p&gt;

&lt;p&gt;前回までは、3層のニューラルネットワークをKerasで実装し、推論処理のみを扱ってきました。今回からは、ゼロから〜の4章と5章に対応する、ニューラルネットワークの学習にとりかかります。また、同時に実験結果の簡単な可視化方法についても触れていきます。&lt;/p&gt;

&lt;p&gt;では、２層のニューラルネットワークを題材にMNISTの分類モデルをKerasで実装し、学習させてみましょう！&lt;/p&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-5/&quot;&gt;畳み込みニューラルネットワーク編&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;1-プロジェクトの作成&quot;&gt;1. プロジェクトの作成&lt;/h2&gt;

&lt;p&gt;はじめに、２層ニューラルネットワーク用のプロジェクトを作成してください。&lt;/p&gt;

&lt;p&gt;以下、本投稿では&lt;code class=&quot;highlighter-rouge&quot;&gt;two_nn.py&lt;/code&gt;を作成するものとして進めます。&lt;/p&gt;

&lt;h2 id=&quot;2-実装&quot;&gt;2. 実装&lt;/h2&gt;

&lt;h3 id=&quot;21-モデルの概要&quot;&gt;2.1 モデルの概要&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;今回実装するモデルの概要図を以下に示します。実装の参考にしてください。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MNISTデータセットの分類を行うモデルを学習させるので、出力はクラスの数に合わせて10次元のベクトルとなっています。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-26/two_layer_nn.png&quot; alt=&quot;2層ニューラルネットワークの概念図&quot; style=&quot;width: 450px;&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;22-モデルの実装&quot;&gt;2.2 モデルの実装&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜の第4章に対応する2層ニューラルネットワークをKerasで実装していきます。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;モデルの実装は前回とあまり変わらないので、以下に一気に進めてしまいます。&lt;br /&gt;
復習として、ソースコードを読んで理解できるかを確認すると良いと思います。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;モデルのパラメータ等は全てゼロから〜のP117〜122に基づいています。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# パラメータ
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# モデルを定義する
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 784)               0
_________________________________________________________________
dense_1 (Dense)              (None, 100)               78500
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1010
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;23-データの読み込み&quot;&gt;2.3 データの読み込み&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;前回と同様にMNISTデータセットを読み込み、前処理（正規化、データの整形）を行います。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;前回との相違点としては、ラベルデータを学習のためにone-hotベクトルに変換させる点です。&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;one-hotベクトル化は、&lt;code class=&quot;highlighter-rouge&quot;&gt;to_categorical&lt;/code&gt;を用いることで行えます。 &lt;br /&gt;
  引数は変換元リストとクラス数です。戻り値は変換後のリストです。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# データを読み込む
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Before: {y_train.shape}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'After: {y_train.shape}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y_train[0]: {y_train[0]}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Before: (60000,)
y_train[0]: 5
After: (60000, 10)
y_train[0]: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;しっかりと、ラベルがone-hotベクトルに変換されていることが確認できます。&lt;/p&gt;

&lt;h3 id=&quot;24-学習の設定&quot;&gt;2.4 学習の設定&lt;/h3&gt;
&lt;p&gt;ここからが本格的に新しい部分になります。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;設計したモデルで学習を実行できるようにするために、「&lt;strong&gt;損失関数&lt;/strong&gt;」と「&lt;strong&gt;最適化アルゴリズム&lt;/strong&gt;」を設定します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;損失関数と最適化アルゴリズムの設定は、&lt;code class=&quot;highlighter-rouge&quot;&gt;compile&lt;/code&gt;メソッドで行えます。
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;ゼロから〜の4章の実装では、損失関数にクロスエントロピー、最適化アルゴリズムに確率的勾配降下法が用いられています。&lt;br /&gt;
したがって、本実装でも&lt;code class=&quot;highlighter-rouge&quot;&gt;loss&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;'categorical_crossentropy'&lt;/code&gt;を指定し、&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;SGD(lr=learning_rate)&lt;/code&gt;を指定します。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;ゼロから〜で使われている学習率は&lt;code class=&quot;highlighter-rouge&quot;&gt;0.1&lt;/code&gt;であるため、Kerasのデフォルト値0.01と異なります。そのため、&lt;code class=&quot;highlighter-rouge&quot;&gt;SGD&lt;/code&gt;に学習率を渡す必要があります。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;評価関数&lt;/strong&gt;の設定も行います。&lt;br /&gt;
ゼロから〜のP121では、認識精度を評価関数としているので、&lt;code class=&quot;highlighter-rouge&quot;&gt;compile&lt;/code&gt;メソッドの引数: &lt;code class=&quot;highlighter-rouge&quot;&gt;metrics&lt;/code&gt;に&lt;code class=&quot;highlighter-rouge&quot;&gt;['accuracy']&lt;/code&gt;を指定します。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.optimizers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/losses/&quot;&gt;（Kerasで利用可能な損失関数について）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/optimizers/&quot;&gt;（Kerasで利用可能な最適化アルゴリズムについて）&lt;/a&gt;&lt;br /&gt;
&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/metrics/&quot;&gt;（Kerasにおける評価関数について）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) Kerasをはじめとする深層学習フレームワークでは、ユーザが順伝播の計算グラフを構築すると、フレームワークが自動的に逆伝播用の処理をブラックボックス的に行ってくれます。
したがって、ゼロから〜の5章の部分は、フレームワーク使用時には実装する必要がありません。（自分でレイヤーを設計することがない限り。）&lt;/p&gt;

&lt;div class=&quot;inner_ads&quot;&gt;
    &lt;div class=&quot;left_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022749.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt; 
    &lt;div class=&quot;right_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22750&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022750.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22750&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;3-モデルの学習&quot;&gt;3. モデルの学習&lt;/h2&gt;

&lt;p&gt;それでは、モデルの学習を進めていきましょう。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;モデルの学習は、&lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;メソッドで行います。&lt;br /&gt;
以下に各引数について簡単に対応表を示します。&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;引数&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;説明&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;訓練データを指定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;訓練データに対応するラベルデータ（正解ラベル）を指定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;batch_size&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;ミニバッチのサイズを指定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;epochs&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;エポック数（学習回数）を指定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;verbose&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;学習進捗をどのように表示するか設定します&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;validation_data&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;テストデータを指定します&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;メソッドの戻り値は、&lt;code class=&quot;highlighter-rouge&quot;&gt;History&lt;/code&gt;オブジェクトになっています。&lt;br /&gt;
この戻り値を活用することで、損失関数や認識精度のプロットができます。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;validation_data&lt;/code&gt;にテストデータを与えることで、エポックごとにモデルのテスト精度を測ることができます。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/models/model/#fit&quot;&gt;（Kerasのfitメソッドにおける引数と戻り値の説明）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Epoch 1/17
60000/60000 [==============================] - 2s 31us/step - loss: 0.8805 - acc: 0.7994
Epoch 2/17
60000/60000 [==============================] - 2s 27us/step - loss: 0.4102 - acc: 0.8907
~~~
~~~
Epoch 17/17
60000/60000 [==============================] - 2s 27us/step - loss: 0.1771 - acc: 0.9497
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-学習結果の表示&quot;&gt;4. 学習結果の表示&lt;/h2&gt;

&lt;p&gt;ゼロから〜のP119とP121では、それぞれ損失関数の値と認識精度の推移を図にしているので、ここでも実際に図にしてみましょう！&lt;/p&gt;

&lt;h3 id=&quot;41-損失関数の値の推移&quot;&gt;4.1 損失関数の値の推移&lt;/h3&gt;
&lt;p&gt;Pythonの図表描画ライブラリである、Matplotlibを活用して、損失関数の値の推移を図にします。&lt;/p&gt;

&lt;h4 id=&quot;411-matplotlibのインストール&quot;&gt;4.1.1 Matplotlibのインストール&lt;/h4&gt;

&lt;p&gt;Matplotlibをインストールしていない方は、インストールしましょう。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install matplotlib
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;（&lt;strong&gt;注意&lt;/strong&gt;）macOSでMatplotlibをインポートすると、バックエンドの問題でエラーが発生することがあります。その場合は、下記を参照してバックエンドを書き換えてください。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://qiita.com/Gen6/items/78d83d117ef67e0d53c2&quot;&gt;（Matplotlibでインポートエラーが出るときの対処法）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;412-historyオブジェクトの中身&quot;&gt;4.1.2 Historyオブジェクトの中身&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;メソッドの戻り値は、&lt;code class=&quot;highlighter-rouge&quot;&gt;History&lt;/code&gt;オブジェクトであると前章で紹介しました。&lt;br /&gt;
実験結果を可視化するためにも、&lt;code class=&quot;highlighter-rouge&quot;&gt;History&lt;/code&gt;オブジェクトの中身を確認しておきましょう。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Keys: {_results.history.keys()}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Keys: dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;このように、損失関数の値と認識精度の結果が訓練・テストデータともに格納されていることがわかります。&lt;/p&gt;

&lt;h4 id=&quot;413-プロットしてみる&quot;&gt;4.1.3 プロットしてみる&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;History&lt;/code&gt;オブジェクトから訓練時とテスト時の損失関数の値のリスト受け取り、それらをプロットします。&lt;/p&gt;

&lt;p&gt;一連のソースコードを下記に示します。&lt;br /&gt;
なお、Matplotlibの詳しい使い方については、&lt;a href=&quot;https://matplotlib.org/tutorials/index.html&quot;&gt;公式チュートリアル&lt;/a&gt;をご覧ください。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'val_loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'best'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'loss.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-26/loss.png&quot; alt=&quot;損失関数の値の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;きちんと損失関数がプロットされていることが確認できました！&lt;/p&gt;

&lt;h3 id=&quot;42-認識精度の推移&quot;&gt;4.2 認識精度の推移&lt;/h3&gt;
&lt;p&gt;モデルが&lt;strong&gt;過学習&lt;/strong&gt;していないかを認識精度の推移を図にして確認してみましょう!&lt;/p&gt;

&lt;p&gt;プロットの流れは、損失関数の時とほとんど同一のため、説明は割愛します。&lt;br /&gt;
以下にソースコードを貼るので、各自試してみてください。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'acc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'val_acc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'best'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'acc.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-26/acc.png&quot; alt=&quot;認識精度の推移&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;図から、テストデータの認識精度を訓練データの認識精度が大幅に上回る現象は確認できないので、モデルの過学習は起きていないことがわかります。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://codeday.me/jp/qa/20181207/13787.html&quot;&gt;（Matplotlibでプロットを一旦クリアする）&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;今回はニューラルネットワークの学習について扱いました。&lt;br /&gt;
フレームワークを活用することで、誤差逆伝播が自動で実行されるため、順伝播の処理だけ記述すればよいという大きなメリットを体感できたと思います。&lt;/p&gt;

&lt;p&gt;次回は、ゼロから〜の第6章に対応する、「学習に関するテクニック」をKerasを用いて実証していきたいと思います。&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras&quot;&gt;GitHub&lt;/a&gt;にて公開しています。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに</summary></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（3層ニューラルネットワーク ＆ 手書き数字認識編）</title><link href="http://localhost:4000/DL-Intro-2/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（3層ニューラルネットワーク ＆ 手書き数字認識編）" /><published>2019-04-19T00:00:00+09:00</published><updated>2019-04-19T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-2</id><content type="html" xml:base="http://localhost:4000/DL-Intro-2/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;このシリーズでは、深層学習の入門書として有名な、「ゼロから作るDeep Learning」（以下、ゼロから〜）と同時並行で、フレームワークを学習し、その定着を目指します。&lt;/p&gt;

&lt;p&gt;前回の&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;第一弾: パーセプトロン編&lt;/a&gt;に目を通していない方は、先に目を通しておくことをおすすめします。&lt;/p&gt;

&lt;p&gt;それでは、今回は3層ニューラルネットワークをKerasで実装し、実際に手書き数字認識（MNISTデータセットの分類）をしていきましょう！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;（3層ニューラルネットワーク）&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP58〜65&lt;br /&gt;
（MNIST）&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP72〜81&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-5/&quot;&gt;畳み込みニューラルネットワーク編&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;1-3層ニューラルネットワークの実装&quot;&gt;1. 3層ニューラルネットワークの実装&lt;/h2&gt;

&lt;h3 id=&quot;11-プロジェクトの作成&quot;&gt;1.1 プロジェクトの作成&lt;/h3&gt;
&lt;p&gt;まず、3層ニューラルネットワーク実装用のプロジェクトを作成してください。&lt;br /&gt;
以下本章では、&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;を作成するものとして進めていきます。&lt;/p&gt;

&lt;h3 id=&quot;12-モデルの作成&quot;&gt;1.2 モデルの作成&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;今回の実装からは全てFunctional APIを用いたモデル実装を行います。&lt;br /&gt;
Sequentialモデルによる実装は行いませんので、あらかじめご了承ください。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;これから実装する3層ニューラルネットワークの概念図を以下に示します。&lt;br /&gt;
実装の際の参考にしてください。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-19/three_layer_nn.png&quot; alt=&quot;3層ニューラルネットワークの概念図&quot; style=&quot;width: 500px;&quot; /&gt;
&lt;/div&gt;

&lt;h4 id=&quot;121-レイヤー--numpyを読み込む&quot;&gt;1.2.1 レイヤー &amp;amp; NumPyを読み込む&lt;/h4&gt;

&lt;p&gt;まず、前回と同じように、実装に必要なレイヤーとNumPyを読み込みます。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;122-各種レイヤーを定義する&quot;&gt;1.2.2 各種レイヤーを定義する&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;3層のニューラルネットワークなので、それと同数の3つのDenseレイヤーのインスタンスを生成します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;units&lt;/code&gt;は各層におけるニューロンの数を表しています。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;活性化関数については、ゼロから〜では&lt;code class=&quot;highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;関数が使用されているので、ここでも&lt;code class=&quot;highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;を活用します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下の例では、簡単のため入れ子式に活性化関数を定義しましたが、活性化関数をレイヤーインスタンスとして定義することもできます。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center&quot;&gt;＜活性化関数を入れ子式に定義する例＞&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;text-align: center&quot;&gt;＜活性化関数をインスタンスとして定義する例＞&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_activ1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_activ1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_activ2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_activ2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/activations/&quot;&gt;https://keras.io/ja/activations/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;123-モデルを定義する&quot;&gt;1.2.3 モデルを定義する&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;前回と同様に、入力のテンソルと出力のテンソルを&lt;code class=&quot;highlighter-rouge&quot;&gt;Model&lt;/code&gt;に渡すことで、モデルを定義します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;model.summary()&lt;/code&gt;でモデルの状態を確認することができます。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# モデルの状態をみる
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 2)                 0
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 9
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 8
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 6
=================================================================
Total params: 23
Trainable params: 23
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;124-重みを設定する&quot;&gt;1.2.4 重みを設定する&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜では重みの初期化を定義しているので、本実装でも事前に重みを設定します。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kerasでは、重みは入力層から順にNumPyの配列で保持されています。&lt;br /&gt;
したがって、重みを設定する際には、順当に重みの配列をNumPy配列で定義して、そのリストを渡せばよいです。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重みの設定には、&lt;code class=&quot;highlighter-rouge&quot;&gt;model.set_weights()&lt;/code&gt;を使用します。&lt;br /&gt;
引数は重みの入ったリストです。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;weight_array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: ゼロから〜 P65&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]], dtype=float32), 
    array([0.1, 0.2, 0.3], dtype=float32), 
    array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]], dtype=float32), 
    array([0.1, 0.2], dtype=float32), 
    array([[0.1, 0.3], [0.2, 0.4]], dtype=float32), 
    array([0.1, 0.2], dtype=float32)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;13-テストする&quot;&gt;1.3 テストする&lt;/h3&gt;
&lt;p&gt;それでは、作成したモデルをテストしましょう。&lt;br /&gt;
作成したモデルのテストには、前回と同様に、&lt;code class=&quot;highlighter-rouge&quot;&gt;model.predict()&lt;/code&gt;を使用します。&lt;/p&gt;

&lt;p&gt;テストデータは、ゼロから〜 P65に示されているものと同一のものを使用します。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[0.3168271 0.6962791]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;見事、ゼロから〜 P65に示されている出力値と同一の値を得ることができました！&lt;/p&gt;

&lt;div class=&quot;inner_ads&quot;&gt;
    &lt;div class=&quot;left_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022749.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22749&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt; 
    &lt;div class=&quot;right_ad_in&quot;&gt;
        &lt;a href=&quot;//af.moshimo.com/af/c/click?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22750&amp;amp;guid=ON&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;//image.moshimo.com/af-img/0866/000000022750.jpg&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border:none;&quot; /&gt;&lt;/a&gt;&lt;img src=&quot;//i.moshimo.com/af/i/impression?a_id=1502939&amp;amp;p_id=1555&amp;amp;pc_id=2816&amp;amp;pl_id=22750&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border:none;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;2-手書き数字認識mnist&quot;&gt;2. 手書き数字認識（MNIST）&lt;/h2&gt;

&lt;p&gt;ここからは、今実装した3層ニューラルネットワークを活用して、手書き数字を実際に分類していきます。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: ゼロから〜のP72〜81&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;21-mnistデータセットの読み込み&quot;&gt;2.1 MNISTデータセットの読み込み&lt;/h2&gt;
&lt;p&gt;Kerasでは、MNISTデータセットは簡単にダウンロード&amp;amp;呼び出しできるようになっています。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;を作成して、以下を入力し動作させてみてください。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: &lt;a href=&quot;https://keras.io/ja/datasets/#mnist&quot;&gt;https://keras.io/ja/datasets/#mnist&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(60000, 28, 28)
(60000,)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) Kerasの&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist.load_data()&lt;/code&gt;は、「正規化されていない &amp;amp; 2次元配列」の状態のリストが返ってきます。ゼロから〜のP73の挙動とは異なるので、注意してください。&lt;/p&gt;

&lt;p&gt;ここで、データセットが&lt;code class=&quot;highlighter-rouge&quot;&gt;train&lt;/code&gt;と&lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt;の二つに分割されていることに気がつくと思います。これは、機械学習においてはモデルの汎化性能を測定するために、通常データセットを訓練データとテストデータの二つ（もしくはそれ以上）に分割するためです。詳しくは、ゼロから〜の第4章を見てください。&lt;/p&gt;

&lt;h3 id=&quot;22-データセットの前処理&quot;&gt;2.2 データセットの前処理&lt;/h3&gt;
&lt;p&gt;モデルの推論処理においてMNISTデータセットを活用するので、「正規化 &amp;amp; 一次元配列化」の処理を行っておきます。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;配列の形状変換は&lt;code class=&quot;highlighter-rouge&quot;&gt;.reshape&lt;/code&gt;メソッドで行えます。&lt;br /&gt;
引数は変換後の配列形状です。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;正規化処理のために、リストをfloat型に変換します。&lt;br /&gt;
型変換は、&lt;code class=&quot;highlighter-rouge&quot;&gt;.astype&lt;/code&gt;メソッドで行えます。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 一次元配列にする
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 正規化処理
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(60000, 784)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;きちんと一次元配列に変換されていることが確認できました。&lt;br /&gt;
正規化されているかどうかは、配列の要素のうち一つを表示させて確認してみてください。&lt;/p&gt;

&lt;h3 id=&quot;22-モデルの改良&quot;&gt;2.2 モデルの改良&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;でMNISTを分類できるように、以下の2点を改良します。 &lt;br /&gt;
改良したものは、&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;に追記してください。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜のP76と合わせて、一層目の全結合層のunit数を50、二層目を100とし、出力層は10とします。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MNISTデータセットの分類は「&lt;strong&gt;分類問題&lt;/strong&gt;」であるため、出力層にsoftmax層を追加します。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# モデルの状態をみる
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 784)               0
_________________________________________________________________
dense_1 (Dense)              (None, 50)                39250
_________________________________________________________________
dense_2 (Dense)              (None, 100)               5100
_________________________________________________________________
dense_3 (Dense)              (None, 10)                1010
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0
=================================================================
Total params: 45,360
Trainable params: 45,360
Non-trainable params: 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;きちんと望みのモデルが実装されていることが確認できました。&lt;/p&gt;

&lt;p&gt;ここで、中間層の定義方法について、&lt;code class=&quot;highlighter-rouge&quot;&gt;three_nn.py&lt;/code&gt;と書き方が変わっていると気づいた方もいるでしょう。&lt;/p&gt;

&lt;p&gt;Functional APIを用いたモデル定義では、前回紹介したように、入力と出力のテンソルを個別に保持しておけば良いルールになっています。&lt;/p&gt;

&lt;p&gt;したがって、中間のベクトルに関しては特段利用したいケースがない限りは、同一の変数を利用した方が、コードが煩雑にならないのでおすすめです。&lt;/p&gt;

&lt;h3 id=&quot;23-重みファイルの読み込み&quot;&gt;2.3 重みファイルの読み込み&lt;/h3&gt;
&lt;p&gt;重みファイルは、ゼロから〜のものと同一のファイルを使用します。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/oreilly-japan/deep-learning-from-scratch/tree/master/ch03&quot;&gt;公式レポジトリ&lt;/a&gt;から、&lt;code class=&quot;highlighter-rouge&quot;&gt;sample_weight.pkl&lt;/code&gt;をダウンロードしてください。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mnist_nn.py&lt;/code&gt;と同一ディレクトリ内に&lt;code class=&quot;highlighter-rouge&quot;&gt;sample_weight.pkl&lt;/code&gt;を配置してください。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;以下が、重みファイルを読み込むためのスクリプトになります。&lt;br /&gt;
なお、今回は「推論処理のみ行う &amp;amp; できる限りゼロから〜に即したものにする」ために、このスクリプトを使用しますが、このような手間のかかる初期化処理は通常行いません。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pickle&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sample_weight.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'rb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;weight_array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'W1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
                        &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'W2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'W3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_array&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/getting-started/faq/#keras-model&quot;&gt;Kerasでモデルの保存/ロードを行う&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;24-テストする&quot;&gt;2.4 テストする&lt;/h3&gt;
&lt;p&gt;それでは、ゼロから〜のP77と同様に実装したモデルをテストしていきましょう。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.argmax&lt;/code&gt;で軸(axis)指定をしていますが、これはリストが2次元配列以上のときに、「どの軸方向に対して演算を行うか」を指定するために活用します。&lt;br /&gt;
軸指定の詳細については、&lt;a href=&quot;https://deepage.net/features/numpy-axis.html&quot;&gt;このページ&lt;/a&gt;を参照するとわかりやすいです。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;_y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Accuracy: {np.sum(y_test == _y_test) / len(y_test)}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Accuracy: 0.9352
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;めでたく、ゼロから〜のP77に示されている分類精度: 0.9352を得ることができました！&lt;/p&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;今回はゼロから〜の3章に対応する部分である、3層ニューラルネットとMNISTデータセットの分類をKerasで実装しました。 
深層学習フレームワークを活用することで、たった数行でゼロから〜にあるものと同一のモデルを実装できることを実感したと思います。&lt;/p&gt;

&lt;p&gt;次回からはゼロから〜の4章以降に対応する、ニューラルネットワークの学習に入ります！&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras&quot;&gt;GitHub&lt;/a&gt;にて公開しています。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに</summary></entry><entry xml:lang="ja_JP"><title type="html">ゼロから作るDeep Learningとともに学ぶフレームワーク（パーセプトロン編）</title><link href="http://localhost:4000/DL-Intro-1/" rel="alternate" type="text/html" title="ゼロから作るDeep Learningとともに学ぶフレームワーク（パーセプトロン編）" /><published>2019-04-13T00:00:00+09:00</published><updated>2019-04-13T00:00:00+09:00</updated><id>http://localhost:4000/DL-Intro-1</id><content type="html" xml:base="http://localhost:4000/DL-Intro-1/">&lt;h2 id=&quot;はじめに&quot;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;「ゼロから作るディープラーニング」は深層学習を学ぶ入門書として非常に人気があり、様々な場所で用いられています。&lt;/p&gt;

&lt;p&gt;しかしながら、「フレームワークを用いないで深層学習の基礎を学ぶ」という本の目的により、深層学習フレームワークに関する内容は触れられていません。&lt;/p&gt;

&lt;p&gt;そのため、読者の中には実際のフレームワークを用いた機械学習の勉強へと繋げる機会や気力を失ってしまった人も少なからずいると思います。&lt;/p&gt;

&lt;p&gt;このプロジェクトでは、「ゼロから作るDeep Learning」（以下、ゼロから〜）を学習しつつ、深層学習フレームワークの一つである、Kerasについて学んでいきます。&lt;br /&gt;
これにより、深層学習の基礎を理解しつつ、フレームワークを活用した実装方法について学ぶことができます！&lt;/p&gt;

&lt;p&gt;それでは、まずはKerasのインストールから始めていきましょう。&lt;/p&gt;

&lt;div class=&quot;link_box&quot;&gt;
    &lt;span class=&quot;box-title&quot;&gt;シリーズリンク&lt;/span&gt;
    &lt;p&gt;第一弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-1/&quot;&gt;パーセプトロン編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第二弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-2/&quot;&gt;3層ニューラルネットワーク &amp;amp; 手書き数字認識編&lt;/a&gt;&lt;/p&gt;  
    &lt;p&gt;第三弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-3/&quot;&gt;ニューラルネットワークの学習編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第四弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-4/&quot;&gt;学習テクニック編&lt;/a&gt;&lt;/p&gt;
    &lt;p&gt;第五弾：&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://gucci-j.github.io/DL-Intro-5/&quot;&gt;畳み込みニューラルネットワーク編&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;!-- START MoshimoAffiliateEasyLink --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
(function(b,c,f,g,a,d,e){b.MoshimoAffiliateObject=a;
b[a]=b[a]||function(){arguments.currentScript=c.currentScript
||c.scripts[c.scripts.length-2];(b[a].q=b[a].q||[]).push(arguments)};
c.getElementById(a)||(d=c.createElement(f),d.src=g,
d.id=a,e=c.getElementsByTagName(&quot;body&quot;)[0],e.appendChild(d))})
(window,document,&quot;script&quot;,&quot;//dn.msmstatic.com/site/cardlink/bundle.js&quot;,&quot;msmaflink&quot;);
msmaflink({&quot;n&quot;:&quot;ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装&quot;,&quot;b&quot;:&quot;&quot;,&quot;t&quot;:&quot;&quot;,&quot;d&quot;:&quot;https:\/\/images-fe.ssl-images-amazon.com&quot;,&quot;c_p&quot;:&quot;\/images\/I&quot;,&quot;p&quot;:[&quot;\/512ru2i5gyL.jpg&quot;,&quot;\/51Z7TzDuljL.jpg&quot;,&quot;\/51Dzt-P86rL.jpg&quot;,&quot;\/51VfxOvKEwL.jpg&quot;,&quot;\/51dNlTr6a7L.jpg&quot;,&quot;\/51RfBXWcDAL.jpg&quot;,&quot;\/415IXnDy3IL.jpg&quot;,&quot;\/415VCPaFk1L.jpg&quot;,&quot;\/410OtMHeqkL.jpg&quot;,&quot;\/41F7PYraodL.jpg&quot;,&quot;\/41TFOjFQtaL.jpg&quot;,&quot;\/51SRdr-iBHL.jpg&quot;,&quot;\/51yxT9nEC4L.jpg&quot;,&quot;\/51q0zWV9NnL.jpg&quot;,&quot;\/51MDmgZZ2cL.jpg&quot;,&quot;\/51n9f4IpDZL.jpg&quot;,&quot;\/51erDZNc9tL.jpg&quot;,&quot;\/41qOS5gPctL.jpg&quot;,&quot;\/51wDA5ZuAeL.jpg&quot;,&quot;\/51Fg67TMeCL.jpg&quot;,&quot;\/51KCmWaOqFL.jpg&quot;,&quot;\/51e5o3xlSTL.jpg&quot;,&quot;\/51RF7CQIW1L.jpg&quot;,&quot;\/514m0GkYReL.jpg&quot;,&quot;\/516bqTekHoL.jpg&quot;,&quot;\/41colcboiNL.jpg&quot;,&quot;\/51IRqvCxzAL.jpg&quot;,&quot;\/51mFjvDorhL.jpg&quot;,&quot;\/51BQcHSo5QL.jpg&quot;,&quot;\/51THHJTIaTL.jpg&quot;,&quot;\/51PzJ4B%2BhtL.jpg&quot;,&quot;\/51CRA6FoSLL.jpg&quot;,&quot;\/41M5Qzg1yXL.jpg&quot;,&quot;\/51iMy2fgPkL.jpg&quot;,&quot;\/41xe6JIHELL.jpg&quot;,&quot;\/41HYfr%2Bv%2BKL.jpg&quot;,&quot;\/41gRFTsmr%2BL.jpg&quot;,&quot;\/51fD5k24M8L.jpg&quot;,&quot;\/518%2B8E-OZeL.jpg&quot;,&quot;\/41iyTyjjgdL.jpg&quot;,&quot;\/51L6s8Uo8aL.jpg&quot;,&quot;\/41xHQHIOQ2L.jpg&quot;,&quot;\/51ZWyzq1L3L.jpg&quot;,&quot;\/51oDwhT1gcL.jpg&quot;,&quot;\/51Zu5NuGq2L.jpg&quot;,&quot;\/512VUPnG69L.jpg&quot;,&quot;\/41Ufnm15s9L.jpg&quot;,&quot;\/41nALw08xcL.jpg&quot;,&quot;\/51uZB7hP-xL.jpg&quot;,&quot;\/41Qi%2BzskZHL.jpg&quot;,&quot;\/51p3s1TTn4L.jpg&quot;,&quot;\/413xgCPJnzL.jpg&quot;,&quot;\/51mc1fX%2B7xL.jpg&quot;,&quot;\/51GLiuSVtbL.jpg&quot;,&quot;\/419bmxhHV9L.jpg&quot;,&quot;\/5100WGZVi6L.jpg&quot;],&quot;u&quot;:{&quot;u&quot;:&quot;https:\/\/www.amazon.co.jp\/%E3%82%BC%E3%83%AD%E3%81%8B%E3%82%89%E4%BD%9C%E3%82%8BDeep-Learning-%E2%80%95Python%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AE%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%A3%85-%E6%96%8E%E8%97%A4-%E5%BA%B7%E6%AF%85\/dp\/4873117585&quot;,&quot;t&quot;:&quot;amazon&quot;,&quot;r_v&quot;:&quot;&quot;},&quot;aid&quot;:{&quot;amazon&quot;:&quot;1430714&quot;,&quot;rakuten&quot;:&quot;1430719&quot;,&quot;yahoo&quot;:&quot;1430721&quot;}});
&lt;/script&gt;

&lt;!-- MoshimoAffiliateEasyLink END --&gt;

&lt;h2 id=&quot;1-kerasのインストール&quot;&gt;1. Kerasのインストール&lt;/h2&gt;
&lt;p&gt;(&lt;strong&gt;注意&lt;/strong&gt;) 本プロジェクトでは、すでにPythonやNumPy等のインストールは終えているものとしてスタートします。&lt;br /&gt;
環境整備がお済みでない方は、先にゼロから〜の一章を参考に済ませてください。&lt;/p&gt;

&lt;p&gt;・コマンドライン上で、以下のコマンドを入力してKerasをインストールします。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install keras
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/&quot;&gt;https://keras.io/ja/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;2-プロジェクトの作成&quot;&gt;2. プロジェクトの作成&lt;/h2&gt;

&lt;p&gt;お好きな環境でゼロから〜二章用のプロジェクトを作成してください。&lt;/p&gt;

&lt;p&gt;ただし、ここでは、&lt;code class=&quot;highlighter-rouge&quot;&gt;sequential.py&lt;/code&gt;と&lt;code class=&quot;highlighter-rouge&quot;&gt;functional.py&lt;/code&gt;の二つのファイルを作成することとします。&lt;/p&gt;

&lt;h2 id=&quot;3-モデルの作成--テスト&quot;&gt;3. モデルの作成 &amp;amp; テスト&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;KerasにはSepuentialモデルとFunctional APIの2種類のモデルの定義方法があります。
    &lt;ul&gt;
      &lt;li&gt;Sepuentialモデル：様々な層を積み木のように積み重ねていくイメージ。線形スタック。&lt;/li&gt;
      &lt;li&gt;Functionalモデル：層をインスタンスとして扱う。複雑なモデルを定義するときに便利。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;それぞれのモデルの定義方法の違いを以下で見ていきましょう。&lt;/p&gt;

&lt;h3 id=&quot;31-sequential-モデル&quot;&gt;3.1 Sequential モデル&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SequentialモデルでANDゲートのパーセプトロンを実装します。&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;sequential.py&lt;/code&gt;に以下のソースを順に書いていきましょう。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;311-レイヤー--numpyを読み込む&quot;&gt;3.1.1 レイヤー + NumPyを読み込む&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;312-modelにsepuentialモデルを定義する&quot;&gt;3.1.2 &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;にSepuentialモデルを定義する&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;313-modelにdense層全結合層を追加する&quot;&gt;3.1.3 &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;にDense層（全結合層）を追加する&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;全結合層という用語はゼロから〜の二章には登場していませんが、ここでは単純パーセプトロンと同じと思ってください。&lt;br /&gt;
参考程度に、&lt;code class=&quot;highlighter-rouge&quot;&gt;input_dim=2, units=1&lt;/code&gt;のときのDense層の様子を概念図にしたものを以下に示します。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/resources/2019-04-13/example_dense.png&quot; alt=&quot;Dense層の様子の概念図&quot; style=&quot;width: 450px;&quot; /&gt;
&lt;/div&gt;

&lt;h4 id=&quot;314-modelに重みを与える&quot;&gt;3.1.4 &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt;に重みを与える&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ゼロから〜の二章では予め重みとバイアスが与えられているので、この実装でも与えます。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重みとバイアスの初期設定には、&lt;code class=&quot;highlighter-rouge&quot;&gt;model.set_weights()&lt;/code&gt;を使用します。&lt;br /&gt;
引数は重みの入ったリストです。&lt;/p&gt;
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;blockquote&gt;
      &lt;p&gt;&lt;i class=&quot;fas fa-book-open&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参照: ゼロから〜のP27&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;315-テストする&quot;&gt;3.1.5 テストする&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;モデルのテストは&lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt;メソッドで行えます。&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt;の返り値は、入力データの予測結果のリストになっています。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Y_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;この結果は以下のようになるはずです。&lt;br /&gt;
Output:
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[-0.7       ]
 [-0.19999999]
 [-0.19999999]
 [ 0.3       ]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;これではわかりにくいので、マイナスのものは&lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;で、プラスのものは&lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;に置き換えます。
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Y_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Results: {Y == Y_}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;以下のような結果が得られたと思います。&lt;br /&gt;
見事ANDゲートが実装できていることが確認できますね。&lt;br /&gt;
Output:
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[0.]
 [0.]
 [0.]
 [1.]]
Results: [[ True]
 [ True]
 [ True]
 [ True]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;32-fucntional-api&quot;&gt;3.2 Fucntional API&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Functional APIでANDゲートのパーセプトロンを実装します。&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;functional.py&lt;/code&gt;に以下のソースを順に書いていきましょう。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;321-レイヤー--numpyを読み込む&quot;&gt;3.2.1 レイヤー + NumPyを読み込む&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;322-各種レイヤーを定義する&quot;&gt;3.2.2 各種レイヤーを定義する&lt;/h4&gt;
&lt;p&gt;Functional APIでは、入力層を追加で定義する必要があります。&lt;/p&gt;

&lt;p&gt;Dense部分のイメージとしては、Denseレイヤーのインスタンスを生成し、その入力として、テンソル：_inputを与えるという感じです。出力のテンソルは_outputとなります。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;323-モデルを定義する&quot;&gt;3.2.3 モデルを定義する&lt;/h4&gt;
&lt;p&gt;以下のように、Functional APIでは、モデルを定義する際に入力と出力のテンソルを別々に保持しておく必要があります！&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;i class=&quot;fas fa-link&quot; style=&quot;padding: 0 2px 0 0;&quot;&gt;&lt;/i&gt;参考: &lt;a href=&quot;https://keras.io/ja/getting-started/functional-api-guide/&quot;&gt;https://keras.io/ja/getting-started/functional-api-guide/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;324-重みを与える--テストする&quot;&gt;3.2.4 重みを与える &amp;amp; テストする&lt;/h4&gt;
&lt;p&gt;Sequentialモデルと同じなので割愛します。&lt;br /&gt;
結果が同一になることを確認するとよいです。&lt;/p&gt;

&lt;h2 id=&quot;まとめ&quot;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;今回は、パーセプトロンによるANDゲートの実装をKerasにより行いました。&lt;/p&gt;

&lt;p&gt;Kerasを用いることで、より「簡単に&amp;amp;抽象的に」パーセプトロンを実装することが確認できたと思います。&lt;/p&gt;

&lt;p&gt;次回は、3層ニューラルネットワークの実装を行います。&lt;/p&gt;

&lt;h2 id=&quot;発展課題&quot;&gt;発展課題&lt;/h2&gt;

&lt;p&gt;NAND, ORゲートも実装してみると良いでしょう。&lt;br /&gt;
重みとバイアスは、ゼロから〜のP27,28を参照してください。&lt;/p&gt;

&lt;h2 id=&quot;ソースコード&quot;&gt;ソースコード&lt;/h2&gt;

&lt;p&gt;ソースコードは、&lt;a href=&quot;https://github.com/gucci-j/intro-deep-learning-keras&quot;&gt;GitHub&lt;/a&gt;にて公開しています。&lt;/p&gt;</content><author><name></name></author><category term="「ゼロからKeras」シリーズ" /><summary type="html">はじめに</summary></entry><entry xml:lang="ja_JP"><title type="html">論文メモ：Deep contextualized word representations</title><link href="http://localhost:4000/Note-ELMo/" rel="alternate" type="text/html" title="論文メモ：Deep contextualized word representations" /><published>2019-04-06T00:00:00+09:00</published><updated>2019-04-06T00:00:00+09:00</updated><id>http://localhost:4000/Note-ELMo</id><content type="html" xml:base="http://localhost:4000/Note-ELMo/">&lt;h2 id=&quot;文献情報&quot;&gt;文献情報&lt;/h2&gt;
&lt;p&gt;著者: M. Peters et al.&lt;br /&gt;
所属: Allen Institute for Artificial Intelligence / Paul G. Allen School of Computer Science &amp;amp; Engineering, University of Washington&lt;br /&gt;
出典: &lt;a href=&quot;https://aclweb.org/anthology/papers/N/N18/N18-1202/&quot;&gt;NAACL 2018&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;どんな論文か&quot;&gt;どんな論文か？&lt;/h2&gt;
&lt;p&gt;ELMo = Embeddings from Language Modelsの略であり，言語モデルを活用した文脈に応じた単語分散表現: ELMoを提唱した論文．&lt;/p&gt;

&lt;h2 id=&quot;先行研究と比べてどこが凄い&quot;&gt;先行研究と比べてどこが凄い？&lt;/h2&gt;
&lt;p&gt;既存のNLPタスクのモデルの埋め込み層にELMoを追加するだけで，様々なタスクで当時のSoTAを達成した．&lt;/p&gt;

&lt;h2 id=&quot;技術や手法のキモはどこ&quot;&gt;技術や手法のキモはどこ？&lt;/h2&gt;
&lt;p&gt;双方向言語モデルを活用し，隠れ層の重みを重み付き線形和で圧縮する点．&lt;br /&gt;
→ 従来手法では，単に双方向言語モデルの出力層だけを取ってきていた．&lt;/p&gt;

&lt;h2 id=&quot;どうやって有効だと検証した&quot;&gt;どうやって有効だと検証した？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;各種NLPタスクに適用して，そのスコアにより評価．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;議論はある&quot;&gt;議論はある？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;ELMoの中間層が捉えている特徴素について&lt;br /&gt;
→ 著者らによると，ELMoの中間層は低層であればあるほど，&lt;strong&gt;文法的(syntactic)&lt;/strong&gt;な情報を含み，高層の方が，&lt;strong&gt;意味的(semantic)&lt;/strong&gt;な情報を含むとのこと．&lt;br /&gt;
→ 基本的にどのタスクもsyntacticな情報を好む傾向にあるらしい．&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;論文の詳細メモ&quot;&gt;論文の詳細メモ&lt;/h2&gt;
&lt;h3 id=&quot;1-順方向言語モデル&quot;&gt;1. 順方向言語モデル&lt;/h3&gt;
&lt;p&gt;トークン数: $N$の単語列: $(t_1, t_2, \dots, t_N)$が与えられたとき，順方向の言語モデルは，単語: $t_k$と単語列: $(t_1, \dots, t_{k-1})$の条件付き確率をモデリングすることで，次のように表される.順方向の言語モデルでは，次の単語: $t_{k+1}$を予測することを目的とする．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$p(t_1, t_2, ..., t_N) = \prod_{k=1}^N p(t_k | t_1, t_2, \dots, t_{k-1})$$
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;最近の言語モデルでは，文脈非依存な単語表現: $\mathbf{x}_k^{LM}$を単語埋め込みやcharacter-based CNNにより算出してから，L層のLSTMに入力することが多い．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;単語列の位置: $k$において，各LSTM層は，文脈依存な単語表現: $\overrightarrow{\mathbf{h}}_{k, j}^{LM}$（ただし，$1 \leq j \leq L$）を出力する．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\overrightarrow{\mathbf{h}}_{k, L}^{LM}&lt;/script&gt;は，次の単語: $t_{k+1}$をsoftmax層で予測するのに用いられる．&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-逆方向言語モデル&quot;&gt;2. 逆方向言語モデル&lt;/h3&gt;
&lt;p&gt;逆方向言語モデルは順方向言語モデルと類似しているが，単語列を逆に処理していく点で異なる．なお，逆方向の言語モデルでは，未来の単語列から一つ前の単語: $t_{k-1}$を予測することを目的とする．つまり，逆方向の言語モデルは次のように定義される．&lt;/p&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$p(t_1, t_2, ..., t_N) = \prod_{k=1}^N p(t_k | t_{k+1}, t_{k+2}, \dots, t_N)$$
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;最終的には，&lt;script type=&quot;math/tex&quot;&gt;\overleftarrow{\mathbf{h}}_{k, L}^{LM}&lt;/script&gt; を求めることで，$t_{k-1}$ をsoftmax層で予測する．&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-双方向言語モデル&quot;&gt;3. 双方向言語モデル&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;通常言語モデルは対数尤度を最大化することで最適化を行う．&lt;br /&gt;
→ 文脈中で出現してほしい単語の確率を最大化するため．&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ELMoで使われる双方向言語モデルは次の式の対数尤度を最大化することで学習する．&lt;br /&gt;
→ 文脈非依存な単語表現とソフトマックス層のパラメータ: $\Theta_{x}, \Theta_s$は共有．LSTMのパラメータについてのみ独立．&lt;br /&gt;
→ 従来手法ではパラメータはすべて独立&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\sum_{k=1}^{N}(\log p(t_k | t_1, t_2, \dots, t_{k-1}; \Theta_x, \overrightarrow{\Theta}_{LSTM}, \Theta_s) \\+ \log p(t_k | t_{k+1}, t_{k+2}, \dots, t_N; \Theta_x, \overleftarrow{\Theta}_{LSTM}, \Theta_s))
$$
&lt;/div&gt;

&lt;h3 id=&quot;4-elmoのパラメータ算出&quot;&gt;4. ELMoのパラメータ算出&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;全てのトークン: $t_k$はL層の双方向言語モデルに対し，2L+1個の特徴量を持つ．&lt;br /&gt;
→ 文脈依存しない単語ベクトル: 1個&lt;br /&gt;
→ 文脈依存のする順方向と逆方向のLSTM: 2L個&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\begin{equation*}
\begin{split}
R_k &amp;amp;= \{x_k^{LM}, \overrightarrow{\mathbf{h}}_{k, j}^{LM}, \overleftarrow{\mathbf{h}}_{k, j}^{LM} | j = 1, \dots, L \}\\
    &amp;amp;= \{\mathbf{h}_{k, j}^{LM} | j=0, \dots, L \}
\end{split}
\end{equation*}
$$
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ELMoを他のタスクに応用するには，Rのすべての要素を一つのベクトル表現に変換する．&lt;br /&gt;
→ 簡単な例だと，一番上の層だけを取ってくるものがある．CoVeやTagLMはこれを採用している．&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\mathbf{ELMo}_k^{task} = E(R_k; \Theta_e) = \mathbf{h}_{k, L}^{LM}
$$
&lt;/div&gt;

&lt;div style=&quot;text-align: center&quot;&gt;ただし，$\mathbf{h}_{k, L}^{LM} = \left[\overrightarrow{\mathbf{h}}_{k, j}^{LM}; \overleftarrow{\mathbf{h}}_{k, j}^{LM}\right]$&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ELMoではより便宜をはかり，重み付き線形和の形で変換する．&lt;br /&gt;
→ $s_j^{task}$はsoftmaxで正規化された重み&lt;br /&gt;
→ $\gamma^{task}$はELMoのベクトル全体をスケーリングするため．チューニングの最適化の観点から必要．&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;mathjax-scroll&quot;&gt;
$$
\mathbf{ELMo}_k^{task} = \gamma^{task} \sum_{j=0}^L s_j^{task}\mathbf{h}_{k, j}^{LM}
$$
&lt;/div&gt;

&lt;h3 id=&quot;5-elmoモデルのnlpタスクへの適用&quot;&gt;5. ELMoモデルのNLPタスクへの適用&lt;/h3&gt;
&lt;p&gt;単に$\mathbf{ELMo}_k^{task}$を入力の埋め込みベクトルとconcatすれば良い．&lt;/p&gt;

&lt;h2 id=&quot;まとめスライド&quot;&gt;まとめスライド&lt;/h2&gt;
&lt;div style=&quot;text-align: center&quot;&gt;&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/hvw0gfJhsc8aWL&quot; width=&quot;510&quot; height=&quot;420&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&quot; allowfullscreen=&quot;&quot;&gt; &lt;/iframe&gt;&lt;/div&gt;
&lt;div style=&quot;margin-bottom:5px&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;実装&quot;&gt;実装&lt;/h2&gt;
&lt;p&gt;試しにKerasでELMo + BiLSTMを使ってIMDBの分類を行ったので，GitHubにあげました．&lt;br /&gt;
→ &lt;a href=&quot;https://github.com/gucci-j/elmo-imdb&quot;&gt;GitHub-ELMo&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="論文メモ" /><summary type="html">文献情報 著者: M. Peters et al. 所属: Allen Institute for Artificial Intelligence / Paul G. Allen School of Computer Science &amp;amp; Engineering, University of Washington 出典: NAACL 2018</summary></entry></feed>