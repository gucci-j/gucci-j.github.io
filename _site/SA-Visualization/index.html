<!DOCTYPE html>
<html>
  <head>
    <title>MatplotlibとseabornによるSelf Attentionの可視化 – きままにNLP – A Technical Blog</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="Pythonの可視化ライブラリであるseabornとグラフ描画ライブラリのMatplotlibを組み合わせることで，意外と簡単にSelf Attentionの重みを可視化することができる．

" />
    <meta property="og:description" content="Pythonの可視化ライブラリであるseabornとグラフ描画ライブラリのMatplotlibを組み合わせることで，意外と簡単にSelf Attentionの重みを可視化することができる．

" />
    
    <meta name="author" content="きままにNLP" />

    
    <meta property="og:title" content="MatplotlibとseabornによるSelf Attentionの可視化" />
    <meta property="twitter:title" content="MatplotlibとseabornによるSelf Attentionの可視化" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="きままにNLP - A Technical Blog" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->

    <!-- Favicon head tag -->
    <link rel="icon" href="https://pbs.twimg.com/profile_images/1112635060480442368/Ou7bjYFs_400x400.png" type="image/x-icon">

    <!-- Begin Jekyll SEO tag v2.6.0 -->
<title>MatplotlibとseabornによるSelf Attentionの可視化 | きままにNLP</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="MatplotlibとseabornによるSelf Attentionの可視化" />
<meta property="og:locale" content="ja_JP" />
<meta name="description" content="Self Attentionの重みを，Pythonのライブラリである「Matplotlibとseaborn」を活用して可視化する方法について紹介します．モデルの実装は，PyTorchに基づきます．" />
<meta property="og:description" content="Self Attentionの重みを，Pythonのライブラリである「Matplotlibとseaborn」を活用して可視化する方法について紹介します．モデルの実装は，PyTorchに基づきます．" />
<link rel="canonical" href="http://localhost:4000/SA-Visualization/" />
<meta property="og:url" content="http://localhost:4000/SA-Visualization/" />
<meta property="og:site_name" content="きままにNLP" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-02T00:00:00+09:00" />
<script type="application/ld+json">
{"description":"Self Attentionの重みを，Pythonのライブラリである「Matplotlibとseaborn」を活用して可視化する方法について紹介します．モデルの実装は，PyTorchに基づきます．","@type":"BlogPosting","url":"http://localhost:4000/SA-Visualization/","headline":"MatplotlibとseabornによるSelf Attentionの可視化","dateModified":"2019-04-02T00:00:00+09:00","datePublished":"2019-04-02T00:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/SA-Visualization/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <!-- Google Adsense-->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-1838422896597988",
        enable_page_level_ads: true
      });
    </script>
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://pbs.twimg.com/profile_images/1112635060480442368/Ou7bjYFs_400x400.png" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">きままにNLP</a></h1>
            <p class="site-description">A Technical Blog</p>
          </div>

          <nav>
            <a href="/">Blog</a>
            <a href="/about">About</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <style type="text/css">
  #toc ul, ol{
  color: #1e366a;
  padding: 0.1em 0 0.1em 1.0em;
  font-size: 90%
  }
  
  #toc ul li, ol li{
    line-height: 1.5;
    padding: 0.1em 0;
  }

  #box div{
   border-top: solid #1e366a 1px;/*上のボーダー*/
   border-bottom: solid #1e366a 1px; /* 下側の1本線 */
   padding: 0.1em 0;
  }
</style>

<article class="post">
  <h1>MatplotlibとseabornによるSelf Attentionの可視化</h1>
  <div id="box">
    <div id="toc">
      <ul class="date">
  <li><a href="#1-ダウンロード--インストール">1. ダウンロード &amp; インストール</a></li>
  <li><a href="#2-インポート">2. インポート</a></li>
  <li><a href="#3-self-attentionの実装">3. Self Attentionの実装</a></li>
  <li><a href="#4-いざ描画">4. いざ描画</a></li>
  <li><a href="#ソースコード">ソースコード</a></li>
</ul>
    </div>
  </div> 
  <div class="entry">
    <p>Pythonの可視化ライブラリであるseabornとグラフ描画ライブラリのMatplotlibを組み合わせることで，意外と簡単にSelf Attentionの重みを可視化することができる．</p>

<p>とあるデータセットを用いて実際に可視化した結果が以下の図です．</p>

<p><img src="../resources/2019-04-02/attention.png" alt="attentionの可視化結果" /></p>

<p>それでは，順を追って簡単に見ていきましょう．
なお，深層学習のフレームワークにはPyTorchを使用し，テキストデータの前処理にはtorchtextを使用しています．</p>

<h2 id="1-ダウンロード--インストール">1. ダウンロード &amp; インストール</h2>
<p>Matplotlib，seabornをインストールしていない場合は，インストールしましょう．</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install matplotlib
pip install seaborn
</code></pre></div></div>

<h2 id="2-インポート">2. インポート</h2>
<p>本稿ではサーバー上で動作させることを想定しているので，前もって<code class="highlighter-rouge">mpl.use('Agg')</code>を指定することで，描画エラーを回避します．</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
</code></pre></div></div>

<h2 id="3-self-attentionの実装">3. Self Attentionの実装</h2>
<p>Self Attentionの実装については，<a href="https://github.com/gucci-j/imdb-classification-gru">GitHub</a>にあげている，ソースコード: <code class="highlighter-rouge">model_with_self_attention.py</code>を流用しました．クラス部分を以下に貼ります．</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class Self_Attention(nn.Module):
    def __init__(self, query_dim):
        # assume: query_dim = key/value_dim
        super(Self_Attention, self).__init__()
        self.scale = 1. / math.sqrt(query_dim)

    def forward(self, query, key, value):
        # query == hidden: (batch_size, hidden_dim * 2)
        # key/value == gru_output: (sentence_length, batch_size, hidden_dim * 2)
        query = query.unsqueeze(1) # (batch_size, 1, hidden_dim * 2)
        key = key.transpose(0, 1).transpose(1, 2) # (batch_size, hidden_dim * 2, sentence_length)

        # bmm: batch matrix-matrix multiplication
        attention_weight = torch.bmm(query, key) # (batch_size, 1, sentence_length)
        attention_weight = F.softmax(attention_weight.mul_(self.scale), dim=2) # normalize sentence_length's dimension

        value = value.transpose(0, 1) # (batch_size, sentence_length, hidden_dim * 2)
        attention_output = torch.bmm(attention_weight, value) # (batch_size, 1, hidden_dim * 2)
        attention_output = attention_output.squeeze(1) # (batch_size, hidden_dim * 2)

        return attention_output, attention_weight.squeeze(1)
</code></pre></div></div>

<p>ソースコード中において，<code class="highlighter-rouge">attention_weight</code>は時系列方向に正規化された重みベクトルとなっています．そのため，このベクトルを可視化することで，各時刻における入力の単語の重要度を可視化できることになります．<br />
要するに，このソースコードにおいては，可視化には<code class="highlighter-rouge">attention_weight</code>のみを用いれば良いことになります．</p>

<h2 id="4-いざ描画">4. いざ描画</h2>

<p>ヒートマップの描画には，<code class="highlighter-rouge">sns.heatmap()</code>を使います．詳しい使い方は，<a href="https://seaborn.pydata.org/generated/seaborn.heatmap.html">ドキュメント</a>をご覧ください．</p>

<p>重要な点としては，ヒートマップ中の各セル内に入力の単語を表示させたいときに，<code class="highlighter-rouge">annot</code>に<code class="highlighter-rouge">string</code>型のリストを渡すことで，描画できてしまうということです！</p>

<p>ただし，必ず<strong>リストをNumPyに通すこと</strong> + <strong><code class="highlighter-rouge">fmt=''</code></strong>を指定するのを忘れないでください！</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>plt.figure(figsize = (15, 7))
sns.heatmap(attention_weight, annot=np.asarray(itos), fmt='', cmap='Blues')
plt.savefig('./fig/attention_' + str(batch_count) + '.png')
plt.close()
</code></pre></div></div>

<h2 id="ソースコード">ソースコード</h2>
<p>ソースコードは後日: <a href="https://github.com/gucci-j/imdb-classification-gru">GitHub</a>に追加して公開する予定です．</p>

  </div>

  <div class="date">
    Written on April  2, 2019
  </div>

  
  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:gucci.research@gmail.com"><i class="svg-icon email"></i></a>


<a href="https://github.com/gucci-j"><i class="svg-icon github"></i></a>



<a href="/feed.xml"><i class="svg-icon rss"></i></a>
<a href="https://www.twitter.com/_gucciiiii"><i class="svg-icon twitter"></i></a>


<br />
          <a href="/privacy">Privacy Policy</a>
        </footer>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-137498199-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/SA-Visualization/',
		  'title': 'MatplotlibとseabornによるSelf Attentionの可視化'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
